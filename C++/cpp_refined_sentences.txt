There is experimental support for non-equal allocators in the standard contain-
ers in C++98 mode.
There are no additional requirements on allocators.
It is undeﬁned behaviour to swap two containers if their
allocators are not equal.
Nope, these types are called implementation-deﬁned because you shouldn’t be taking advantage of their underlying
types.
Anything and everything we have on locale implementation will be described under Localization.
Whether or not the previously-written
I/O is destroyed in this process depends mostly on the --enable-libio choice: for stdio, if the written data is already in the
stdio buffer, the data may be completely safe!
We are not
currently taking advantage of this yet.
This table is based on the table of contents of ISO/IEC JTC1 SC22 WG21 Doc No: N3290 Date: 2011-04-11 Final Draft
International Standard, Standard for Programming Language C++
In this implementation the -std=gnu++11 or -std=c++11 ﬂag must be used to enable language and library features.
See
dialect options.
The pre-deﬁned symbol __cplusplus is used to check for the presence of the required ﬂag.
GCC 5.1 was
the ﬁrst release with non-experimental C++11 support, so the API and ABI of features added in C++11 is only stable since that
release.
This status table is based on the table of contents of ISO/IEC 14882:2011.
This section describes the C++11 support in mainline GCC, not in any particular release.
This section only documents behaviour which is new in the 2011 standard.
Time point values are truncated to time_t values.
There is no loss of precision for conver-
sions in the other direction.
The types u16streampos and
u32streampos are both synonyms for fpos<mbstate_t>.
The function eof returns int_type(-1).
The mapping should be documented here.
The valid token values are shown in the list below.
The default constructor uses the token "default".
This is the only token that is always valid.
"rand_s" Use the MSVCRT rand_s function.
This token is only valid for mingw-w64 targets.
These tokens are only valid for x86 and x86_64 targets when both the assembler and CPU support
the corresponding instruction.
This token is only valid for 64-bit powerpc targets when both the assembler and CPU support the
corresponding instruction.
This is
equivalent to trying each of the following and using the ﬁrst that is supported: "rdseed""rdrand""darn"
"arc4random", "getentropy" Use the named C library function, if available on the target.
These tokens are
only valid when the device ﬁles are present and readable by the current user.
An integer seed value can be used as the token and will be converted to an unsigned long using
strtoul.
These tokens are only valid when no other source of random bytes is available.
An exception of type runtime_error will be thrown if a random_device object is constructed with an invalid token, or if
it cannot open or read from the source of random bytes.
The handle types are deﬁned in
terms of the Gthreads abstraction layer, although this is subject to change at any time.
Any use of native_handle is inherently
non-portable and not guaranteed to work between major releases of GCC.
The value of the native handle is undeﬁned for a thread which is not joinable.
The native handle type is __gthread_mutex_t* i.e.
pthread_mutex_t* for the posix
thread model.
The native handle type is __gthread_recursive_mutex_t* i.e.
pthread_mutex_t* for the posix thread model.
There are no additional bitmask elements deﬁned.
In this implementation the -std=gnu++14 or -std=c++14 ﬂag must be used to enable language and library features.
See
dialect options.
The pre-deﬁned symbol __cplusplus is used to check for the presence of the required ﬂag.
GCC 6.1 was
the ﬁrst release with non-experimental C++14 support, so the API and ABI of features added in C++14 is only stable since that
release.
This status table is based on the table of contents of ISO/IEC 14882:2014.
Some subclauses are not shown in the table where the
content is unchanged since C++11 and the implementation is complete.
This section describes the C++14 and library TS support in mainline GCC, not in any particular release.
Some features will not be supported on some targets.
Symbolic links and ﬁle permissions are not supported
on Windows.
On Windows, experimental::filesystem::rename is implemented by calling MoveFileExW
and so does not meet the requirements of POSIX rename when one or both of the paths resolves to an existing directory.
Speciﬁ-
cally, it is possible to rename a directory so it replaces a non-directory (POSIX requires an error in that case), and it is not possible
to rename a directory to replace another directory (POSIX requires that to work if the directory being replaced is empty).
In this implementation the -std=gnu++17 or -std=c++17 ﬂag must be used to enable language and library features.
See
dialect options.
The pre-deﬁned symbol __cplusplus is used to check for the presence of the required ﬂag.
GCC 9.1 was
the ﬁrst release with non-experimental C++17 support, so the API and ABI of features added in C++17 is only stable since that
release.
This section describes the C++17 and library TS support in mainline GCC, not in any particular release.
C++ Dynamic Arrays
N
Array Extensions TS
N3793
A proposal to add a utility
class to represent optional
objects
Y
Library Fundamentals TS
N3804
Any library proposal
Y
Library Fundamentals TS
N3866
Invocation type traits, but
dropping
function_call_operator.
The following table lists new library features that are included in the C++17 standard.
The "Proposal" column provides a link
to the ISO C++ committee proposal that describes the feature, while the "Status" column indicates the ﬁrst version of GCC that
contains an implementation of this feature (if it has been implemented).
The "SD-6 Feature Test" column shows the corresponding
macro or header from SD-6: Feature-testing recommendations for C++.
Note 1: This feature is supported in GCC 7.1 and 7.2 but before GCC 7.3 the __cpp_lib macro is not deﬁned, and compilation
will fail if the header is included without using -std to enable C++17 support.
Note 2: This feature is supported in older releases but the __cpp_lib macro is not deﬁned to the right value (or not deﬁned at
all) until the version shown in parentheses.
Note 3: The Parallel Algorithms have an external dependency on Intel TBB 2018 or later.
If the <execution> header is
included then -ltbb must be used to link to TBB.
Note 4: The mathematical special functions are enabled in C++17 mode from GCC 7.1 onwards.
For GCC 6.x or for C++11/C++14
deﬁne __STDCPP_WANT_MATH_SPEC_FUNCS__ to a non-zero value and test for __STDCPP_MATH_SPEC_FUNCS__ >=
201003L.
The following status table is based on the table of contents of ISO/IEC 14882:2017.
Some subclauses are not shown in the table
where the content is unchanged since C++14 and the implementation is complete.
This section only documents behaviour which is new in the 2017 standard.
For the GNU C library, there is no Annex K support and so none of its names are
declared by C++ headers.
The limit for maximum
number of blocks in a chunk is given by 2N-1, where N is min(19, 3 + S/2).
Some features will not be supported on some targets.
Symbolic links and ﬁle permissions are not supported on Windows.
The clock’s epoch is unspeciﬁed, but is not the same as the system clock’s
epoch.
On Windows, a drive speciﬁer such as
"C:" or "z:" is treated as a root-name.
On Cygwin, a path that begins with two successive directory separators is a root-name.
Otherwise (for POSIX-like systems other than Cygwin), the implementation-deﬁned root-name is an unspeciﬁed string which
does not appear in any pathnames.
Speciﬁcally, it is not
possible to rename a directory to replace another directory (POSIX requires that to work if the directory being replaced is empty).
When targeting 32-bit x86, simd_abi::compatible<T> is an alias for simd_abi::scalar.
When targeting 64-bit
x86 (including x32) or Aarch64, simd_abi::compatible<T> is an alias for simd_abi::_VecBuiltin<16>, unless
T is long double, in which case it is an alias for simd_abi::scalar.
When targeting ARM (but not Aarch64) with
NEON support, simd_abi::compatible<T> is an alias for simd_abi::_VecBuiltin<16>, unless sizeof(T) >
4, in which case it is an alias for simd_abi::scalar.
Additionally, simd_abi::compatible<float> is an alias for
simd_abi::scalar unless compiling with -ffast-math.
When targeting x86 (both 32-bit and 64-bit), simd_abi::native<T> is an alias for one of simd_abi::scalar, simd_abi::_V
simd_abi::_VecBuiltin<32>, or simd_abi::_VecBltnBtmsk<64>, depending on T and the machine options the
compiler was invoked with.
When targeting ARM/Aarch64 or POWER, simd_abi::native<T> is an alias for simd_abi::scalar or simd_abi::_VecB
depending on T and the machine options the compiler was invoked with.
The extended ABI tag types deﬁned in the std::experimental::parallelism_v2::simd_abi namespace are:
simd_abi::_VecBuiltin<Bytes>, and simd_abi::_VecBltnBtmsk<Bytes>.
Otherwise it is an alias for simd_abi::fixed_size<N>.
The
simd_abi::_VecBltnBtmsk ABI tag
is preferred over simd_abi::_VecBuiltin.
T::size() rounded up to the next
power-of-two value.
Additionally, sizeof(T) == 8 with integral T is supported if __ARM_ARCH >= 8, and double is
supported if __aarch64__ is deﬁned.
VSX__ is deﬁned, and any T with
sizeof(T) <=
8 is supported if __POWER8_VECTOR__ is deﬁned.
In this implementation the -std=gnu++20 or -std=c++20 ﬂag must be used to enable language and library features.
See
dialect options.
The pre-deﬁned symbol __cplusplus is used to check for the presence of the required ﬂag.
This section describes the C++20 and library TS support in mainline GCC, not in any particular release.
The "Proposal" column provides a link
to the ISO C++ committee proposal that describes the feature, while the "Status" column indicates the ﬁrst version of GCC that
contains an implementation of this feature (if it has been implemented).
A dash (—) in the status column indicates that the
changes in the proposal either do not affect the code in libstdc++, or the changes are not required for conformance.
The "SD-6
Feature Test / Notes" column shows the corresponding macro or header from SD-6: Feature-testing recommendations for C++
(where applicable) or any notes about the implementation.
Note 1: This feature is supported in older releases but the __cpp_lib macro is not deﬁned to the right value (or not deﬁned at
all) until the version shown in parentheses.
See
dialect options.
The pre-deﬁned symbol __cplusplus is used to check for the presence of the required ﬂag.
This section describes the C++23 and library TS support in mainline GCC, not in any particular release.
The following table lists new library features that have been accepted into the C++23 working draft.
The "Proposal" column
provides a link to the ISO C++ committee proposal that describes the feature, while the "Status" column indicates the ﬁrst version
of GCC that contains an implementation of this feature (if it has been implemented).
A dash (—) in the status column indicates
that the changes in the proposal either do not affect the code in libstdc++, or the changes are not required for conformance.
The
"SD-6 Feature Test / Notes" column shows the corresponding macro or header from SD-6: Feature-testing recommendations for
C++ (where applicable) or any notes about the implementation.
In this implementation the header names are preﬁxed by tr1/, for instance <tr1/functional>, <tr1/memory>, and so
on.
This page describes the TR1 support in mainline GCC, not in any particular release.
This page describes the TR 24733 support in mainline GCC, not in any particular release.
This table is based on the table of contents of ISO/IEC FDIS 29124, Doc No: N3060, Date: 2010-03-06, "Extensions to the C++
Library to support mathematical special functions".
Complete support for IS 29124 is in GCC 6.1 and later releases, when using at least C++11 (for older releases or C++98/C++03
use TR1 instead).
For C++11 and C++14 the additions to the library are not declared by their respective headers unless
__STDCPP_WANT_MATH_SPEC_FUNCS__ is deﬁned as a macro that expands to a non-zero integer constant.
For C++17
the special functions are always declared (since GCC 7.1).
When the special functions are declared the macro __STDCPP_MATH_SPEC_FUNCS__ is deﬁned to 201003L.
In addition to the special functions deﬁned in IS 29124, for non-strict modes (i.e. -std=gnu++NN modes) the hypergeometric
functions and conﬂuent hypergeometric functions from TR1 are also provided, deﬁned in namespace __gnu_cxx.
This section documents
behaviour which is required by IS 29124.
The functions declared in Clause 8 are only declared when __STDCPP_WANT_MATH_SPEC_FUNCS__
== 1 (or in C++17 mode, for GCC 7.1 and later).
The effect of calling these functions with n >= 128 or m >= 128 should be described here.
The effect of calling these functions with l >= 128 should be described here.
The effect of calling these functions with nu >= 128 should be described here.
J]/3 The effect of calling these functions with nu >= 128 should be described here.
The effect of calling these functions with nu >= 128 should be described here.
The effect of calling these functions with n >= 128 should be described here.
The effect of calling these functions with n >= 128 should be described here.
The effect of calling these functions with l >= 128 should be described here.
The effect of calling these functions with l >= 128 should be described here.
The header <ctgmath>
Partial
Conﬂicts with C++ 2011
requirements.
C++ Special Functions Implementation Status


There are two licenses affecting GNU libstdc++: one for the code, and one for the documentation.
There is a license section in the FAQ regarding common questions.
If you have more questions, ask the FSF or the gcc mailing
list.
March 2009
Copyright (C) 2009 Free Software Foundation, Inc.
Everyone is permitted to copy and distribute verbatim copies of this
license document, but changing it is not allowed.
This GCC Runtime Library Exception ("Exception") is an additional
permission under section 7 of the GNU General Public License, version
3 ("GPLv3").
It applies to a given file (the "Runtime Library") that
bears a notice placed by the copyright holder of the file stating that
the file is governed by GPLv3 along with this Exception.
When you use GCC to compile a program, GCC may combine portions of
certain GCC header files and runtime libraries with the compiled
program.
The purpose of this Exception is to allow compilation of
non-GPL (including proprietary) programs to use, in this way, the
header files and runtime libraries covered by this Exception.
Definitions.
A file is an "Independent Module" if it either requires the Runtime
Library for execution after a Compilation Process, or makes use of an
interface provided by the Runtime Library, but is not otherwise based
on the Runtime Library.
Notwithstanding that, Target Code does not include data in any
format that is used as a compiler intermediate representation, or used
for producing a compiler intermediate representation.
Thus, for example,
use of source code generators and preprocessors need not be considered
part of the Compilation Process, since the Compilation Process can be
understood as starting with the output of the generators or
preprocessors.
A Compilation Process is "Eligible" if it is done using GCC, alone or
with other GPL-compatible software, or if it is done without using any
work based on GCC.
For example, using non-GPL-compatible Software to
optimize any GCC intermediate representations would not qualify as an
Eligible Compilation Process.
Grant of Additional Permission.
You have permission to propagate a work of Target Code formed by
combining the Runtime Library with Independent Modules, even if such
propagation would otherwise violate the terms of GPLv3, provided that
all Target Code was generated by Eligible Compilation Processes.
You
may then convey such a combination under terms of your choice,
consistent with the licensing of the Independent Modules.
No Weakening of GCC Copyleft.
The availability of this Exception does not imply any general
presumption that third-party software is unaffected by the copyleft
requirements of the license of GCC.
Hopefully that text is self-explanatory.
If it isn’t, you need to speak to your lawyer, or the Free Software Foundation.
The documentation shipped with the library and made available over the web, excluding the pages generated from source com-
ments, are copyrighted by the Free Software Foundation, and placed under the GNU Free Documentation License version 1.3.
There are no Front-Cover Texts, no Back-Cover Texts, and no Invariant Sections.
For documentation generated by doxygen or other automated tools via processing source code comments and markup, the original
source code license applies to the generated ﬁles.
Thus, the doxygen documents are licensed GPL.
If you plan on making copies of the documentation, please let us know.
We can probably offer suggestions.
Even the C++ Standard Library.
The Library Working Group, or LWG, is the ISO subcommittee responsible for making changes to the library.
They periodically
publish an Issues List containing problems and possible solutions.
As they reach a consensus on proposed solutions, we often
incorporate the solution.
The links are to the full version of the Issues List.
You
can read the full version online at the ISO C++ Committee homepage.
If a DR is not listed here, we may simply not have gotten to it yet; feel free to submit a patch.
Search the include and src
directories for appearances of _GLIBCXX_RESOLVE_LIB_DEFECTS for examples of style.
Note that we usually do not make
changes to the code until an issue has reached DR status.
If codecvt::do_in returns noconv there are no changes to the values in [to, to_limit)
22: Member open vs ﬂags Re-opening a ﬁle stream does not clear the state ﬂags.
The return type is the previous state of synchronization.
These members functions are declared private and are thus
inaccessible.
Specifying the correct semantics of "copying stream state" was deemed too complicated.
This DR made many widespread changes to basic_istream and basic_ostream
all of which have been implemented.
An editing glitch in the last item in the list of [27.6.1.2.3]/7.
74: Garbled text for codecvt::do_max_length The text of the standard was gibberish.
Typos gone rampant.
For associative containers where the value
type is the same as the key type, both iterator and const_iterator
are constant iterators.
Note that the DR says to replace the func-
tion with a const one; we have instead provided an overloaded version with identical contents.
Need error indication from seekp() and seekg() These functions set failbit on error now.
Yes, it can, speciﬁcally if EOF is reached while skipping
whitespace.
For conversion from a ﬂoating-point type, str.precision() is speciﬁed in the conversion
speciﬁcation.
However, no speciﬁcation is given what this constructor should do.
241: Does unique_copy() require CopyConstructible and Assignable?
Add a helper for forward_iterator/output_iterator, ﬁx
the existing one for input_iterator/output_iterator to not rely on Assignability.
This nested typedef was originally not speciﬁed.
Add global functions with two template parameters.
Bitset input operator underspeciﬁed Basically, compare the input character to is.widen(0) and is.widen(1).
Wrong new expression in [some_]allocator::construct Replace "new" with "::new".
Tweak the debug-mode checks in _Safe_iterator.
Is it undeﬁned if a function in the standard changes in parameters?
Use &value.
538: 241 again: Does unique_copy() require CopyConstructible and Assignable?
In case of input_iterator/output_iterator
rely on Assignability of input_iterator’ value_type.
In C++11 mode, remove the pow(ﬂoat,int), etc., signatures.
Implement the int -> size_t replacements.
Further incorrect uses of result_of Correctly decay types in signature of std::async.
2049: is_destructible underspeciﬁed Handle non-object types.
C++0x ambiguity problem with map::erase Add additional overloads.
2062: 2062.
Effect contradictions w/o no-throw guarantee of std::function swaps Add noexcept to swap functions.
No way to identify allocator types that always compare equal Deﬁne and use is_always_equal even for C++11.
2118: unique_ptr for array does not support cv qualiﬁcation conversion of actual argument Adjust constraints to allow
safe conversions.
2127: Move-construction with raw_storage_iterator Add assignment operator taking an rvalue.
Missing noexcept speciﬁcation in type_index Add noexcept
2145: error_category default constructor Declare a public constexpr constructor.
Validity and return type of std::abs(0u) is unclear Move all declarations to a common header and remove the
generic abs which accepted unsigned arguments.
Unnecessary copying when inserting into maps with braced-init syntax Add overloads of insert taking value_type&&
rvalues.
2399: shared_ptr’s constructor from unique_ptr should be constrained Constrain the constructor to require convert-
ibility.
Make common_type<> empty.
Inconsistency between unique_ptr and shared_ptr Create empty an shared_ptr from an empty unique_ptr.
2418: apply does not work with member pointers Use mem_fn for member pointers.
Exact-width atomic typedefs should be provided Deﬁne the typedefs.
Add raw_storage_iterator::base() member
Add the base() member function.
Allocator default construction should be allowed to throw
Make noexcept speciﬁcations conditional.
There is no way to supply an allocator for basic_string(str, pos)
Add new constructor.
Wrong value category used in scoped_allocator_adaptor::construct()
Change internal helper for uses-
allocator construction to always check using const lvalue allocators.
Add noexcept to several shared_ptr related functions
Add noexcept.
Inconsistent bit operations returning a count
Changed bit_width to return int.
Steps include getting the sources, conﬁguring and building the sources, testing, and installation.
The general outline of commands is something like:
get gcc sources
extract into gccsrcdir
mkdir gccbuilddir
cd gccbuilddir
gccsrcdir/configure --prefix=destdir --other-opts...
make
make check
make install
Each step is described in more detail in the following sections.
In particular, list of
prerequisite software needed to build the library starts with those requirements.
The same pages also list the tools you will need
if you wish to modify the source.
Additional data is given here only where it applies to libstdc++.
As of GCC the minimum version of binutils required to build libstdc++ is 2.15.90.0.1.1.
Older releases of libstdc++
do not require such a recent version, but to take full advantage of useful space-saving features and bug-ﬁxes you should use
a recent binutils whenever possible.
The conﬁgure process will automatically detect and use these features if the underlying
support is present.
To generate the API documentation from the sources you will need Doxygen, see Documentation Hacking in the appendix for
full details.
The relevant functions are provided by Glibc
and so are always available, however they can also be provided by the separate GNU libiconv library.
If GNU libiconv
is found when GCC is built (e.g., because its headers are installed in /usr/local/include) then the libstdc++.
If you do not want that run-time dependency then
you should do one of the following:
• Uninstall the libiconv headers before building GCC.
Glibc already provides iconv so you should not need libiconv
anyway.
This will build libiconv as part of building GCC and link to it statically, so there is no libiconv.so.2 dependency.
This requires the static libiconv.a library, which is
not installed by default.
You might need to reinstall libiconv using the --enable-static conﬁgure option to get the
static library.
If GCC or later on is being used on GNU/Linux, an attempt will be made to use "C" library functionality necessary
for C++ named locale support.
For GCC and later, this means that glibc 2.3 or later is required.
If the ’gnu’ locale model is being used, the following locales are used and tested in the libstdc++ testsuites.
The ﬁrst
column is the name of the locale, the second is the character set it is expected to use.
If this isn’t an issue, don’t worry about it.
If a named locale is needed, the underlying locale
information must be installed.
Note that rebuilding libstdc++ after "C" locales are installed is not necessary.
ISO-8859-1 de_DE
(repeat for each entry in the above list)
– Instructions for other operating systems solicited.


When conﬁguring libstdc++, you’ll have to conﬁgure the entire gccsrcdir directory.
Consider using the toplevel gcc conﬁguration
option --enable-languages=c++, which saves time by only building the C++ toolchain.
Here are all of the conﬁgure options speciﬁc to libstdc++.
Keep in mind that they all have opposite forms as well (enable/disable
and with/without).
The defaults are for the current development sources, which may be different than those for released versions.
This is part of the generic multilib support for building cross compilers.
As such, targets like
"powerpc-elf" will have libstdc++ built many different ways: "-msoft-ﬂoat" and not, etc.
A different libstdc++ will be built
for each of the different multilib versions.
This option is on by default.
This option is useful if you intend to use several versions of gcc in parallel.
In addition, libstdc++’s include ﬁles will
be installed in ${libdir}/gcc-lib/${target_alias}/${gcc_version}/include/g++, unless you also
specify --with-gxx-include-dir=dirname during conﬁguration.
For in-
stance, the following puts all the libstdc++ headers into a directory called "4.4-20090404" instead of the usual "c++/(version)".
At the moment, the only choice is to use ’stdio’, a generic
"C" abstraction.
The default is ’stdio’.
This option can change the library ABI.
The choices are ’ieee_1003.1-2001’ to
specify an X/Open, Standard Unix (IEEE Std.
If not explicitly speciﬁed, the conﬁgure process tries to guess the most suitable package from the choices above.
The
default is ’generic’.
On glibc-based systems of sufﬁcient vintage (2.3 and newer), ’gnu’ is automatically selected.
On
newlib-based systems (’--with_newlib=yes’) and OpenBSD, ’newlib’ is automatically selected.
On Mac OS X
’darwin’ is automatically selected.
This option can change the library ABI.
The choices are ’new’
to specify a wrapper for new, and ’malloc’ to specify a wrapper for malloc.
See Section 6.for more information.
This
option can change the library ABI.
Op-
tions are c, c_std, and c_global.
These correspond to the source directory’s include/c, include/c_std, and include/c_global,
and may also include include/c_compatibility.
The default is ’c_global’.
A full description is given in the general compiler conﬁguration
instructions.
This option can change the library ABI.
If not explicitly speciﬁed, the conﬁgure process enables
it if possible.
This option can change the library ABI.
The choice OPTION=yes checks for the availability of
the facilities in libc.
OPTION=rt also checks in librt (and, if it’s needed, links to it).
Note that linking to librt is not
always desirable because for glibc it requires linking to libpthread too, which causes all reference counting to use atomic
operations, resulting in a potentially large overhead for single-threaded programs.
OPTION=no skips the tests completely.
The default is OPTION=auto, which skips the checks and enables the features only for targets known to support them.
For
Linux targets, if clock_gettime is not used then the [time.clock] implementation will use a system call to access the
realtime and monotonic clocks, which is signiﬁcantly slower than the C library’s clock_gettime function.
By default, the debug
libraries are compiled with
CXXFLAGS=’-g3 -O0 -fno-inline’ , are installed in ${libdir}/debug, and
have the same names and versioning information as the non-debug libraries.
This option is off by default.
Note this make command, executed in the build directory, will do much the same thing, without the conﬁguration difference
and without building everything twice: make CXXFLAGS=’-g3 -O0 -fno-inline’ all
--enable-libstdcxx-debug-flags=FLAGS This option is only valid when --enable-libstdcxx-debug is also
speciﬁed, and applies to the debug builds only.
With this option, you can pass a speciﬁc string of ﬂags to the compiler to
use when building the debug versions of libstdc++.
FLAGS is a quoted string of options, like
--enable-libstdcxx-debug-flags=’-g3 -O1 -fno-inline’
--enable-cxx-flags=FLAGS With this option, you can pass a string of -f (functionality) ﬂags to the compiler to use when
building libstdc++.
This option can change the library ABI.
FLAGS is a quoted string of options, like
--enable-cxx-flags=’-fvtable-gc -fomit-frame-pointer -ansi’
Note that the ﬂags don’t necessarily have to all be -f ﬂags, as shown, but usually those are the ones that will make sense
for experimentation and conﬁgure-time overriding.
The advantage of --enable-cxx-ﬂags over setting CXXFLAGS in the ’make’ environment is that, if ﬁles are automatically
rebuilt, the same ﬂags will be used when compiling those ﬁles as well, so that everything matches.
Fun ﬂags to try might include combinations of
-fstrict-aliasing
-fno-exceptions
-ffunction-sections
-fvtable-gc
and opposite forms (-fno-) of the same.
The long long type was introduced in C99, along with many other functions for wide characters, and math
classiﬁcation macros, etc.
If enabled, all C99 functions not speciﬁed by the C++ standard will be put into namespace
__gnu_cxx, and then all these names will be injected into namespace std, so that C99 functions can be used "as if" they
were in the C++ standard (as they will eventually be in some future revision of the standard, without a doubt).
By default,
C99 support is on, assuming the conﬁgure probes ﬁnd all the necessary functions and bits necessary.
This option can
change the library ABI.
Disabling wide character specializations may be expedient for initial porting efforts, but builds only a subset of what
is required by ISO, and is not recommended.
By default, this option is on.
This option can change the library ABI.
It is provided as a GNU extension to C++98 in g++.
This ﬂag builds support for "long long" into the library (specialized templates and the like for iostreams).
This option is
on by default: if enabled, users will have to either use the new-style "C" headers by default (i.e., <cmath> not <math.h>)
or add appropriate compile-time ﬂags to all compile lines to allow "C" visibility of this feature (on GNU/Linux, the ﬂag
is -D_ISOC99_SOURCE, which is added automatically via CPLUSPLUS_CPP_SPEC’s addition of _GNU_SOURCE).
This option can change the library ABI.
Mostly useful together with shared memory allocators, see PR libstdc++/16612
for details.
They can help users discover when they break the
rules of the STL, before their programs run.
These checks are based on C++03 rules and some of them are not compatible
with correct C++11 code.
In 3.1 and later, tries to turn on symbol versioning in the shared library (if a shared li-
brary has been requested).
Values for ’style’ that are currently supported are ’gnu’, ’gnu-versioned-namespace’, ’darwin’,
’darwin-export’, and ’sun’.
Both gnu- options require that a recent version of the GNU linker be in use.
Both darwin
options are equivalent.
With no style given, the conﬁgure script will try to guess correct defaults for the host system, probe
to see if additional requirements are necessary and present for activation, and if so, will turn symbol versioning on.
This
option can change the library ABI.
In 4.2 and later, enables or disables visibility attributes.
Prior to 4.7 this option was spelled
--enable-visibility.
In 3.4 and later, tries to turn on the generation of stdc++.h.gch, a pre-compiled ﬁle including
all the standard C++ includes.
If enabled (as by default), and the compiler seems capable of passing the simple sanity
checks thrown at it, try to build stdc++.h.gch as part of the make process.
In addition, this generated ﬁle is used later on
(by appending
--include bits/stdc++.h
to CXXFLAGS) when running the testsuite.
These types include string and dependents like char_traits, the templatized IO
classes, allocator, and others.
Disabling means that implicit template generation will be used when compiling these
types.
By default, this option is on.
This option can change the library ABI.
The C++ Standard also describes a
freestanding environment, in which only a minimal set of headers are provided.
This option builds such an environment.
Note that a hosted library installs headers that still can be used in non hosted environments, as the library checks for
__STDC_HOSTED__, however, a library conﬁgured with --disable-hosted-libstdcxx will not install unusable
headers.
Those messages
cause the library to depend on the demangler and standard I/O facilities, which might be undesirable in a low-memory
environment or when standard error is not available.
This option disables those messages.
This option does not change the
library ABI.
This option
changes the library ABI.
The default is OPTION=new which sets the macro to 1, use OPTION=gcc4-compatible to set it to 0.
This
option does not change the library ABI.
The choice OPTION=atomic enables use of atomics for updates to shared_ptr reference counts.
The choice OPTION=mutex enables use of a mutex to synchronize updates to shared_ptr reference counts.
If the
compiler’s thread model is "single" then this option has no effect, as no synchronization is used for the reference counts.
The default is OPTION=auto, which checks for the availability of compiler built-ins for 2-byte and 4-byte atomic compare-
and-swap, and uses OPTION=atomic if they’re available, OPTION=mutex otherwise.
This option can change the library
ABI.
If the library is conﬁgured to use atomics and user programs are compiled using a target that doesn’t natively support

the atomic operations (e.g. the library is conﬁgured for armv7 and then code is compiled with -march=armv5t) then
the program might rely on support in libgcc to provide the atomics.
All virtual functions in the standard library will be veriﬁed at runtime.
Types impacted include
locale and iostream, and others.
Disabling means that the C++ runtime is compiled without support for vtable
veriﬁcation.
By default, this option is off.
Build libstdc++fs.a as well as the usual libstdc++ and libsupc++
libraries.
This is enabled by default on select POSIX targets where it is known to work and disabled otherwise.
The default is to allocate the pool on program startup using malloc.
With this option,
a static buffer will be provided by libstdc++ instead.
This does not change the library ABI.
NUM is the
number of simultaneous allocated exceptions to support.
This does not change the library ABI.
The li-
brary requires a copy of the tzdata.zi and leapseconds ﬁles from the IANA Time Zone Database.
The choice
OPTION=static will embed a copy of the ﬁles into the library, and use that static data when time zone information is re-
quired.
The choice OPTION=dir will use the ﬁles dir/tzdata.zi and dir/leapseconds (which must exist when
a program tries to access time zone information).
The choice OPTION=dir,static will try to use ﬁles in dir but if they
are not available the embedded static data will be used instead.
The default choice is OPTION=yes.
This is equivalent
to OPTION=dir,static with a system-speciﬁc default directory (if a suitable default for the target is known).
The choice
OPTION=no will disable all code for loading time zone info from ﬁle or from the embedded static data, which means
that only the "UTC" and "GMT" time zones are deﬁned.
Using OPTION=no results in a smaller library, so is suitable for
systems that will never need to query the time zone database.
This does not change the library ABI.
Read all of them.
Twice.
Then type: make, and congratulations, you’ve started to build.
Options that impact libstdc++
are enumerated and detailed in the table below.
The standard library conforms to the dialect of C++ speciﬁed by the -std option passed to the compiler.
By default, g++ is
equivalent to g++ -std=gnu++17 since GCC 11, and g++ -std=gnu++14 in GCC 6, 7, 8, 9, and 10, and g++ -std=gnu++98 for
older releases.
Actually, the word
"ﬁles" is a misnomer, since the contents of the headers don’t necessarily have to be in any kind of external ﬁle.
The only rule is
that when one #includes a header, the contents of that header become available, no matter how.
That said, in practice ﬁles are used.
There are two main types of include ﬁles: header ﬁles related to a speciﬁc version of the ISO C++ standard (called Standard
Headers), and all others (TS, TR1, C++ ABI, and Extensions).
Multiple dialects of standard headers are supported, corresponding to the 1998 standard as updated for 2003, the 2011 standard,
the 2014 standard, and so on.
Table 3.2 and Table 3.3 and Table 3.4 show the C++98/03 include ﬁles.
These are available in the C++98 compilation mode, i.e.
-std=c++98 or -std=gnu++98.
Unless speciﬁed otherwise below, they are also available in later modes (C++11, C++14
etc).
The following header is deprecated and might be removed from a future C++ standard.
Table 3.5 and Table 3.6 show the C++11 include ﬁles.
These are available in C++11 compilation mode, i.e. -std=c++11
or -std=gnu++11.
Including these headers in C++98/03 mode may result in compilation errors.
Unless speciﬁed otherwise
below, they are also available in later modes (C++14 etc).
Table 3.7 shows the C++14 include ﬁle.
This is available in C++14 compilation mode, i.e. -std=c++14 or -std=gnu++14.
Including this header in C++98/03 mode or C++11 will not result in compilation errors, but will not deﬁne anything.
Unless
speciﬁed otherwise below, it is also available in later modes (C++17 etc).
Table 3.8 shows the C++17 include ﬁles.
These are available in C++17 compilation mode, i.e. -std=c++17 or -std=gnu++17.
Including these headers in earlier modes will not result in compilation errors, but will not deﬁne anything.
Unless speciﬁed oth-
erwise below, they are also available in later modes (C++20 etc).
For parallel mode.
Headers that
are not supported in freestanding will emit a "This header
is not available in freestanding mode" error.
Headers that
are in the freestanding subset partially will not expose
functionality that is not part of the freestanding subset.
C++ 2020 Library Headers

Table 3.9 shows the C++2a include ﬁles.
These are available in C++2a compilation mode, i.e. -std=c++2a or -std=gnu++2a.
Including these headers in earlier modes will not result in compilation errors, but will not deﬁne anything.
The following headers have been removed in the C++2a working draft.
They are still available when using this implementation,
but in future they might start to produce warnings or errors when included in C++2a mode.
Programs that intend to be portable
should not include them.
C++ 2020 Obsolete Headers
Table 3.11, shows the additional include ﬁle deﬁne by the File System Technical Speciﬁcation, ISO/IEC TS 18822.
This is
available in C++11 and later compilation modes.
Including this header in earlier modes will not result in compilation errors, but
will not deﬁne anything.
File System TS Header
Table 3.12, shows the additional include ﬁles deﬁne by the C++ Extensions for Library Fundamentals Technical Speciﬁcation,
ISO/IEC TS 19568.
These are available in C++14 and later compilation modes.
Including these headers in earlier modes will
not result in compilation errors, but will not deﬁne anything.
In addition, TR1 includes as:
Decimal ﬂoating-point arithmetic is available if the C++ compiler supports scalar decimal ﬂoating-point types deﬁned via
__attribute__((mode(SD|DD|LD))).
Also included are ﬁles for the C++ ABI interface:
And a large variety of extensions.
First, mixing different dialects of the standard headers is not possible.
It’s an all-or-nothing affair.
C++ ABI Headers
ext/algorithm
ext/atomicity.
To use the entities in <array>, the C++11 compilation mode must be used, which implies the C++11
functionality (and deprecations) in <functional> will be present.
Second, the other headers can be included with either dialect of the standard headers, although features and types speciﬁc to
C++11 are still only enabled when in C++11 compilation mode.
So, to use rvalue references with __gnu_cxx::vstring, or
to use the debug-mode versions of std::unordered_map, one must use the std=gnu++11 compiler ﬂag.
A special case of the second rule is the mixing of TR1 and C++11 facilities.
It is possible (although not especially prudent) to
include both the TR1 version and the C++11 version of header in the same translation unit:
#include <tr1/type_traits>
#include <type_traits>
Several parts of C++11 diverge quite substantially from TR1 predecessors.
On the other hand, including the
C++-style header (<cmath>) guarantees that the entities will be found in namespace std and perhaps in the global namespace.
Usage of C++-style headers is recommended, as then C-linkage names can be disambiguated by explicit qualiﬁcation, such as by
std::abort.
In addition, the C++-style headers can use function overloading to provide a simpler interface to certain families
of C-functions.
For instance in <cmath>, the function std::sin has overloads for all the builtin ﬂoating-point types.
This
means that std::sin can be used uniformly, instead of a combination of std::sinf, std::sin, and std::sinl.
They can be used to precompile the standard headers and extensions into
binary ﬁles that may then be used to speed up compilations that use these headers.
Actual content varies depending on language dialect.
To construct a .gch ﬁle from one of these base header ﬁles, ﬁrst ﬁnd the include directory for the compiler.
Then, create a precompiled header ﬁle with the same ﬂags that will be used to compile other projects.
How to use the resulting ﬁle.
Detailed information about creating precompiled header ﬁles can be found in the GCC documentation.
Furthermore, all pre-processor macros, switches, and conﬁguration options are gathered in the ﬁle c++config.h, which is
generated during the libstdc++ conﬁguration and build process.
This ﬁle is then included when needed by ﬁles part of the public
libstdc++ API, like <ios>.
Most of these macros should not be used by consumers of libstdc++, and are reserved for internal
implementation use.
These macros cannot be redeﬁned.
A select handful of macros control libstdc++ extensions and extra features, or provide versioning information for the API.
Only
those macros listed below are offered for consideration by the general public.
The major release number for libstdc++.
This macro is deﬁned to the GCC major version that the
libstdc++ headers belong to, as an integer constant.
When compiling with GCC it has the same value as GCC’s pre-deﬁned
macro __GNUC__.
This macro can be used when libstdc++ is used with a non-GNU compiler where __GNUC__ is not
deﬁned, or has a different value that doesn’t correspond to the libstdc++ version.
This macro ﬁrst appeared in the GCC 7.1
release and is not deﬁned for GCC 6.x or older releases.
The revision date of the libstdc++ source code, in compressed ISO date format, as an unsigned long.
For notes
about using this macro and details on the value of this macro for a particular release, please consult the ABI History
appendix.
Below are the macros which users may change with #deﬁne/#undef or with -D/-U compiler ﬂags.
The default state of the symbol
is listed.
ABI-changing means that changing from the default value may mean changing the ABI of compiled code.
In other words, these
choices control code which has already been compiled (i.e., in a binary such as libstdc++.a/.so).
If you explicitly #deﬁne or
#undef these macros, the headers may see different code paths, but the libraries which you link against will not.
Experimenting
with different values with the expectation of consistent linkage requires changing the conﬁg headers before building/installing
the library.
Not conﬁgurable.
ABI-changing.
Turning this off removes
older ARM-style iostreams code, and other anachronisms from the API.
This macro is dependent on the version of the
standard being tracked, and as a result may give different results for different -std options.
This may be useful in
updating old C++ code which no longer meet the requirements of the language, or for checking current code against new
language standards.
Deﬁned to the value 1 by default.
Conﬁgurable via --disable-libstdcxx-dual-abi
and/or --with-default-libstdcxx-abi.
ABI-changing.
When deﬁned to a non-zero value the library headers
will use the new C++11-conforming ABI introduced in GCC 5, rather than the older ABI introduced in GCC 3.4.
This
changes the deﬁnition of several class templates, including std:string, std::list and some locale facets.
For more
details see Dual ABI.
Undeﬁned by default.
Conﬁgurable via --enable-concept-checks.
When deﬁned,
performs compile-time checking on certain template instantiations to detect violations of the requirements of the standard.
This macro has no effect for freestanding implementations.
Undeﬁned by default.
When deﬁned, enables extra error checking in the form of precondition
assertions, such as bounds checking in strings and null pointer checks when dereferencing smart pointers.
Undeﬁned by default.
When deﬁned, compiles user code using the debug mode.
When deﬁned, _GLIBCXX_ASSE
is deﬁned automatically, so all the assertions enabled by that macro are also enabled in debug mode.
Undeﬁned by default.
When deﬁned while compiling with the debug mode, makes the debug
mode extremely picky by making the use of libstdc++ extensions and libstdc++-speciﬁc behavior into errors.
Undeﬁned by default.
Considered only if libstdc++ has been conﬁgured with --enable-libstd
and if _GLIBCXX_DEBUG is deﬁned.
When deﬁned display backtraces on debug mode assertions.
Undeﬁned by default.
When deﬁned, compiles user code using the parallel mode.
Undeﬁned by default, but when any parallel mode header is included this macro will
be deﬁned to a non-zero value if _GLIBCXX_ASSERTIONS has a non-zero value, otherwise to zero.
Undeﬁned by default.
When deﬁned to a non-zero integer constant, enables sup-
port for ISO/IEC 29124 Special Math Functions.
Undeﬁned by default.
When deﬁned, std::vector operations will be annotated so
that AddressSanitizer can detect invalid accesses to the unused capacity of a std::vector.
These annotations are
only enabled for std::vector<T, std::allocator<T>> and only when std::allocator is derived from
new_allocator or malloc_allocator.
The annotations must be present on all vector operations or none, so this macro must
be deﬁned to the same value for all translation units that create, destroy or modify vectors.
In the GCC 5.1 release libstdc++ introduced a new library ABI that includes new implementations of std::string and
std::list.
These changes were necessary to conform to the 2011 C++ standard which forbids Copy-On-Write strings and
requires lists to keep track of their size.
In order to maintain backwards compatibility for existing code linked to libstdc++ the library’s soname has not changed and the
old implementations are still supported in parallel with the new ones.
This is achieved by deﬁning the new implementations
in an inline namespace so they have different names for linkage purposes, e.g. the new version of std::list<int> is
actually deﬁned as std::__cxx11::list<int>.
Because the symbols for the new implementations have different names
the deﬁnitions for both versions can be present in the same library.
The _GLIBCXX_USE_CXX11_ABI macro (see Macros) controls whether the declarations in the library headers use the old or
new ABI.
So the decision of which ABI to use can be made separately for each source ﬁle being compiled.
Using the default
conﬁguration options for GCC the default value of the macro is 1 which causes the new ABI to be active, so to use the old ABI
you must explicitly deﬁne the macro to 0 before including any library headers.
Although the changes were made for C++11 conformance, the choice of ABI to use is independent of the -std option used to
compile your code, i.e. for a given GCC build the default value of the _GLIBCXX_USE_CXX11_ABI macro is the same for
all dialects.
This ensures that the -std does not change the ABI, so that it is straightforward to link C++03 and C++11 code
together.
Because std::string is used extensively throughout the library a number of other types are also deﬁned twice, including the
stringstream classes and several facets used by std::locale.
The standard facets which are always installed in a locale may
be present twice, with both ABIs, to ensure that code like std::use_facet<std::time_get<char>>(locale); will
work correctly for both std::time_get and std::__cxx11::time_get (even if a user-deﬁned facet that derives from
one or other version of time_get is installed in the locale).
Although the standard exception types deﬁned in <stdexcept> use strings, most are not deﬁned twice, so that a std::out_of_ran
exception thrown in one ﬁle can always be caught by a suitable handler in another ﬁle, even if the two ﬁles are compiled with
different ABIs.
One exception type does change when using the new ABI, namely std::ios_base::failure.
This is necessary because
the 2011 standard changed its base class from std::exception to std::system_error, which causes its layout to
change.
Exceptions due to iostream errors are thrown by a function inside libstdc++.so, so whether the thrown exception
uses the old std::ios_base::failure type or the new one depends on the ABI that was active when libstdc++.so
was built, not the ABI active in the user code that is using iostreams.
This means that for a given build of GCC the type thrown
is ﬁxed.
In current releases the library throws a special type that can be caught by handlers for either the old or new type, but
for GCC 7.1, 7.2 and 7.3 the library throws the new std::ios_base::failure type, and for GCC 5.x and 6.x the library
throws the old type.
Catch handlers of type std::ios_base::failure will only catch the exceptions if using a newer
release, or if the handler is compiled with the same ABI as the type thrown by the library.
Handlers for std::exception will
always catch iostreams exceptions, because the old and new type both inherit from std::exception.
This commonly happens when linking to a third-party library that was compiled
with an older version of GCC.
If the third-party library cannot be rebuilt with the new ABI then you will need to recompile your
code with the old ABI.
Not all uses of the new ABI will cause changes in symbol names, for example a class with a std::string member variable
will have the same mangled name whether compiled with the old or new ABI.
In order to detect such problems the new types and
functions are annotated with the abi_tag attribute, allowing the compiler to warn about potential ABI incompatibilities in code
using them.
Those warnings can be enabled with the -Wabi-tag option.
This includes namespaces nested
within namespace std, such as namespace std::chrono.
• abi
Speciﬁed by the C++ ABI.
This ABI speciﬁes a number of type and function APIs supplemental to those required by the ISO
C++ Standard, but necessary for interoperability.
The library uses a number of inline namespaces as implementation details that are not intended for users to refer to directly, these
include std::__detail, std::__cxx11 and std::_V2.
A complete list of implementation namespaces (including namespace contents) is available in the generated source documenta-
tion.
Thus, in order to use these types
or functions, one must do one of two things:
• put a kind of using-declaration in your source (either using namespace std; or i.e. using std::string;) This
approach works well for individual source ﬁles, but should not be used in a global context, like header ﬁles.
This is considered an advantage over dumping everything in the global namespace, as then name look-up can be
explicitly enabled or disabled as above, symbols are consistently mangled without repetitive naming preﬁxes or macros, etc.
For instance, consider a project that deﬁnes most of its classes in namespace gtk.
It is possible to adapt namespace gtk
to namespace std by using a C++-feature called namespace composition.
This is what happens if a using-declaration is put
into a namespace-deﬁnition: the imported symbol(s) gets imported into the currently active namespace(s).
For example:
namespace ;
}
In this example, std::string gets imported into namespace gtk.
The result is that use of std::string inside names-
pace gtk can just use string, without the explicit qualiﬁcation.
As an added bonus, std::string does not get imported
into the global namespace.
Additionally, a more elaborate arrangement can be made for backwards compatibility and porta-
bility, whereby the using-declarations can wrapped in macros that are set based on autoconf-tests to either "" or i.e. using
std::string; (depending on whether the system has libstdc++ in std:: or not).
This is a minimal conﬁguration, with only partial support for the standard library.
In addition, throw in
• cxxabi.h.
In the C++11 dialect add
• initializer_list
• type_traits
As of GCC 13, libstdc++ implements P1642, which brings in many more headers, as well a quite a few ones not covered by the
paper.
In general, if a feature does not require traditionally libc-provided facilities, or dynamic memory allocation, it’s enabled
in the freestanding subset.
In addition, if only a subset of a header requires such features, it is partially included.
Some examples
include:
• string_view
• tuple
• bitset
Currently, this subset includes all of the iterator APIs (including the ranges APIs) that do not involve streams, the entire C++
algorithms library, excluding parallel algorithms, and a large part of the utilities library.
This is on top of the headers included in
the lists above.
If you’re using a libstdc++ conﬁgured for hosted environments, and would like to not involve the libraries libstdc++ would
depend on in your programs, you will need to use gcc to link your application with only libsupc++.a, like so:
gcc -ffreestanding foo.cc -lsupc++
If you conﬁgured libstdc++ with --disable-hosted-libstdcxx, however, you can use the normal g++ command to link,
as this conﬁguration provides a (nearly) empty libstdc++.a.
But if
building or using a shared library (libstdc++.so), then additional location information will need to be provided.
But how?
A quick read of the relevant part of the GCC manual, Compiling C++ Programs, speciﬁes linking against a C++ library.
More
details from the GCC FAQ, which states GCC does not, by default, specify a location so that the dynamic linker can ﬁnd dynamic
libraries at runtime.
Users will have to provide this information.
Methods vary for different platforms and different styles, and are printed to the screen during installation.
At runtime set LD_LIBRARY_PATH in your environment correctly, so that the shared library for libstdc++ can be found and
loaded.
Be certain that you understand all of the other implications and behavior of LD_LIBRARY_PATH ﬁrst.
Compile the path to ﬁnd the library at runtime into the program.
This can be done by passing certain options to g++, which
will in turn pass them on to the linker.
The exact format of the options is dependent on which linker you use:
– GNU ld (default on GNU/Linux): -Wl,-rpath,destdir/lib
– Solaris ld: -Wl,-Rdestdir/lib
• Some linkers allow you to specify the path to the library by setting LD_RUN_PATH in your environment when linking.
On some platforms the system administrator can conﬁgure the dynamic linker to always look for libraries in destdir/lib,
for example by using the ldconﬁg utility on GNU/Linux or the crle utility on Solaris.
This is a system-wide change which can
make the system unusable so if you are unsure then use one of the other methods described above.
Use the ldd utility on the linked executable to show which libstdc++.so library the system will get at runtime.
A libstdc++.la ﬁle is also installed, for use with Libtool.
If you use Libtool to create your executables, these details are
taken care of for you.
Because this is an experimental library extension, not part of the C++ standard, it is implemented in a separate library, libstdc+
+fs.a, and there is no shared library for it.
To use the library you should include <experimental/filesystem> and link
with -lstdc++fs.
The library implementation is incomplete on non-POSIX platforms, speciﬁcally Windows is only partially
supported.
GCC 13 includes an implementation of the C++ Contracts library deﬁned by P1429R3.
Because this is an experimental extension,
not part of the C++ standard, it is implemented in a separate library, libstdc++exp.a, and there is no shared library for it.
To use the library you should include <experimental/contract> and link with -lstdc++exp.
Due to the experimental nature of these libraries the usual guarantees about ABI stability and backwards compatibility do not
apply to them.
There is no guarantee that the components in any <experimental/xxx> header will remain compatible
between different GCC releases.
This information is GCC-speciﬁc since the C++ standard does not address matters of multithreaded applications.
As long as your ﬁnal
application is actually single-threaded, then it should be safe to mix user code built with a thread model of single with a libstdc++
and other C++ libraries built with another thread model useful on the platform.
Other mixes may or may not work but are not
considered supported.
When you link a multithreaded application, you will probably need to add a library or ﬂag to g++.
This is a very non-standardized
area of GCC across ports.
Some ports support a special ﬂag (the spelling isn’t even standardized yet) to add all required macros to
a compilation (if any such ﬂags are required then you must provide the ﬂag for all compilations not just linking) and link-library
additions and/or replacements at link time.
The documentation is weak.
On several targets (including GNU/Linux, Solaris and
various BSDs) -pthread is honored.
Some other ports use other switches.
This is not well documented anywhere other than in
"gcc -dumpspecs" (look at the ’lib’ and ’cpp’ entries).
Some uses of std::atomic also require linking to libatomic.
In the terms of the 2011 C++ standard a thread-safe program is one which does not perform any conﬂicting non-atomic operations
on memory locations and so does not contain any data races.
The standard places requirements on the library to ensure that no
data races are caused by the library itself or by programs which use the library correctly (as described below).
The C++11
memory model and library requirements are a more formal version of the SGI STL deﬁnition of thread safety, which the library
used prior to the 2011 standard.
The compiler in use reports a thread model other than ’single’.
This can be tested via output from gcc -v.
Multi-thread
capable versions of gcc output something like this:

%gcc -v
Using built-in specs.
...
Thread model: posix
gcc version 20070925 (Red Hat 4.1.2-33)
Look for "Thread model" lines that aren’t equal to "single.
Examples of this include -pthread and
-march=native, although speciﬁcs vary depending on the host environment.
See Command Options and Machine De-
pendent Options.
An implementation of the atomicity.h functions exists for the architecture in question.
See the internals documentation
for more details.
The user code must guard against concurrent function calls which access any particular library object’s state when one or more
of those accesses modiﬁes the state.
An object will be modiﬁed by invoking a non-const member function on it or passing it as a
non-const argument to a library function.
An object will not be modiﬁed by invoking a const member function on it or passing it
to a function as a pointer- or reference-to-const.
Typically, the application programmer may infer what object locks must be held
based on the objects referenced in a function call and whether the objects are accessed as const or non-const.
Without getting
into great detail, here is an example which requires user-level locks:
library_class_a shared_object_a;
void thread_main () {
library_class_b *object_b = new library_class_b;
shared_object_a.add_b (object_b);
// must hold lock for shared_object_a
shared_object_a.mutate ();
// must hold lock for shared_object_a
}
// Multiple copies of thread_main() are started in independent threads.
Unless otherwise documented,
the only exceptions to these rules are atomic operations on the types in <atomic> and lock/unlock operations on the standard
mutex types in <mutex>.
These atomic operations allow concurrent accesses to the same object without introducing data races.
The following member functions of standard containers can be considered to be const for the purposes of avoiding data races:
begin, end, rbegin, rend, front, back, data, find, lower_bound, upper_bound, equal_range, at and,
except in associative or unordered associative containers, operator[].
In other words, although they are non-const so that
they can return mutable iterators, those member functions will not modify the container.
Accessing an iterator might cause a
non-modifying access to the container the iterator refers to (for example incrementing a list iterator must access the pointers
between nodes, which are part of the container and so conﬂict with other accesses to the container).
Programs which follow the rules above will not encounter data races in library code, even when using library types which share
state between distinct objects.
Please read carefully, and bear with me.
Nearly all decisions
dealing with actual input and output must be made in __basic_file.
A generic locking mechanism is somewhat in place at the ﬁlebuf layer, but is not used in the current code.
Providing locking at
any higher level is akin to providing locking within containers, and is not done for the same reasons (see the links above).
We
do no locking ourselves, but simply pass through to calls to fopen, fwrite, and so forth.
Some are by default, some are not; many offer multiple implementations of the C library with varying tradeoffs of
threadsafety and efﬁciency.
You, the programmer, are always required to take care with multiple threads.
POSIX-conforming C libraries (e.g,
on Solaris and GNU/Linux) have an internal mutex to serialize operations on FILE*s.
So, if your platform’s C library is threadsafe, then your fstream I/O operations will be threadsafe at the lowest level.
For
higher-level operations, such as manipulating the data contained in the stream formatting classes (e.g., setting up callbacks inside
an std::ofstream), you need to guard such accesses like any other critical shared resource.
This is disabled by default, and in fact will not currently work
due to other issues.
It will be revisited, however.
The libio code is a subset of the guts of the GNU libc (glibc) I/O implementation.
When libio is in use, the __basic_file
type is basically derived from FILE.
The result is that there is no "layer" of C stdio to go
through; the ﬁlebuf makes calls directly into the same functions used to implement fread, fwrite, and so forth, using internal
data structures.
Fast but frightening.
This requires pulling in large chunks of glibc, such as a pthreads implementation, and is
one of the issues preventing widespread use of libio as the libstdc++ cstdio implementation.
But we plan to make this work, at least as an option if not a future default.
Platforms running a copy of glibc with a recent-enough
version will see calls from libstdc++ directly into the glibc already installed.
For other platforms, a copy of the libio subsection
will be built and included in libstdc++.
You could easily write one to perform your own forms of locking, to
solve your "interesting" problems.
All
information in this section is current as of the gcc 3.0 release and all later point releases.
Although earlier gcc releases had a
different approach to threading conﬁguration and proper compilation, the basic code design rules presented here were similar.
For information on all other aspects of multithreading as it relates to libstdc++, including details on the proper compilation of
threaded code (and compatibility between threaded and non-threaded code), see Chapter 17.
Two excellent pages to read when working with the Standard C++ containers and threads are SGI’s https://web.archive.org/-
web/20171225062613/http://www.sgi.com/tech/stl/thread_safety.html and SGI’s https://web.archive.org/web/20171225062613/-
http://www.sgi.com/tech/stl/Allocators.html.
However, please ignore all discussions about the user-level conﬁguration of the lock implementation inside the STL container-
memory allocator on those pages.
For the sake of this discussion, libstdc++ conﬁgures the SGI STL implementation, not you.
This is quite different from how gcc pre-3.0 worked.
In particular, past advice was for people using g++ to explicitly deﬁne
_PTHREADS or other macros or port-speciﬁc compilation options on the command line to get a thread-safe STL.
This is no
longer required for any port and should no longer be done unless you really know what you are doing and assume all responsi-
bility.
Since the container implementation of libstdc++ uses the SGI code, we use the same deﬁnition of thread safety as SGI when
discussing design.
A key point that beginners may miss is the fourth major paragraph of the ﬁrst page mentioned above (For
most clients...), which points out that locking must nearly always be done outside the container, by client code (that’d be you,
not us).
There is a notable exceptions to this rule.
Allocators called while a container or element is constructed uses an internal
lock obtained and released solely within libstdc++ code (in fact, this is the reason STL requires any knowledge of the thread
conﬁguration).
For implementing a container which does its own locking, it is trivial to provide a wrapper class which obtains the lock (as SGI
suggests), performs the container operation, and then releases the lock.
This could be templatized to a certain extent, on the
underlying container and/or a locking mechanism.
Trying to provide a catch-all general template solution would probably be
more trouble than it’s worth.
The library implementation may be conﬁgured to use the high-speed caching memory allocator, which complicates thread safety
issues.
For all details about how to globally override this at application run-time see here.
Also useful are details on allocator
options and capabilities.
These are very powerful constructs, and require some thought when applied to the standard library in order to yield components
that work efﬁciently while cleaning up resources when unexpectedly killed via exceptional circumstances.
Two general topics of discussion follow: exception neutrality and exception safety.
Please note that using exceptions in combination with templates imposes an additional requirement for exception safety.
Instan-
tiating types are required to have destructors that do no throw.
Using the layered approach from Abrahams, can classify library components as providing set levels of safety.
These will be
called exception guarantees, and can be divided into three categories.
Don’t throw.
As speciﬁed in general container requirements.
Applicable to container and string classes.
Member functions erase, pop_back, pop_front, swap, clear.
And iterator copy constructor and assignment operator.
Two.
Don’t leak resources when exceptions are thrown.
This is also referred to as the “basic” exception safety guarantee.
This applicable throughout the standard library.
Three.
Commit-or-rollback semantics.
This is referred to as “strong” exception safety guarantee.
As speciﬁed in general container requirements.
Applicable to container and string classes.
Member functions insert of a single element, push_back, push_front, and rehash.
In practice, this means propagat-
ing exceptions should not be swallowed in gratuitous catch(...) blocks.
Instead, matching try and catch blocks should
have speciﬁc catch handlers and allow un-handed exception objects to propagate.
If a terminating catch(...) blocks exist
then it should end with a throw to re-throw the current exception.
Why do this?
Instead of dealing with an error immediately, one can allow the exception to propagate up until sufﬁcient context is available and
the choice of exiting or retrying can be made in an informed manner.
Unfortunately, this tends to be more of a guideline than a strict rule as applied to the standard library.
As such, the following is a
list of known problem areas where exceptions are not propagated.
All formatted input in basic_istream or formatted output in basic_ostream can be conﬁgured to swallow exceptions
when exceptions is set to ignore ios_base::badbit.
Functions that have been registered with ios_base::register_callback swallow all exceptions when called as part
of a callback event.
When closing the underlying ﬁle, basic_filebuf::close will swallow (non-cancellation) exceptions thrown and return
NULL.
Libstdc++ will try to use malloc to obtain storage, but provides an emergency buffer to be used if malloc fails, as
described by the Itanium exception handling ABI.
Contrary to the ABI, the libstdc++ emergency buffer is not always 64kB, and does not always allocate 1kB chunks.
The
buffer is used as a pool for variable-sized allocations, so that it doesn’t waste space for smaller exception objects such as
std::bad_alloc.
The total size of the buffer is scaled appropriately for the target.
Speciﬁcally it depends on sizeof(void*),
so that a 64-bit system uses a larger pool than a 32-bit system.
This is done because for 32-bit systems the exception objects (and
the exception header) require less space, and core counts and thread counts are typically lower as well.
By default, libstdc++ will use malloc to allocate the buffer on program startup.
Conﬁguring libstdc++ with the --enable-libstdcx
option will make it use a static buffer instead of using malloc.
The buffer size is chosen automatically, but can be overridden by conﬁguring with --with-libstdcxx-eh-pool-obj-count=NU
where NUM is the number of simultaneous allocations that should be supported.
The size of the pool will be sufﬁcient for NUM
exceptions of 6 * sizeof(void*) bytes, plus another NUM exceptions captured in std::exception_ptr and rethrown
using std::rethrow_exception.
The buffer size determined by the obj-count value applies whether the buffer is reserved
as static storage or is allocated dynamically.
Setting obj-count to zero will disable the pool, so that no emergency buffer is
present.
For a dynamic buffer, the default size can also be changed at runtime, per-process, via the GLIBCXX_TUNABLES environ-
ment variable.
The GLIBCXX_TUNABLES environment variable should be a string of colon-separated name=value pairs.
The number of exception objects to provide space for in the pool.
The value must be
a non-negative integer and has the same meaning as the --with-libstdcxx-eh-pool-obj-count option for
configure.
The expected size of exception objects that the pool might get used for.
The value must be a
positive integer, and is measured in units of sizeof(void*).
The default value is 6 which is large enough to store any
exception type thrown by libstdc++.
Exceptions larger than this can still be allocated from the pool, but larger exceptions
will exhaust the pool more rapidly.
As such, considerable care is used by both
language implementer and designers to make sure unused features not impose hidden or unexpected costs.
The GNU system
tries to be as ﬂexible and as conﬁgurable as possible.
So, it should come as no surprise that GNU C++ provides an optional
language extension, spelled -fno-exceptions, as a way to excise the implicitly generated magic necessary to support try
and catch blocks and thrown objects.
Before detailing the library support for -fno-exceptions, ﬁrst a passing note on the things lost when this ﬂag is used: it
will break exceptions trying to pass through code compiled with -fno-exceptions whether or not that code has any try or
catch constructs.
If you might have some code that throws, you shouldn’t use -fno-exceptions.
If you have some code
that uses try or catch, you shouldn’t use -fno-exceptions.
And what it to be gained, tinkering in the back alleys with a language like this?
Exception handling overhead can be measured
in the size of the executable binary, and varies with the capabilities of the underlying operating system and speciﬁc conﬁguration
of the C++ compiler.
On recent hardware with GNU system software of the same age, the combined code and data size overhead
for enabling exception handling is around 7%.
Of course, if code size is of singular concern than using the appropriate optimizer
setting with exception handling enabled (ie, -Os -fexceptions) may save up to twice that, and preserve error checking.
Hell bent, we race down the slippery track, knowing the brakes are a little soft and that the right front wheel has a tendency
to wobble at speed.
Go on: detail the standard library support for -fno-exceptions.
In sum, valid C++ code with exception handling is transformed into a dialect without exception handling.
In detailed steps: all use
of the C++ keywords try, catch, and throw in the standard library have been permanently replaced with the pre-processor
controlled equivalents spelled __try, __catch, and __throw_exception_again.
They are deﬁned as follows.
An
example:
#if __cpp_exceptions
void __throw_bad_exception(void)
{ throw bad_exception(); }
#else
void __throw_bad_exception(void)
{ abort(); }
#endif
The last language feature needing to be transformed by -fno-exceptions is treatment of exception speciﬁcations on member
functions.
Fortunately, the compiler deals with this by ignoring exception speciﬁcations and so no alternate source markup is
needed.
By using this combination of language re-speciﬁcation by the compiler, and the pre-processor tricks and the functional indirection
layer for thrown exception objects by the library, libstdc++ ﬁles can be compiled with -fno-exceptions.
User code that uses C++ keywords like throw, try, and catch will produce errors even if the user code has included libstdc++
headers and is using constructs like basic_iostream.
Even though the standard library has been transformed, user code may
need modiﬁcation.
User code that attempts or expects to do error checking on standard library components compiled with
exception handling disabled should be evaluated and potentially made conditional.
Some issues remain with this approach (see bugzilla entry 25191).
Code paths are not equivalent, in particular catch blocks
are not evaluated.
Also problematic are throw expressions expecting a user-deﬁned throw handler.
Known problem areas in the
standard library include using an instance of basic_istream with exceptions set to speciﬁc ios_base::iostate conditions,
or cascading catch blocks that dispatch error handling or recovery efforts based on the type of exception object thrown.
Oh, and by the way: none of this hackery is at all special.
Support
continues to evolve and may change in the future.
Similar and even additional techniques are used in other C++ libraries and
compilers.
C++ hackers with a bent for language and control-ﬂow purity have been successfully consoled by grizzled C veterans lamenting
the substitution of the C language keyword const with the ugliﬁed doppelganger __const.
This will make debugging
a C language function called as part of C++-induced stack unwinding possible.
In particular, unwinding into a frame with no exception handling data will cause a runtime abort.
If the unwinder runs out of
unwind info before it ﬁnds a handler, std::terminate() is called.
Please note that most development environments should take care of getting these details right.
For GNU systems, all appropriate
parts of the GNU C library are already compiled with -fexceptions.
Cancellation points are functions deﬁned by POSIX as worthy of special treatment.
The standard library may use some of these
functions to implement parts of the ISO C++ standard or depend on them for extensions.
Of note:
nanosleep, read, write, open, close, and wait.
The parts of libstdc++ that use C library functions marked as cancellation points should take pains to be exception neutral.
Failing
this, catch blocks have been augmented to show that the POSIX cancellation object is in ﬂight.
This augmentation adds a catch block for __cxxabiv1::__forced_unwind, which is the object representing the POSIX
cancellation object.
Like so:
catch(const __cxxabiv1::__forced_unwind&)
{
this->_M_setstate(ios_base::badbit);
throw;
}
catch(...)
{ this->_M_setstate(ios_base::badbit); }

[1] System Interface Deﬁnitions, Issue 7 (IEEE Std.
The Open Group/The Institute of Electrical and Electronics Engineers, Inc. .
Here are some of them.
The default optimizations and debug ﬂags for a libstdc++ build are -g -O2.
However, both debug and optimization ﬂags
can be varied to change debugging characteristics.
For instance, turning off all optimization via the -g -O0 -fno-inline
ﬂags will disable inlining and optimizations, and add debugging information, so that stepping through all functions, (including
inlined constructors and destructors) is possible.
In addition, -fno-eliminate-unused-debug-types can be used when
additional debug information, such as nested class info, is desired.
Expressiveness can be enhanced by ﬂags like -g3.
The default debug information for a particular platform can be
identiﬁed via the value set by the PREFERRED_DEBUGGING_TYPE macro in the GCC sources.
Many other options are available: please see "Options for Debugging Your Program" in Using the GNU Compiler Collection
(GCC) for a complete list.
Both the normal build and the debug build will persist, without having to specify CXXFLAGS, and the debug library will be
installed in a separate directory tree, in (prefix)/lib/debug.
For more information, look at the conﬁguration section.
A second approach is to use the conﬁguration ﬂags
make CXXFLAGS=’-g3 -fno-inline -O0’ all
This quick and dirty approach is often sufﬁcient for quick debugging tasks, when you cannot or don’t want to recompile your
application to use the debug mode.
There are also various third party memory tracing and debug utilities that can be used to provide detailed memory allocation
information about C++ code.
An exhaustive list of tools is not going to be attempted, but includes mtrace, valgrind,
mudflap (no longer supported since GCC 4.9.0), ElectricFence, and the non-free commercial product purify.
In addition,
libcwd, jemalloc and TCMalloc have replacements for the global new and delete operators that can track memory allocation
and deallocation and provide useful memory statistics.
For valgrind, there are some speciﬁc items to keep in mind.
First of all, use a version of valgrind that will work with current
GNU C++ tools: the ﬁrst that can do this is valgrind 1.0.4, but later versions should work better.
Second, using an unoptimized
build might avoid confusing valgrind.
Third, it may be necessary to force deallocation in other libraries as well, namely the "C" library.
On GNU/Linux, this can be
accomplished with the appropriate use of the __cxa_atexit or atexit functions.
Prior to GCC the default was
to use a pooling allocator, pool_allocator, which is still available as the optional __pool_alloc extension.
Another
optional extension, __mt_alloc, is a high-performance pool allocator.
In a suspect executable these pooling allocators can give the mistaken impression that memory is being leaked, when in reality
the memory "leak" is a pool being used by the library’s allocator and is reclaimed after program termination.
If you’re using memory debugging tools on a program that uses one of these pooling allocators, you can set the environment
variable GLIBCXX_FORCE_NEW to keep extraneous pool allocation noise from cluttering debug information.
For more details,
see the mt allocator documentation and look speciﬁcally for GLIBCXX_FORCE_NEW.
Two annotation macros are used to explain low-level synchronization to race detectors: _GLIBCXX_SYNCHRONIZATION_HAPPENS_
and
_GLIBCXX_SYNCHRONIZATION_HAPPENS_AFTER().
By default, these macros are deﬁned empty -- anyone who
wants to use a race detector needs to redeﬁne them to call an appropriate API.
Since these macros are empty by default when the
library is built, redeﬁning them will only affect inline functions and template instantiations which are compiled in user code.
This
allows annotation of templates such as shared_ptr, but not code which is only instantiated in the library.
Code which is only
instantiated in the library needs to be recompiled with the annotation macros deﬁned.
That can be done by rebuilding the entire
libstdc++.so ﬁle but a simpler alternative exists for ELF platforms such as GNU/Linux, because ELF symbol interposition
allows symbols deﬁned in the shared library to be overridden by symbols with the same name that appear earlier in the runtime
search path.
This means you only need to recompile the functions that are affected by the annotation macros, which can be done
by recompiling individual ﬁles.
Annotating std::string and std::wstring reference counting can be done by disabling
extern templates (by deﬁning _GLIBCXX_EXTERN_TEMPLATE=-1) or by rebuilding the src/string-inst.cc ﬁle.
An-
notating the remaining atomic operations (at the time of writing these are in ios_base::Init::~Init, locale::_Impl,
locale::facet and thread::_M_start_thread) requires rebuilding the relevant source ﬁles.
The approach described above is known to work with the following race detection tools: DRD, Helgrind, and ThreadSanitizer
(this refers to ThreadSanitizer v1, not the new "tsan" feature built-in to GCC itself).
With DRD, Helgrind and ThreadSanitizer you will need to deﬁne the macros like this:
#define _GLIBCXX_SYNCHRONIZATION_HAPPENS_BEFORE(A) ANNOTATE_HAPPENS_BEFORE(A)
#define _GLIBCXX_SYNCHRONIZATION_HAPPENS_AFTER(A)
ANNOTATE_HAPPENS_AFTER(A)
Refer to the documentation of each particular tool for details.
Also recommended:
the other parts of this manual.
These settings can either be switched on in at the GDB command line, or put into a .gdbinit ﬁle to establish default debugging
characteristics, like so:
set print pretty on
set print object on
set print static-members on
set print vtbl on
set print demangle on
set demangle-style gnu-v3
Starting with version 7.0, GDB includes support for writing pretty-printers in Python.
Pretty printers for containers and other
classes are distributed with GCC from version and should be installed alongside the libstdc++ shared library ﬁles and found
automatically by GDB.
Depending where libstdc++ is installed, GDB might refuse to auto-load the python printers and print a warning instead.
If this
happens the python printers can be enabled by following the instructions GDB gives for setting your auto-load safe-path
in your .gdbinit conﬁguration ﬁle.
Once loaded, standard library classes that the printers support should print in a more human-readable format.
To print the classes
in the old style, use the /r (raw) switch in the print command (i.e., print /r foo).
This will print the classes as if the Python
pretty-printers were not loaded.
For additional information on STL support and GDB please visit: "GDB Support for STL" in the GDB wiki.
Additionally,
in-depth documentation and discussion of the pretty printing feature can be found in "Pretty Printing" node in the GDB manual.
You can ﬁnd on-line versions of the GDB user manual in GDB’s homepage, at "GDB: The GNU Project Debugger" .
While we can’t reproduce the contents of the Standard here (you need to get your own copy from your nation’s member body;
see our homepage for help), we can mention a couple of changes in what kind of support a C++ program gets from the Standard
Library.
These types are exactly the same in either
C++ or in C.
Specializing parts of the library on these types is prohibited: instead, use a POD.
The traits classes -- fourteen in total -- are all specializations of the class template numeric_limits and deﬁned as follows:
;

The only change that might affect people is the type of NULL: while it is required to be a macro, the deﬁnition of that macro is
not allowed to be an expression with pointer type such as (void*)0, which is often used in C.
For g++, NULL is #define’d to be __null, a magic keyword extension of g++ that is slightly safer than a plain integer.
The biggest problem of #deﬁning NULL to be something like “0L” is that the compiler will view that as a long integer before it
views it as a pointer, so overloading won’t do what you expect.
Scott Meyers explains this in more detail in his book Effective Modern C++ and as a guideline to solve this problem recommends
to not overload on pointer-vs-integer types to begin with.
The C++ 2011 standard added the nullptr keyword, which is a null pointer constant of a special type, std::nullptr_t.
Values of this type can be implicitly converted to any pointer type, and cannot convert to integer types or be deduced as an integer
type.
Unless you need to be compatible with C++98/C++03 or C you should prefer to use nullptr instead of NULL.
In C++98 there are six ﬂavors each of operator new and operator delete, so make certain that you’re using the right
ones.
Here are quickie descriptions of operator new:
void* operator new(std::size_t); Single object form.
Throws std::bad_alloc on error.
This is what most
people are used to using.
Array new.
This function cannot be replaced.
This function cannot be replaced.
They are distinguished by the arguments that you pass to them, like any other overloaded function.
The six ﬂavors of operator
delete are distinguished the same way, but none of them are allowed to throw an exception under any circumstances anyhow.
The C++ 2014 revision of the standard added two additional overloads of operator delete for “sized deallocation”, allow-
ing the compiler to provide the size of the storage being freed.
The C++ 2017 standard added even more overloads of both operator new and operator delete for allocating and
deallocating storage for overaligned types.
These overloads correspond to each of the allocating forms of operator new and
operator delete but with an additional parameter of type std::align_val_t.
These new overloads are not interchangeable
with the versions without an aligment parameter, so if memory was allocated by an overload of operator new taking an
alignment parameter, then it must be decallocated by the corresponding overload of operator delete that takes an alignment
parameter.
Apart from the non-allocating forms, the default versions of the array and nothrow operator new functions will all result
in a call to either operator new(std::size_t) or operator new(std::size_t, std::align_val_t), and
similarly the default versions of the array and nothrow operator delete functions will result in a call to either operator
delete(void*) or operator delete(void*, std::align_val_t) (or the sized versions of those).
Apart from the non-allocating forms, any of these functions can be replaced by deﬁning a function with the same signature in
your program.
Replacement versions must preserve certain guarantees, such as memory obtained from a nothrow operator
new being free-able by the normal (non-nothrow) operator delete, and the sized and unsized forms of operator
delete being interchangeable (because it’s unspeciﬁed whether the compiler calls the sized delete instead of the normal
one).
The simplest way to meet the guarantees is to only replace the ordinary operator new(size_t) and operator
delete(void*) and operator delete(void*, std::size_t) functions, and the replaced versions will be used
by all of operator new(size_t, nothrow_t), operator new[](size_t) and operator new[](size_t,
nothrow_t) and the corresponding operator delete functions.
To support types with extended alignment you may
also need to replace operator new(size_t, align_val_t) and operator delete(void*, align_val_t)
operator delete(void*, size_t, align_val_t) (which will then be used by the nothrow and array forms for
extended alignments).
If you do need to replace other forms (e.g. to deﬁne the nothrow operator new to allocate memory
directly, so it works with exceptions disabled) then make sure the memory it allocates can still be freed by the non-nothrow forms
of operator delete.
If the default versions of operator new(std::size_t) and operator new(size_t, std::align_val_t) can’t
allocate the memory requested, they usually throw an exception object of type std::bad_alloc (or some class derived from
that).
This means you can inﬂuence what happens on allocation failure by writing your own new-handler and then registering it with
std::set_new_handler:
typedef void (*PFV)();
static char*
safety;
static PFV
old_handler;
void my_new_handler ()
{
delete[] safety;
safety = nullptr;
popup_window ("Dude, you are running low on heap memory.
You"
" should, like, close some windows, or something.
Nothing happens, by deﬁnition.
That is not the same thing as
deleting a pointer twice.
You should note that the abort() function does not call the destructors of automatic
nor static objects, so if you’re depending on those to do cleanup, it isn’t going to happen.
The good old exit() function can be a bit funky, too, until you look closer.
Basically, three points to remember are:
1.
Static objects are destroyed in reverse order of their creation.
Functions registered with atexit() are called in reverse order of registration, once per registration call.
The previous two actions are “interleaved,” that is, given this pseudocode:
extern "C or C++" void f1 ();
extern "C or C++" void f2 ();
static Thing obj1;
atexit(f1);
static Thing obj2;
atexit(f2);
then at a call of exit(), f2 will be called, then obj2 will be destroyed, then f1 will be called, and ﬁnally obj1 will
be destroyed.
If f1 or f2 allow an exception to propagate out of them, Bad Things happen.
Note also that atexit() is only required to store 32 functions, and the compiler/library might already be using some of those
slots.
If you think you may run out, we recommend using the xatexit/xexit combination from libiberty, which has no
such limit.
The verbose terminate handler is only available for hosted environments (see Conﬁguring) and will be used by default unless the
library is built with --disable-libstdcxx-verbose or with exceptions disabled.
If you need to enable it explicitly you
can do so by calling the std::set_terminate function.
If the exception is derived from std::exception then the output from what() will be included.
Any replacement termination function is required to kill the program without returning; this one calls std::abort.
Aborted
The ’Aborted’ line is printed by the shell after the process exits by calling abort().
As this is the default termination handler, nothing need be done to use it.
To go back to the previous “silent death” method,
simply include <exception> and <cstdlib>, and call
std::set_terminate(std::abort);
After this, all calls to terminate will use abort as the terminate handler.
Note: the verbose terminate handler will attempt to write to stderr.
If your application closes stderr or redirects it to an
inappropriate location, __verbose_terminate_handler will behave in an unspeciﬁed manner.
The C++ 2011 revision of the standard added more exception types in the headers <functional>, <future>, <regex>,
and <system_error>.
The C++ 2017 revision of the standard added more exception types in the headers <any>, <filesystem>,
<optional>, and <variant>.
All exceptions thrown by the library have a base class of type std::exception, deﬁned in <exception>.
This type has
no std::string member.
Derived from this are several classes that may have a std::string member.
A full hierarchy can be found in the source
documentation.
It’s good to remember that you can add your own data to these exceptions when extending the hierarchy:
struct My_Exception : public std::
int
errno_at_time_of_throw() 
DBID id_of_thing_that_threw() 
protected:
int
e;
DBID
id;
// some user-defined type
};

The C and POSIX standards guarantee that errno is never set to zero by any library function.
The C++ standard has less to say
about when errno is or isn’t set, but libstdc++ follows the same rule and never sets it to zero.
On the other hand, there are few guarantees about when the C++ library sets errno on error, beyond what is speciﬁed for
functions that come from the C library.
For example, when std::stoi throws an exception of type std::out_of_range,
errno may or may not have been set to ERANGE.
For example, on a target where operator new uses malloc a failed memory allocation with
operator new might set errno to ENOMEM.
Which C++ library functions can set errno in this way is unspeciﬁed because
it may vary between platforms and between releases.
For
example, the Standard requires that types passed as template parameters to vector be "Assignable" (which means what you
think it means).
The checking was done during compilation, and none of the code was executed at runtime.
Unfortunately, the size of the compiler ﬁles grew signiﬁcantly as a result.
The checking code itself was cumbersome.
And bugs
were found in it on more than one occasion.
The primary author of the checking code, Jeremy Siek, had already started work on a replacement implementation.
The new
code was formally reviewed and accepted into the Boost libraries, and we are pleased to incorporate it into the GNU C++ library.
The new version imposes a much smaller space overhead on the generated object ﬁle.
The checks are also cleaner and easier to
read and understand.
They are off by default for all versions of GCC.
They can be enabled at conﬁgure time with --enable-concept-checks.
You can
enable them on a per-translation-unit basis with -D_GLIBCXX_CONCEPT_CHECKS.
Please note that the checks are based on the requirements in the original C++ standard, many of which were relaxed in the C++11
standard and so valid C++11 code may be incorrectly rejected by the concept checks.
Additionally, some correct C++03 code
might be rejected by the concept checks, for example template argument types may need to be complete when used in a template
deﬁnition, rather than at the point of instantiation.
There are no plans to address these shortcomings.
Many people get slightly the wrong idea.
In the interest of not rein-
venting the wheel, we will refer you to the introduction to the functor concept written by SGI as part of their STL, in their
https://web.archive.org/web/20171225062613/http://www.sgi.com/tech/stl/functors.html.

The pair<T1,T2> is a simple and handy way to carry around a pair of objects.
One is of type T1, and another of type T2; they
may be the same type, but you don’t get anything extra if they are.
The two members can be accessed directly, as .first and
.second.
Construction is simple.
The default ctor initializes each member with its respective default ctor.
The other simple ctor,
pair (const T1& x, const T2& y);
does what you think it does, first getting x and second getting y.
The compiler will convert as necessary from U to T1 and from V to T2 in order to perform the respective initializations.
The comparison operators are done for you.
The less-than operator is a bit odd the ﬁrst time you see it.
The other operators are not deﬁned using the rel_ops functions above, but their semantics are the same.
Finally, there is a template function called make_pair that takes two references-to-const objects and returns an instance of a
pair instantiated on their respective types:
pair<int,MyClass> p = make_pair(4,myobject);


Memory contains three general areas.
First, function and operator calls via new and delete operator or member function calls.
Second, allocation via allocator.
And ﬁnally, smart pointer and intelligent pointer abstractions.
The allocator
abstraction is used throughout the library in string, container classes, algorithms, and parts of iostreams.
This class, and base
classes of it, are the superset of available free store (“heap”) management classes.
This includes adding chars to the string
class, which acts as a regular STL container in this respect.
The default Allocator argument of every container-of-T is allocator<T>.
The interface of the allocator<T> class is extremely simple.
The n arguments in both those functions is a count of the number of T’s to allocate space for, not their total size.
The storage is obtained by calling ::operator new, but it is unspeciﬁed when or how often this function is called.
The use
of the hint is unspeciﬁed, but intended as an aid to locality if an implementation so desires.
This method may be slower than caching the allocations and re-
using previously-allocated memory, but has the advantage of working correctly across a wide variety of hardware and operating
systems, including large clusters.
The __gnu_cxx::new_allocator implements the simple operator new and operator
delete semantics, while __gnu_cxx::malloc_allocator implements much the same thing, only with the C language
functions std::malloc and std::free.
Another approach is to use intelligence within the allocator class to cache allocations.
This extra machinery can take a variety
of forms: a bitmap index, an index into an exponentially increasing power-of-two-sized buckets, or simpler ﬁxed-size pooling
cache.
The cache is shared among all the containers in the program: when your program’s std::vector<int> gets cut
in half and frees a bunch of its storage, that memory can be reused by the private std::list<WonkyWidget> brought in
from a KDE library that you linked against.
And operators new and delete are not always called to pass the memory on,
either, which is a speed bonus.
Examples of allocators that use these techniques are __gnu_cxx::bitmap_allocator,
__gnu_cxx::pool_allocator, and __gnu_cxx::__mt_alloc.
Depending on the implementation techniques used, the underlying operating system, and compilation environment, scaling
caching allocators can be tricky.
In particular, order-of-destruction and order-of-creation for memory pools may be difﬁcult to
pin down with certainty, which may create problems when used with plugins or loading and unloading shared objects in memory.
As such, using caching allocators on systems that do not support abi::__cxa_atexit is not recommended.
As such, all STL containers have been adjusted, and
all external allocators have been modiﬁed to support this change.
The class allocator just has typedef, constructor, and rebind members.
It inherits from one of the high-speed extension
allocators, covered below.
Thus, all allocation and deallocation depends on the base class.
The choice of base class that allocator is derived from is ﬁxed at the time when GCC is built, and the different choices are
not ABI compatible.
It’s difﬁcult to pick an allocation strategy that will provide maximum utility, without excessively penalizing some behavior.
In
fact, it’s difﬁcult just deciding which typical actions to measure for speed.
Three synthetic benchmarks have been created that provide data that is used to compare different C++ allocators.
These tests are:
1. Insertion.
Over multiple iterations, various STL container objects have elements inserted to some maximum amount.
A variety of
allocators are tested.
Test source for sequence and associative containers.
This test shows the ability of the allocator to reclaim memory on a per-thread basis, as well as measuring thread contention
for memory resources.
Test source here.
A threaded producer/consumer model.
Test source for sequence and associative containers.
Since GCC 12 the default choice for allocator is std::__new_allocator.
In use, allocator may allocate and deallocate using implementation-speciﬁc strategies and heuristics.
Because of this, a given
call to an allocator object’s allocate member function may not actually call the global operator new and a given call to
to the deallocate member function may not call operator delete.
This can be confusing.
In particular, this can make debugging memory errors more difﬁcult, especially when using third-party tools like valgrind or
debug versions of new.
There are various ways to solve this problem.
One would be to use a custom allocator that just called operators new and delete
directly, for every allocation.
However, that
option may involve changing source code to use a non-default allocator.
Another option is to force the default allocator to remove
caching and pools, and to directly allocate with every call of allocate and directly deallocate with every call of deallocate,
regardless of efﬁciency.
As it turns out, this last option is also available.
To globally disable memory caching within the library for some of the optional non-default allocators, merely set GLIBCXX_FORCE_NE
(with any value) in the system’s environment before running the program.
If your program crashes with GLIBCXX_FORCE_NEW
in the environment, it likely means that you linked against objects built against the older library (objects which might still using
the cached allocations...).
For example, an easy (but non-portable) method of specifying that only malloc or free should be used instead of
the default node allocator is:
std::list <int, __gnu_cxx::malloc_allocator<int> >
malloc_list;
Likewise, a debugging form of whichever allocator is currently in use:
std::deque <int, __gnu_cxx::debug_allocator<std::allocator<int> > >
debug_deque;
6.Custom Allocators
Writing a portable C++ allocator would dictate that the interface would look much like the one speciﬁed for allocator.
Additional member functions, but not subtractions, would be permissible.
Probably the best place to start would be to copy one of the extension allocators: say a simple one like new_allocator.
Since C++11 the minimal interface require for an allocator is much smaller, as std::allocator_traits can provide
default for much of the interface.
The location of the extension allocators and their names have
changed, but in all cases, functionality is equivalent.
Starting with gcc-3.4, all extension allocators are standard style.
Before this
point, SGI style was the norm.
Because of this, the number of template arguments also changed.
Table B.6 tracks the changes.
More details on each of these extension allocators follows.
There is also a hook for an out-of-memory handler (for new/delete this is taken care
of elsewhere).
When a pointer is passed to deallocate(), the stored size is checked, and assert() is used
to guarantee they match.
The reusable memory is shared among identical instantiations of this type.
It
calls through ::operator new to obtain new memory when its lists run out.
If a client container requests a block larger
than a certain threshold size, then the pool is bypassed, and the allocate/deallocate request is passed to ::operator new
directly.
For thread-enabled conﬁgurations, the pool is locked with a single big lock.
In some situations, this implementation detail
may result in severe performance degradation.
A high-performance ﬁxed-size allocator with exponentially-increasing allocations.
It has its own chapter in the documen-
tation.
It has its own
chapter in the documentation.
Sufﬁce it to say that the use of AP safely in the presence of copying has some subtleties.
The AP class is a really nifty idea for a smart pointer, but it is one of the dumbest of all the smart pointers -- and that’s ﬁne.
AP is not meant to be a supersmart solution to all resource leaks everywhere.
Neither is it meant to be an effective form of
garbage collection (although it can help, a little bit).
And it can notbe used for arrays!
AP is meant to prevent nasty leaks in the presence of exceptions.
That’s all.
This code is AP-friendly:
// Not a recommend naming scheme, but good for web-based FAQs.
If it points to many things, you are
about to die.
AP is trivial to write, however, so you could write your own auto_array_ptr for that situation (in fact, this has
been done many times; check the mailing lists, Usenet, Boost, etc).
The template class auto_ptr (called AP here) does not
meet this requirement.
Creating a new AP by copying an existing one transfers ownership of the pointed-to object, which means
that the AP being copied must change, which in turn means that the copy ctors of AP do not take const objects.
The resulting rule is simple: Never ever use a container of auto_ptr objects.
The standard says that “undeﬁned” behavior is the
result, but it is guaranteed to be messy.
The basic design
and algorithms are from Boost, the notes below describe details speciﬁc to the GCC implementation.
Names have been ugliﬁed
in this implementation, but the design should be recognisable to anyone familiar with the Boost 1.32 shared_ptr.
The basic design is an abstract base class, _Sp_counted_base that does the reference-counting and calls virtual functions
when the count drops to zero.
Derived classes override those functions to destroy resources in a context where the correct
dynamic type is known.
This is an application of the technique known as type erasure.
The managed object is destroyed when the last strong reference is dropped, but
the _Sp_counted_base itself must exist until the last weak reference is dropped.
Ptr, Deleter, Lp> Inherits from _Sp_counted_base and stores a pointer of type Ptr
and a deleter of type Deleter.
Unlike Boost’s,
this default deleter is not "checked" because GCC already issues a warning if delete is used with an incomplete type.
Sp_counted_ptr<Ptr, Lp> Inherits from _Sp_counted_base and stores a pointer of type Ptr, which is passed to delete
when the last reference is dropped.
This is the simplest form and is used when there is no custom deleter or allocator.
Inherits from _Sp_counted_ptr and adds support for custom deleter
and allocator.
Empty Base Optimization is used for the allocator.
This class is used even when the user only provides a
custom deleter, in which case allocator is used as the allocator.
Contains aligned
storage to hold an object of type Tp, which is constructed in-place with placement new.
Has a variadic template construc-
tor allowing any number of arguments to be forwarded to Tp’s constructor.
Unlike the other _Sp_counted_* classes,
this one is parameterized on the type of object, not the type of pointer; this is purely a convenience that simpliﬁes the
implementation slightly.
C++11-only features are: rvalue-ref/move support, allocator support, aliasing constructor, make_shared & allocate_shared.
Ad-
ditionally, the constructors taking auto_ptr parameters are deprecated in C++11 mode.
The implementation must ensure that concurrent updates to separate shared_ptr instances are correct even when
those instances share a reference count e.g.
shared_ptr<A> a(new A);
shared_ptr<A> b(a);
// Thread 1
// Thread 2
a.reset();
b.reset();
The dynamically-allocated object must be destroyed by exactly one of the threads.
Weak references make things even more
interesting.
The shared state used to implement shared_ptr must be transparent to the user and invariants must be preserved at
all times.
The key pieces of shared state are the strong and weak reference counts.
On multi-processor
systems memory synchronisation may be needed so that reference-count updates and the destruction of the managed resource
are race-free.
The function _Sp_counted_base::_M_add_ref_lock(), called when obtaining a shared_ptr from a weak_ptr, has to
test if the managed resource still exists and either increment the reference count or throw bad_weak_ptr.
In a multi-threaded
program there is a potential race condition if the last reference is dropped (and the managed resource destroyed) between testing
the reference count and incrementing it, which could result in a shared_ptr pointing to invalid memory.
For other platforms there are fall-backs using mutex locks.
Boost (as of version 1.35) includes several different implementations and the preprocessor selects one based on the compiler,
standard library, platform etc.
For the version of shared_ptr in libstdc++ the compiler and library are ﬁxed, which makes things
much simpler: we have an atomic CAS or we don’t, see Lock Policy below for details.
This design is necessary because it would not be conforming for shared_ptr to have an extra template parameter, even
if it had a default value.
The available policies are:
1.
The reference counts are maintained using a lock-free algorithm and GCC’s atomic builtins, which provide the required
memory synchronisation.
This policy is
used when GCC’s atomic builtins aren’t available so explicit memory barriers are needed in places.
It is used when libstdc++ is built without --enable-threads.
For all three policies, reference count increments and decrements are done via the functions in ext/atomicity.h, which
detect if the program is multi-threaded.
If only one thread of execution exists in the program then less expensive non-atomic
operations are used.
As noted in N2351, these functions can
be implemented non-intrusively using the alias constructor.
However the aliasing constructor is only available in C++11
mode, so in TR1 mode these casts rely on three non-standard constructors in shared_ptr and __shared_ptr.
In C++11 mode
these constructors and the related tag types are not needed.
The clever overload to detect a base class of type enable_shared_from_this comes
straight from Boost.
Although these functions can be implemented non-intrusively using the alias constructor, if they have
access to the implementation then it is possible to save storage and reduce the number of heap allocations.
The newly
constructed object and the _Sp_counted_* can be allocated in a single block and the standard says implementations
are "encouraged, but not required," to do so.
This implementation provides additional non-standard constructors (se-
lected with the type _Sp_make_shared_tag) which create an object of type _Sp_counted_ptr_inplace to
hold the new object.
The returned shared_ptr<A> needs to know the address of the new A object embedded in the
_Sp_counted_ptr_inplace, but it has no way to access it.
This implementation uses a "covert channel" to return
the address of the embedded object when get_deleter<_Sp_make_shared_tag>() is called.
Users should not
try to use this.
As well as the extra constructors, this implementation also needs some members of _Sp_counted_deleter to
be protected where they could otherwise be private.
Unlike Boost, this implementation does not use separate classes for the pointer+deleter and pointer+deleter+allocator cases in
C++11 mode, combining both into _Sp_counted_deleter and using allocator when the user doesn’t specify an allocator.
If it
was found to be beneﬁcial an additional class could easily be added.
With the current implementation, the _Sp_counted_deleter
and __shared_count constructors taking a custom deleter but no allocator are technically redundant and could be removed,
changing callers to always specify an allocator.
If a separate pointer+deleter class was added the __shared_count constructor
would be needed, so it has been kept for now.
The hack used to get the address of the managed object from _Sp_counted_ptr_inplace::_M_get_deleter() is
accessible to users.
This could be prevented if get_deleter<_Sp_make_shared_tag>() always returned NULL, since
the hack only needs to work at a lower level, not in the public API.
This wouldn’t be difﬁcult, but hasn’t been done since there
is no danger of accidental misuse: users already know they are relying on unsupported features if they refer to implementation
details such as _Sp_make_shared_tag.
tr1::_Sp_deleter could be a private member of tr1::__shared_count but it would alter the ABI.
Phillip Jordan and Paolo Carlini for the lock policy implementation.
Libraries documentation, shared_ptr , N2461 .
The word transformations is especially apt, because the standard template function transform<> is used.
This code will go through some iterations.
Here’s a simple version:
#include <string>
#include <algorithm>
#include <cctype>
// old <ctype.h>
struct 
};
struct 
};
int main()
{
std::string
s ("Some Kind Of Initial Input Goes Here");
// Change everything into upper case
std::transform (s.begin(), s.end(), s.begin(), ToUpper());
// Change everything into lower case
std::transform (s.begin(), s.end(), s.begin(), ToLower());
// Change everything back into upper case, but store the
// result in a different string
std::string
capital_s;
capital_s.resize(s.size());
std::transform (s.begin(), s.end(), capital_s.begin(), ToUpper());
}
Note that these calls all involve the global C locale through the use of the C functions toupper/tolower.
This is absolutely
guaranteed to work -- but only if the string contains only characters from the basic source character set, and there are only 96 of

those.
Which means that not even all English text can be represented (certain British spellings, proper names, and so forth).
So,
if all your input forevermore consists of only those 96 characters (hahahahahaha), then you’re done.
Another common operation is trimming off excess whitespace.
Much like transformations, this task is trivial with the use of
string’s find family.
C function stricmp()”.
The original answer was posted on Usenet, and a revised version appears in Herb Sutter’s book
Exceptional C++ and on his website as GotW 29.
See?
The May 2000 issue of C++ Report contains a fascinating article by Matt Austern (yes, the Matt Austern)
on why case-insensitive comparisons are not as easy as they seem, and why creating a class is the wrong way to go about it in
production code.
Basically, this is "easy" only if you ignore some things, things which may be too important to your program to ignore.
The GotW question and
answer remain useful instructional tools, however.
James Kanze provided a link to a Unicode Technical Report discussing case handling, which provides
some very good information.
In
theory, you could whip up a Unicode character class and instantiate std::basic_string<my_unicode_char>, or as-
suming that integers are wider than characters on your platform, maybe just declare variables of type std::basic_string<int>.
That’s the theory.
Remember however that basic_string has additional type parameters, which take default arguments based on
the character type (called CharT here):
;
Now, allocator<CharT> will probably Do The Right Thing by default, unless you need to implement your own allocator
for your characters.
But char_traits takes more work.
The char_traits template is declared but not deﬁned.
That means there is only
;
and functions such as char_traits<CharT>::foo() are not actually deﬁned anywhere for the general case.
The C++ standard
permits this, because writing such a deﬁnition to ﬁt all possible CharT’s cannot be done.
The C++ standard also requires that char_traits be specialized for instantiations of char and wchar_t, and it is these template
specializations that permit entities like basic_string<char,char_traits<char>> to work.
If you want to use character types other than char and wchar_t, such as unsigned char and int, you will need suitable
specializations for them.
For a time, in earlier versions of GCC, there was a mostly-correct implementation that let programmers
be lazy but it broke under many situations, so it was removed.
GCC 3.4 introduced a new implementation that mostly works and
can be specialized even for int and other built-in types.
If you want to use your own special character class, then you have a lot of work to do, especially if you with to use i18n features
(facets require traits information but don’t have a traits argument).
Another example of how to specialize char_traits was given on the mailing list and at a later date was put into the ﬁle include/ext/p
We agree that the way it’s used with basic_string (scroll down to main()) doesn’t look nice, but that’s because the nice-looking
ﬁrst attempt turned out to not be conforming C++, due to the rule that CharT must be a POD.
It’s unintuitive, it destroys
the character string on which it operates, and it requires you to handle all the memory problems.
But it does let the client code
decide what to use to break the string into pieces; it allows you to choose the "whitespace," so to speak.
A C++ implementation lets us keep the good things and ﬁx those annoyances.
The implementation here is more intuitive (you
only call it once, not in a loop with varying argument), it does not affect the original string at all, and all the memory allocation
is handled for you.
It’s called stringtok, and it’s a template function.
Sources are as below, in a less-portable form than it could be, to keep this
example simple (for example, see the comments on what kind of string it will accept).
The original s is still available for use, ls will clean up after itself, and ls.size() will
return how many tokens there were.
As always, there is a price paid here, in that stringtok is not as fast as strtok.
The other beneﬁts usually outweigh that, however.
Mark Wilden pointed out that the standard std::getline() function can be used with standard
istringstreams to perform tokenizing as well.
Build an istringstream from the input text, and then use std::getline with
varying delimiters (the three-argument signature) to extract tokens into a string.
This behaviour is suggested, but not required by the standard.
Prior to GCC 3.4 the following alternative can be used instead

std::string(str.data(), str.size()).swap(str);
This is similar to the idiom for reducing a vector’s memory usage (see this FAQ entry) but the regular copy constructor cannot
be used because libstdc++’s string is Copy-On-Write in GCC 3.
In C++11 mode you can call s.shrink_to_fit() to achieve the same effect as s.reserve(s.size()).
Often programmers realize that a standard portable answer is better than a proprietary nonportable one, but in
porting their application from a Win32 platform, they discover that they are relying on special functions offered by the CString
class.
Things are not as bad as they seem.
In this message, Joe Buck points out a few very important things:
• The Standard string supports all the operations that CString does, with three exceptions.
Two of those exceptions (whitespace trimming and case conversion) are trivial to implement.
In fact, we do so on this page.
The third is CString::Format, which allows formatting in the style of sprintf.
This deserves some mention:
The old libg++ library had a function called form(), which did much the same thing.
But for a Standard solution, you should use
the stringstream classes.
These are the bridge between the iostream hierarchy and the string class, and they operate with regular
streams seamlessly because they inherit from the iostream hierarchy.
Speciﬁcally, quoting from that same message:
CString suffers from a common programming error that results in
poor performance.
The reason is that each +=

causes a reallocation and copy of the existing string.
If you replace CString with string in the above function, the
performance is O(n).
CString permits access to its internal representation; coders who exploited that may have problems moving to string.
Microsoft ships the source to CString (in the ﬁles MFC\SRC\.cpp), so you could ﬁx the allocation bug and rebuild
your MFC libraries.
Note: It looks like the CString shipped with VC++6.0 has ﬁxed this, although it may in fact have been one
of the VC++ SPs that did it.
The libstdc++ implementors did it
correctly.
Other vendors might not.
• While parts of the SGI STL are used in libstdc++, their string class is not.
The SGI string is essentially vector<char>
and does not do any reference counting like libstdc++’s does.
So if you’re thinking about SGI’s string or
rope classes, you’re now looking at four possibilities: CString, the libstdc++ string, the SGI string, and the SGI rope, and this
is all before any allocator or traits customizations!
For instance, a facet called numpunct is the data object that can be used to query
for the thousands separator in the locale.
Of interest in this class are the memory management options explicitly speciﬁed as an argument to facet’s constructor.
Each
constructor of a facet class takes a std::size_t __refs argument: if __refs == 0, the facet is deleted when the locale containing it is
destroyed.
If __refs == 1, the facet is not destroyed, even when it is no longer referenced.
Because C and earlier versions of POSIX fall down so completely, portability is an issue.
LANG=en_US

LC_CTYPE="en_US"
LC_NUMERIC="en_US"
LC_TIME="en_US"
LC_COLLATE="en_US"
LC_MONETARY="en_US"
LC_MESSAGES="en_US"
LC_PAPER="en_US"
LC_NAME="en_US"
LC_ADDRESS="en_US"
LC_TELEPHONE="en_US"
LC_MEASUREMENT="en_US"
LC_IDENTIFICATION="en_US"
LC_ALL=
From Josuttis, p. 697-698, which says, that "there is only *one* relation (of the C++ locale mechanism) to the C locale mecha-
nism: the global C locale is modiﬁed if a named C++ locale object is set as the global locale" (emphasis Paolo), that is:
std::locale::global(std::locale(""));
affects the C functions as if the following call was made:
std::setlocale(LC_ALL, "");
On the other hand, there is *no* vice versa, that is, calling setlocale has *no* whatsoever on the C++ locale mechanism, in
particular on the working of locale(""), which constructs the locale object from the environment of the running program, that is,
in practice, the set of LC_ALL, LANG, etc. variable of the shell.
Can named locales assume this initialization
has already taken place?
• Document how named locales error check when ﬁlling data members.
I.e., a fr_FR locale that doesn’t have numpunct::truename():
does it use "true"?
Or is it a blank string?
What’s the convention?
• Explain how locale aliasing happens.
When does "de_DE" use "de" information?
What is the rule for locales composed of just
an ISO language code (say, "de") and locales with both an ISO language code and ISO country code (say, "de_DE").
If the generic implementation is provided, then how to end-users provide
specializations?
The Open Group/The
Institute of Electrical and Electronics Engineers, Inc. .
Addison Wesley, Inc., Appendix D, Addison Wesley .
Addison Wes-
ley Longman, Inc., Addison Wesley Longman .
This is simple specialization.
Implementing this was a piece of cake.
As such, the im-
plementation is straightforward, involving mcsrtombs for the conversions between char to wchar_t and wcsrtombs for
conversions between wchar_t and char.
Neither of these two required specializations deals with Unicode characters.
Can this be made (more) generic?
Need to make some kind of static table, and not do lookup every time
somebody hits the do_is... functions.
Too bad we can’t just redeﬁne mask for ctype<wchar_t>
• Rename abstract base class.
See if just smash-overriding is a better approach.
Clarify, add sanity to naming.
Copyright © 1999 The Open
Group/The Institute of Electrical and Electronics Engineers, Inc..
Addison Wesley, Inc., Appendix D, Addison Wesley .
Addison Wes-
ley Longman, Inc., Addison Wesley Longman .
This document
attempts to describe how the GNU libstdc++ implementation deals with the conversion between wide and narrow characters, and
also presents a framework for dealing with the huge number of other encodings that iconv can convert, including Unicode and
UTF8.
Design issues and requirements are addressed, and examples of correct usage for both the required specializations for
wide and narrow characters and the implementation-provided extended functionality are given.
The class codecvt<internT,externT,stateT> is for use when converting from one codeset to another,
such as from wide characters to multibyte characters, between wide character encodings such as Unicode and EUC.
Hmm.
The stateT argument selects the pair of codesets being mapped between.
Ah ha!
The instantiations required in the Table 51 (lib.locale.category), namely codecvt<wchar_t,char,mbstate_t>
and codecvt<char,char,mbstate_t>, convert the implementation-deﬁned native character set.
Instantiations on mbstate_t perform conversion
between encodings known to the library implementor.
Other encodings can be converted by specializing on a user-
deﬁned stateT type.
The stateT object can contain any state that is useful to communicate to or from the specialized
do_convert member.
At this point, a couple points become clear:
One: The standard clearly implies that attempts to add non-required (yet useful and widely used) conversions need to do so
through the third template parameter, stateT.
Two: The required conversions, by specifying mbstate_t as the third template parameter, imply an implementation strategy that
is mostly (or wholly) based on the underlying C library, and the functions mcsrtombs and wcsrtombs in particular.
Many systems use a two byte, unsigned
integral type to represent wide characters, and use an internal encoding of Unicode or UCS2.
Other systems, use a four byte, unsigned integral type to represent wide characters, and use an internal encoding of
UCS4.
The C programming language (and thus C++) does not specify a speciﬁc
size for the type wchar_t.
Thus, portable C++ code cannot assume a byte size (or endianness) either.
The
dude part is optional, but apparently the usefulness of Unicode strings is pretty widely appreciated.
The Unicode character set
(and useful encodings like UTF-8, UCS-4, ISO 8859-10, etc etc etc) were not mentioned in the ﬁrst C++ standard.
A couple of comments:
The thought that all one needs to convert between two arbitrary codesets is two types and some kind of state argument is
unfortunate.
In particular, encodings may be stateless.
The naming of the third parameter as stateT is unfortunate, as what is
really needed is some kind of generalized type that accounts for the issues that abstract encodings will need.
The minimum
information that is required includes:
• Identiﬁers for each of the codesets involved in the conversion.
For example, using the iconv family of functions from the Single
Unix Speciﬁcation (what used to be called X/Open) hosted on the GNU/Linux operating system allows bi-directional mapping
between far more than the following tantalizing possibilities:
(An edited list taken from `iconv --list` on a Red Hat 6.2/Intel system:
8859_1, 8859_9, 10646-1:1993, 10646-1:1993/UCS4, ARABIC, ARABIC7,
ASCII, EUC-CN, EUC-JP, EUC-KR, EUC-TW, GREEK-CCIcode, GREEK, GREEK7-OLD,
GREEK7, GREEK8, HEBREW, ISO-8859-1, ISO-8859-2, ISO-8859-3,
ISO-8859-4, ISO-8859-5, ISO-8859-6, ISO-8859-7, ISO-8859-8,
ISO-8859-9, ISO-8859-10, ISO-8859-11, ISO-8859-13, ISO-8859-14,
ISO-8859-15, ISO-10646, ISO-10646/UCS2, ISO-10646/UCS4,
ISO-10646/UTF-8, ISO-10646/UTF8, SHIFT-JIS, SHIFT_JIS, UCS-2, UCS-4,
UCS2, UCS4, UNICODE, UNICODEBIG, UNICODELIcodeLE, US-ASCII, US, UTF-8,
UTF-16, UTF8, UTF16).
For iconv-based implementations, string literals for each of the encodings (i.e. "UCS-2" and "UTF-8") are necessary, although
for other, non-iconv implementations a table of enumerated values or some other mechanism may be required.
Some encodings require explicit endian-ness.
As such, some kind of endian marker or other byte-order marker will be neces-
sary.
See "Footnotes for C/C++ developers" in Haible for more information on UCS-2/Unicode endian issues.
Note that the conversion descriptor encodes more information than a
simple encoding state type.
As part of this, the size of the internal and external
types will need to be known.
In par-
ticular, they affect the required specialization codecvt<wchar_t, char, mbstate_t> when implemented using stan-
dard "C" functions.
Three problems arise, one big, one of medium importance, and one small.
For
GNU/Linux and glibc, this is not an issue.
Of medium concern, in the grand scope of things, is that the functions used to implement this specialization work on null-
terminated strings.
Buffers, especially ﬁle buffers, may not be null-terminated, thus giving conversions that end prematurely or
are otherwise incorrect.
Yikes!
The last, and fundamental problem, is the assumption of a global locale for all the "C" functions referenced above.
For something
like C++ iostreams (where codecvt is explicitly used) the notion of multiple locales is fundamental.
In practice, most users may
not run into this limitation.
However, as a quality of implementation issue, the GNU C++ library would like to offer a solution
that allows multiple locales and or simultaneous usage with computationally correct results.
In short, libstdc++ is trying to offer,
as an option, a high-quality implementation, damn the additional complexity!
For the required specialization codecvt<wchar_t, char, mbstate_t>, conversions are made between the internal
character set (always UCS4 on GNU/Linux) and whatever the currently selected locale for the LC_CTYPE category implements.
This is a degenerate (i.e., does nothing) specialization.
Implementing this was a piece of cake.
This specialization, by specifying all the template parameters, pretty much ties the hands of implementors.
As such, the im-
plementation is straightforward, involving mcsrtombs for the conversions between char to wchar_t and wcsrtombs for
conversions between wchar_t and char.
Neither of these two required specializations deals with Unicode characters.
As such, libstdc++ implements a partial specializa-
tion of the codecvt class with an iconv wrapper class, encoding_state as the third template parameter.
This implementation should be standards conformant.
First of all, the standard explicitly points out that instantiations on the
third template parameter, stateT, are the proper way to implement non-required conversions.
Second of all, the standard says (in
Chapter 17) that partial specializations of required classes are A-OK.
Third of all, the requirements for the stateT type elsewhere
in the standard (see traits typedefs) only indicate that this type be copy constructible.
As such, the type encoding_state is deﬁned as a non-templatized, POD type to be used as the third type of a codecvt instantiation.
This type is just a wrapper class for iconv, and provides an easy interface to iconv functionality.
This default constructor sets the internal encoding to some default (currently UCS4) and the external encoding to whatever is
returned by nl_langinfo(CODESET).
This constructor takes as parameters string literals that indicate the desired internal and external encoding.
There are no defaults
for either argument.
One of the issues with iconv is that the string literals identifying conversions are not standardized.
Because of this, the thought
of mandating and/or enforcing some set of pre-determined valid identiﬁers seems iffy: thus, a more practical (and non-migraine
inducing) strategy was implemented: end-users can specify any string (subject to a pre-determined length qualiﬁer, currently 32
bytes) for encodings.
It is up to the user to make sure that these strings are valid on the target system.
If the con-
version descriptors are not valid, the conversion descriptors returned will not be valid and the resulting calls to the codecvt
conversion functions will return error.
If the string literals describing the desired
internal and external encoding are not valid, initialization will fail, and this will return false.
If the internal and external encodings
are valid, but iconv_open could not allocate conversion descriptors, this will also return false.
Otherwise, the object is ready
to convert and will return true.
As iconv allocates memory and sets up conversion descriptors, the copy constructor can only copy the member data pertaining to
the internal and external code conversions, and not the conversion descriptors themselves.
Deﬁnitions for all the required codecvt member functions are provided for this specialization, and usage of codecvt<internal
character type, external character type, encoding_state> is consistent with other codecvt usage.
I have no idea how to do this correctly, and in a generic manner.
Nathan?
• b. conversions involving std::string

– how should operators !
A byte by byte comparison or an encoding then byte comparison?
– conversions between narrow, wide, and unicode strings
• c. conversions involving std::ﬁlebuf and std::ostream
– how to initialize the state object in a standards-conformant manner?
– how to synchronize the "C" and "C++" conversion information?
– wchar_t/char internal buffers and conversions between internal/external buffers?
8.Bibliography
[34] Roland McGrathUlrich Drepper, Copyright © 2007 FSF, Chapters 6 Character Set Handling and 7 Locales and
Internationalization .
The Open Group/The
Institute of Electrical and Electronics Engineers, Inc. .
Addison Wesley, Inc., Appendix D, Addison Wesley .
Addison Wes-
ley Longman, Inc., Addison Wesley Longman .
MessageFormat
using either GNU gettext or IEEE 1003.1-200 functions.
It’s assumed that this facility
was built into the standard library in order to convert string literals from one locale to the other.
For instance, converting the "C"
locale’s const char* c = "please" to a German-localized "bitte" during program execution.
The public member functions are:
catalog open(const string&, const locale&) const
string_type get(catalog, int, int, const string_type&) const
void close(catalog) const
While the virtual functions are:
catalog do_open(const string& name, const locale& loc) const

-1- Returns: A value that may be passed to get() to retrieve a message, from the message catalog identiﬁed
by the string name according to an implementation-deﬁned mapping.
The result can be used until it is passed to
close().
Returns a value less than 0 if no such catalog can be opened.
If no such message can
be found, returns dfault.
Notes: The limit on such resources, if any, is implementation-deﬁned.
First, why is messages_base::catalog speciﬁed as a typedef to int?
This makes sense for implementations that use
catopen and deﬁne nl_catd as int, but not for others.
Fortunately, it’s not heavily used and so only a minor irritant.
This has
been reported as a possible defect in the standard (LWG 2028).
Second, by making the member functions const, it is impossible to save state in them.
Thus, storing away information used in
the ’open’ member function for use in ’get’ is impossible.
This is unfortunate.
The ’open’ member function in particular seems to be oddly designed.
The signature seems quite peculiar.
Why specify a const
string&
argument, for instance, instead of just const char*?
Or, why specify a const locale& argument that is to
be used in the ’get’ member function?
How, exactly, is this locale argument useful?
What was the intent?
It might make sense if
a locale argument was associated with a given default message string in the ’open’ member function, for instance.
Quite murky
and unclear, on reﬂection.
Lastly, it seems odd that messages, which explicitly require code conversion, don’t use the codecvt facet.
Because the messages
facet has only one template parameter, it is assumed that ctype, and not codecvt, is to be used to convert between character sets.
It is implicitly assumed that the locale for the default message string in ’get’ is in the "C" locale.
Thus, all source code is assumed
to be written in English, so translations are always from "en_US" to other, explicitly named locales.
This is a relatively simple class, on the face of it.
The standard speciﬁes very little in concrete terms, so generic implementations
that are conforming yet do very little are the norm.
Adding functionality that would be useful to programmers and comparable
to Java’s java.text.
MessageFormat takes a bit of work, and is highly dependent on the capabilities of the underlying operating
system.
Three different mechanisms have been provided, selectable via conﬁgure ﬂags:
• generic
This model does very little, and is what is used by default.
It’s based on the GNU gettext package, which is part of glibc.
It uses the functions
textdomain, bindtextdomain, gettext to implement full functionality.
Creating message catalogs is a relatively
straight-forward process and is lightly documented below, and fully documented in gettext’s distributed documentation.
The functions catopen, catgets,
catclose are used to retrieve locale-speciﬁc messages given the appropriate message catalogs that have been constructed
for their use.
Note, the script
po2msg.sed that is part of the gettext distribution can convert gettext catalogs into catalogs
that catopen can use.
A new, standards-conformant non-virtual member function signature was added for ’open’ so that a directory could be speciﬁed
with a given message catalog.
This simpliﬁes calling conventions for the gnu model.
In addition, underlying "C" library locale support is necessary for more than just the LC_MESSAGES
mask: LC_CTYPE is also necessary.
To avoid any unpleasantness, all bits of the "C" mask (i.e. LC_ALL) are set before retrieving
messages.
Making the message catalogs can be initially tricky, but become quite simple with practice.
For complete info, see the gettext
documentation.
Here’s an idea of what is required:
• Make a source ﬁle with the required string literals that need to be translated.
See intl/string_literals.cc for an
example.
• Make initial catalog (see "4 Making the PO Template File" from the gettext docs).
It might not be possible to do a real character set based conversion, due to the fact that the template parameter for
messages is not enough to instantiate the codecvt facet (1 supplied, need at least 2 but would prefer 3).
This dependence on the global locale makes
the current "gnu" model non MT-safe.
Future versions of glibc, i.e. glibc 2.3.x will ﬁx this, and the C++ library bits are
already in place.
If this is done, it will change the library ABI.
The C++ parts
to support glibc 2.3 have already been coded, but are not in use: once this version of the "C" library is released, the marked
parts of the messages implementation can be switched over to the new "C" library functionality.
At some point in the near future, std::numpunct will probably use std::messages facilities to implement truename/falsename
correctly.
This is currently not done, but entries in libstdc++.pot have already been made for "true" and "false" string literals,
so all that remains is the std::numpunct coding and the conﬁgure/make hassles to make the installed library search its own
catalog.
Currently the libstdc++.mo catalog is only searched for the testsuite cases involving messages members.
The following member functions:
catalog open(const basic_string<char>& __s, const locale& __loc) const
catalog open(const basic_string<char>&, const locale&, const char*) const;
Don’t actually return a "value less than 0 if no such catalog can be opened" as required by the standard in the "gnu" model.
As
of this writing, it is unknown how to query to see if a speciﬁed message catalog exists using the gettext package.
The Open Group/The
Institute of Electrical and Electronics Engineers, Inc. .
Addison Wesley, Inc., Appendix D, Addison Wesley .
Addison Wes-
ley Longman, Inc., Addison Wesley Longman .
Properties,
java.text.
MessageFormat,
java.util.
Locale,
java.util.
ResourceBundle .
Yes it is, at least using the old ABI, and that’s okay.
This is a decision that we preserved when we imported SGI’s STL
implementation.
The following is quoted from their FAQ:
The size() member function, for list and slist, takes time proportional to the number of elements in the list.
This
was a deliberate tradeoff.
The only way to get a constant-time size() for linked lists would be to maintain an extra
member variable containing the list’s size.
This would require taking extra time to update that variable (it would
make splice() a linear time operation, for example), and it would also make the list larger.
Many list algorithms don’t
require that extra word (algorithms that do require it might do better with vectors than with lists), and, when it is
necessary to maintain an explicit size count, it’s something that users can do themselves.
This choice is permitted by the C++ standard.
The standard says that size() “should” be constant time, and “should”
does not mean the same thing as “shall”.
This is the ofﬁcially recommended ISO wording for saying that an imple-
mentation is supposed to do something unless there is a good reason not to.
One implication of linear time size(): you should never write
if (L.size() == 0)
...
Since version 4.2 GCC implements
the resolution to DR 233, so that insertions happen as close as possible to the hint.
For earlier releases the hint was only used as
described below.
Here we’ll describe how the hinting works in the libstdc++ implementation, and what you need to do in order to take advantage
of it.
Also, since
the current implementation is based on the SGI STL one, these points may hold true for other library implementations also, since
the HP/SGI code is used in a lot of places.
In the following text, the phrases greater than and less than refer to the results of the strict weak ordering imposed on the
container by its comparison object, which defaults to (basically) “<”.
Using those phrases is semantically sloppy, but I didn’t
want to get bogged down in syntax.
I assume that if you are intelligent enough to use your own comparison objects, you are also
intelligent enough to assign “greater” and “lesser” their new meanings in the next paragraph.
The item will be inserted
at the beginning of the container, becoming the new entry at begin().
• end(), then the item being inserted should have a key greater than all the other keys in the container.
The item will be inserted
at the end of the container, becoming the new entry before end().
Then the
item being inserted should have a key less than that of h, and greater than that of the item preceding h.
The new item will be
inserted between h and h’s predecessor.
If the conditions are not met, then the hint is not used, and the insertion proceeds as if you had called
a.insert(t)
instead.
This behavior goes well with other containers’ insert() functions which take an iterator: if used, the new item will be inserted
before the iterator passed as an argument, same as the other containers.
Note also that the hint in this implementation is a one-shot.
The older insertion-with-hint routines check the immediately
surrounding entries to ensure that the new item would in fact belong there.
If the hint does not point to the correct place, then no
further local searching is done; the search begins from scratch in logarithmic time.
Your compiler is correct; it is not a bug.
That’s the way templates work.
There are a couple of ways to handle this kind of thing.
Please consider all of them before passing judgement.
They include, in
no particular order:

• A very large N in bitset<N>.
A container<bool>.
A very large N in bitset<N>.
It has been pointed out a few times in newsgroups that N bits only takes up (N/8) bytes on most
systems, and division by a factor of eight is pretty impressive when speaking of memory.
Half a megabyte given over to a bitset
(recall that there is zero space overhead for housekeeping info; it is known at compile time exactly how large the set is) will hold
over four million bits.
If you’re using those bits as status ﬂags (e.g., “changed”/“unchanged” ﬂags), that’s a lot of state.
You can then keep track of the “maximum bit used” during some testing runs on representative data, make note of how many of
those bits really need to be there, and then reduce N to a smaller number.
Leave some extra space, of course.
A container<bool>.
The Committee made provision for the space savings possible with that (N/8) usage previously men-
tioned, so that you don’t have to do wasteful things like Container<char> or Container<short int>.
Speciﬁcally,
vector<bool> is required to be specialized for that space savings.
The problem is that vector<bool> doesn’t behave like a normal vector anymore.
There have been journal articles which dis-
cuss the problems (the ones by Herb Sutter in the May and July/August 1999 issues of C++ Report cover it well).
Future revisions
of the ISO C++ Standard will change the requirement for vector<bool> specialization.
In the meantime, deque<bool> is
recommended (although its behavior is sane, you probably will not get the space savings, but the allocation scheme is different
than that of vector).
Extremely weird solutions.
If you have access to the compiler and linker at runtime, you can do something insane, like ﬁguring
out just how many bits you need, then writing a temporary source code ﬁle.
That ﬁle contains an instantiation of bitset for the
required number of bits, inside some wrapper functions with unchanging signatures.
Have your program then call the compiler
on that ﬁle using Position Independent Code, then open the newly-created object ﬁle and load those wrapper functions.
You’ll
have an instantiation of bitset<N> for the exact N that you need at the time.
Don’t forget to delete the temporary ﬁles.
This would be the approach of either a visionary genius or a raving lunatic, depending on your programming and management
style.
Probably the latter.
Which of the above techniques you use, if any, are up to you and your intended application.
Some time/space proﬁling is indicated
if it really matters (don’t just guess).
And, if you manage to do anything along the lines of the third category, the author would
love to hear from you...
Also note that the implementation of bitset used in libstdc++ has some extensions.
This is something of an accident, but you can read
about the problem: follow the library’s “Links” from the homepage, and from the C++ information “defect reﬂector” link, select
the library issues list.
Issue number 116 describes the problem.
For now you can simply make a temporary string object using the constructor expression:
std::bitset<5> b ( std::string("10110") );
instead of
std::bitset<5> b ( "10110" );
// invalid



Here is how the hinting works in the libstdc++ implementation of unordered containers, and the rationale behind this behavior.
In the following text, the phrase equivalent to refer to the result of the invocation of the equal predicate imposed on the container
by its key_equal object, which defaults to (basically) “==”.
Unordered containers can be seen as a std::vector of std::forward_list.
The std::vector represents the buckets
and each std::forward_list is the list of nodes belonging to the same bucket.
When inserting an element in such a data
structure we ﬁrst need to compute the element hash code to ﬁnd the bucket to insert the element to, the second step depends on
the uniqueness of elements in the container.
In the case of std::unordered_set and std::unordered_map you need to look through all bucket’s elements for an
equivalent one.
If there is none the insertion can be achieved, otherwise the insertion fails.
As we always need to loop though all
bucket’s elements, the hint doesn’t tell us if the element is already present, and we don’t have any constraint on where the new
element is to be inserted, the hint won’t be of any help and will then be ignored.
In the case of std::unordered_multiset and std::unordered_multimap equivalent elements must be linked to-
gether so that the equal_range(const key_type&) can return the range of iterators pointing to all equivalent elements.
This is where hinting can be used to point to another equivalent element already part of the container and so skip all non equiv-
alent elements of the bucket.
So to be useful the hint shall point to an element equivalent to the one being inserted.
The new
element will be then inserted right after the hint.
Note that because of an implementation detail inserting after a node can require
updating the bucket of the following node.
To check if the next bucket is to be modiﬁed we need to compute the following node’s
hash code.
So if you want your hint to be really efﬁcient it should be followed by another equivalent element, the implementation
will detect this equivalence and won’t compute next element hash code.
It is highly advised to start using unordered containers hints only if you have a benchmark that will demonstrate the beneﬁt of it.
If you don’t then do not use hints, it might do more harm than good.
The unordered containers in libstdc++ may cache the hash code for each element alongside the element itself.
In some cases not
recalculating the hash code every time it’s needed can improve performance, but the additional memory overhead can also reduce
performance, so whether an unordered associative container caches the hash code or not depends on the properties described
below.
The C++ standard requires that erase and swap operations must not throw exceptions.
Those operations might need an
element’s hash code, but cannot use the hash function if it could throw.
This means the hash codes will be cached unless the hash
function has a non-throwing exception speciﬁcation such as noexcept or throw().
If the hash function is non-throwing then libstdc++ doesn’t need to cache the hash code for correctness, but might still do so
for performance if computing a hash code is an expensive operation, as it may be for arbitrarily long strings.
As an extension
libstdc++ provides a trait type to describe whether a hash function is fast.
By default hash functions are assumed to be fast unless
the trait is specialized for the hash function and the trait’s value is false, in which case the hash code will always be cached.
You’re writing some code and can’t decide whether to use builtin arrays or some kind of container.
There are compelling reasons
to use one of the container classes, but you’re afraid that you’ll eventually run into difﬁculties, change everything back to arrays,
and then have to change all the code that uses those data types to keep up with the change.
If your code makes use of the standard algorithms, this isn’t as scary as it sounds.
The algorithms don’t know, nor care, about the
kind of “container” on which they work, since the algorithms are only given endpoints to work with.
For the container classes,
these are iterators (usually begin() and end(), but not always).
For builtin arrays, these are the address of the ﬁrst element
and the past-the-end element.
Some very simple wrapper functions can hide all of that from the rest of the code.
For example, a pair of functions called
beginof can be written, one that takes an array, another that takes a vector.
The ﬁrst returns a pointer to the ﬁrst element, and
the second returns the vector’s begin() iterator.
The functions should be made template functions, and should also be declared inline.
As pointed out in the comments in the code
below, this can lead to beginof being optimized out of existence, so you pay absolutely nothing in terms of increased code size
or execution time.
The result is that if all your algorithm calls look like
std::transform(beginof(foo), endof(foo), beginof(foo), SomeFunction);
then the type of foo can change from an array of ints to a vector of ints to a deque of ints and back again, without ever changing
any client code.
This would mean that three functions for deque would have to be added, another three for list, and so
on.
This is due to problems with getting template resolution correct; I ﬁnd it easier just to give the extra three lines and avoid
confusion.
Hint: unused parameters can be left nameless.
They are a generalization of pointers, but they
are implemented in libstdc++ as separate classes.
Keeping that simple fact in mind as you design your code will prevent a whole lot of difﬁcult-to-understand bugs.
You can think of it the other way ’round, even.
Since iterators are a generalization, that means that pointers are iterators, and that
pointers can be used whenever an iterator would be.
All those functions in the Algorithms section of the Standard will work just
as well on plain arrays and their pointers.
That doesn’t mean that when you pass in a pointer, it gets wrapped into some special delegating iterator-to-pointer class with a
layer of overhead.
Oh, no; if you pass
in a pointer, then the compiler will instantiate that template using T* as a type, and good old high-speed pointer arithmetic as its
operations, so the resulting code will be doing exactly the same things as it would be doing if you had hand-coded it yourself (for
the 273rd time).
How much overhead is there when using an iterator class?
Very little.
Most of the layering classes contain nothing but typedefs,
and typedefs are "meta-information" that simply tell the compiler some nicknames; they don’t create code.
That information gets
passed down through inheritance, so while the compiler has to do work looking up all the names, your runtime code does not.
Trust me.
First, some history, and a reminder of some of the funkier rules in C and C++ for builtin arrays.
The following rules have always
been true for both languages:
1.
You can point anywhere in the array, or to the ﬁrst element past the end of the array.
A pointer that points to one past the
end of the array is guaranteed to be as unique as a pointer to somewhere inside the array, so that you can compare such
pointers safely.
If your array pointer points outside the array -- even to just
one past the end -- and you dereference it, Bad Things happen.
Strictly speaking, simply pointing anywhere else invokes undeﬁned behavior.
Most programs won’t puke until such a
pointer is actually dereferenced, but the standards leave that up to the platform.
The reason this past-the-end addressing was allowed is to make it easy to write a loop to go over an entire array, e.g., while (*d++
= *s++);.
So, when you think of two pointers delimiting an array, don’t think of them as indexing 0 through n-1.
This is bad.
Always having to
|
|
remember to add or subtract one.
This is safe.
This
|
|
is guaranteed to work.
Just don’t
|
|
dereference ’end’.
Everything between the boundary markers is chapter of the array.
Simple.
Now think back to your junior-high school algebra course, when you were learning how to draw graphs.
Remember that a
graph terminating with a solid dot meant, "Everything up through this point," and a graph terminating with an open dot meant,
"Everything up to, but not including, this point," respectively called closed and open ranges?
Remember how closed ranges were
written with brackets, [a,b], and open ranges were written with parentheses, (a,b)?
The boundary markers for arrays describe a half-open range, starting with (and including) the ﬁrst element, and ending with (but
not including) the last element: [beginning,end).
See, I told you it would be simple in the end.
Iterators, and everything working with iterators, follows this same time-honored tradition.
A container’s begin() method
returns an iterator referring to the ﬁrst element, and its end() method returns a past-the-end iterator, which is guaranteed to be
unique and comparable against any other iterator pointing into the middle of the container.
Container constructors, container methods, and algorithms, all take pairs of iterators describing a range of values on which to
operate.
All of these ranges are half-open ranges, so you pass the beginning iterator as the starting parameter, and the one-past-
the-end iterator as the ﬁnishing parameter.
This generalizes very well.
You can operate on sub-ranges quite easily this way; functions accepting a [ﬁrst,last) range don’t
know or care whether they are the boundaries of an , or whether they only enclose
a few elements from the center.
This approach also makes zero-length sequences very simple to recognize: if the two endpoints
compare equal, then  is empty.
Just don’t dereference end().
This means
two important things:
1.
Anything that behaves like an iterator can be used in one of these algorithms.
Raw pointers make great candidates, thus
built-in arrays are ﬁne containers, as well as your own iterators.
The algorithms do not (and cannot) affect the container as a whole; only the things between the two iterator endpoints.
If
you pass a range of iterators only enclosing the middle third of a container, then anything outside that range is inviolate.
Even strings can be fed through the algorithms here, although the string class has specialized versions of many of these functions
(for example, string::find()).
Most of the examples on this page will use simple arrays of integers as a playground for
algorithms, just to keep things simple.
The use of N as a size in the examples is to keep things easy to read but probably won’t
be valid code.
You can use wrappers such as those described in the containers section to keep real code readable.
The single thing that trips people up the most is the deﬁnition of range used with iterators; the famous "past-the-end" rule that
everybody loves to hate.
The iterators section of this document has a complete explanation of this simple rule that seems to cause
so much confusion.
Once you get range into your head (it’s not that hard, honest!), then the algorithms are a cakewalk.
This allows member functions of each container class to take over, and containers’ swap functions should have O(1) complexity
according to the standard.
This should not be surprising, since for two containers of the same type to swap
contents, only some internal pointers to storage need to be exchanged.
David Tribble has compiled a list of C++98 and C99 conﬂict points; his description of C’s new
type versus those of C++ and how to get them playing together nicely is here.
As long as you meet that and some other basic requirements,
then the resulting instantiation has all of the usual math operators deﬁned, as well as deﬁnitions of op<< and op>> that work
with iostreams: op<< prints (u,v) and op>> can read u, (u), and (u,v).
As an extension to C++11 and for increased compatibility with C, <complex.h> includes both <complex> and the C99
<complex.h> (if the C library provides it).

There are four generalized functions in the <numeric> header that follow the same conventions as those in <algorithm>.
Each
of them is overloaded: one signature for common default operations, and a second for fully general operations.
Their names are
self-explanatory to anyone who works with numerics on a regular basis:
• accumulate
• inner_product
• partial_sum
• adjacent_difference
Here is a simple example of the two forms of accumulate.
The second does the same, but uses
someval as the starting value (thus, sum_stuff == sum + someval).
The ﬁnal call uses the second of the two signa-
tures, and multiplies all the members of the array; here we must obviously use 1 as a starting value instead of 0.
The other three functions have similar dual-signature forms.
C99 adds a new keyword, restrict, to apply to individual
pointers.
The C++ solution is contained in the library rather than the language (although many vendors can be expected to add
this to their compilers as an extension).
That library solution is a set of two classes, ﬁve template classes, and "a whole bunch" of functions.
The classes are required to
be free of pointer aliasing, so compilers can optimize the daylights out of them the same way that they have been for FORTRAN.
They are collectively called valarray, although strictly speaking this is only one of the ﬁve template classes, and they are
designed to be familiar to people who have worked with the BLAS libraries before.
In addition to the other topics on this page, we’ll note here some of the C99 features that appear in libstdc++.
The C99 features depend on the --enable-c99 conﬁgure ﬂag.
This ﬂag is already on by default, but it can be disabled by the
user.
Also, the conﬁguration machinery will disable it if the necessary support for C99 (e.g., header ﬁles) cannot be found.
As of GCC 3.0, C99 support includes classiﬁcation functions such as isnormal, isgreater, isnan, etc.
The functions
used for ’long long’ support such as strtoll are supported, as is the lldiv_t typedef.
Also supported are the wide character
functions using ’long long’, like wcstoll.
Many people
simply include <iostream> when they don’t need to -- and that can penalize your runtime as well.
Here are some tips on
which header to use for which situations, starting with the simplest.
For example,
#include <iosfwd>
class MyClass
{
....
The ios_base class is what holds the format ﬂags, the state ﬂags, and the functions which change them (setf(), width(),
precision(), etc).
You can also store extra data and register callback functions through ios_base, but that has been
historically underused.
Anything which doesn’t depend on the type of characters stored is consolidated here.
The class template basic_ios is the highest class template in the hierarchy; it is the ﬁrst one depending on the character type,
and holds all general state associated with that type: the pointer to the polymorphic stream buffer, the facet information, etc.
<streambuf> declares the class template basic_streambuf, and two standard instantiations, streambuf and wstreambuf.
If you need to work with the vastly useful and capable stream buffer classes, e.g., to create a new form of storage transport, this
header is the one to include.
For example,
#include <istream>
std::ostream& operator<< (std::ostream& os, MyClass& c)
{
return os << c.data1() << c.data2();
}

The std::istream and std::ostream classes are the abstract parents of the various concrete implementations.
If you are only using
the interfaces, then you only need to use the appropriate interface header.
If you need to write expressions like os << setw(3); or is >>
setbase(8);, you must include <iomanip>.
As they are the standard concrete descendants
of istream and ostream, you will already know about them.
Finally, <iostream> provides the eight standard global objects (cin, cout, etc).
To do this correctly, this header also
provides the contents of the <istream> and <ostream> headers, but nothing else.
The contents of this header look like:
#include <ostream>
#include <istream>
namespace std
{
extern istream cin;
extern ostream cout;
....
Like any other global object, they must be initialized once and only once.
This is typically
done with a construct like the one above, and the nested class ios_base::Init is speciﬁed in the standard for just this reason.
How does it work?
Because the header is included before any of your code, the __foo object is constructed before any of your
objects.
The ﬁrst time the
constructor runs, the eight stream objects are set up.
The static keyword means that each object ﬁle compiled from a source ﬁle containing <iostream> will have its own private
copy of __foo.
There is no speciﬁed order of construction across object ﬁles (it’s one of those pesky NP complete problems that
make life so interesting), so one copy in each object ﬁle means that the stream objects are guaranteed to be set up before any of
your code which uses them could run, thereby meeting the requirements of the standard.
The time
spent is merely for an increment-and-test inside a function call, but over several dozen or hundreds of object ﬁles, that time can
add up.
The lesson?
Only include <iostream> when you need to use one of the standard objects in that source ﬁle; you’ll pay less
startup time.
Only include the header ﬁles you need to in general; your compile times will go down when there’s less parsing
work to do.


Creating your own stream buffers for I/O can be remarkably easy.
If you are interested in doing so, we highly recommend two
very excellent books: Standard C++ IOStreams and Locales by Langer and Kreft, ISBN 0-201-18395-1, and The C++ Standard
Library by Nicolai Josuttis, ISBN 0-201-37926-0.
Both are published by Addison-Wesley, who isn’t paying us a cent for saying
that, honest.
Here is a simple example, io/outbuf1, from the Josuttis text.
It transforms everything sent through it to uppercase.
More examples can be found in 3.1.x code, in include/ext/*_filebuf.h, and in the article Filtering
Streambufs by James Kanze.
Particularly the fact that C++ may not, in fact, have anything to do with it?
Many people think that writing a newline to an output stream automatically ﬂushes the output buffer.
This is true only when the
output stream is, in fact, a terminal and not a ﬁle or some other device -- and that may not even be true since C++ says nothing
about ﬁles nor terminals.
All of that is system-dependent.
Some people also believe that sending endl down an output stream only writes a newline.
This is incorrect; after a newline
is written, the buffer is also ﬂushed.
You could make the code prettier by moving the single newline
to the start of the quoted text on the last line, for example.
If you do need to ﬂush the buffer above, you can send an endl if you also need a newline, or just ﬂush the buffer yourself:
output << ...... << flush;
// can use std::flush manipulator
output.flush();
// or call a member fn
On the other hand, there are times when writing to a ﬁle should be like writing to standard error; no buffering should be done
because the data needs to appear quickly (a prime example is a log ﬁle for security-related information).
The way to do this is
just to turn off the buffering before any I/O operations at all have been done (note that opening counts as an I/O operation):
std::ofstream
os;
std::ifstream
is;
int
i;
os.rdbuf()->pubsetbuf(0,0);
is.rdbuf()->pubsetbuf(0,0);
os.open("/foo/bar/baz");
is.open("/qux/quux/quuux");
...
Then the public version of setbuf can be called.
The arguments are the same as those for the Standard C I/O Library function
(a buffer area followed by its size).
A great deal of this is implementation-dependent.
For example, streambuf does not specify any actions for its own setbuf()-
ish functions; the classes derived from streambuf each deﬁne behavior that "makes sense" for that class: an argument of (0,0)
turns off buffering for filebuf but does nothing at all for its siblings stringbuf and strstreambuf, and specifying
anything other than (0,0) has varying effects.
User-deﬁned classes derived from streambuf can do whatever they want.
A last reminder: there are usually more buffers involved than just those at the language/library level.
Kernel buffers, disk buffers,
and the like will also have an effect.
Inspecting and changing those are system-dependent.


Stringstreams (deﬁned in the header <sstream>) are in this author’s opinion one of the coolest things since sliced time.
An
example of their use is in the Received Wisdom section for Sect1 21 (Strings), describing how to format strings.
The quick deﬁnition is: they are siblings of ifstream and ofstream, and they do for std::string what their siblings do for
ﬁles.
All that work you put into writing << and >> functions for your classes now pays off again!
Need to format a string before
passing the string to a function?
Send your stuff via << to an ostringstream.
You’ve read a string as input and need to parse it?
Initialize an istringstream with that string, and then pull pieces out of it with >>.
Have a stringstream and need to get a copy of
the string inside?
Just call the str() member function.
This only works if you’ve written your <</>> functions correctly, though, and correctly means that they take istreams and
ostreams as parameters, not ifstreams and ofstreams.
If they take the latter, then your I/O operators will work ﬁne with ﬁle
streams, but with nothing else -- including stringstreams.
If you are a user of the strstream classes, you need to update your code.
You don’t have to explicitly append ends to terminate
the C-style character array, you don’t have to mess with "freezing" functions, and you don’t have to manage the memory yourself.
The strstreams have been ofﬁcially deprecated, which means that 1) future revisions of the C++ Standard won’t support them,
and 2) if you use them, people will laugh at you.
And since this is C++, you have an open
ifstream (call it IN) and an open ofstream (call it OUT):
#include <fstream>
std::ifstream
IN ("input_file");
std::ofstream
OUT ("output_file");
Here’s the easiest way to get it completely wrong:
OUT << IN;
For those of you who don’t already know why this doesn’t work (probably from having done it before), I invite you to quickly
create a simple text ﬁle called "input_ﬁle" containing the sentence
The quick brown fox jumped over the lazy dog.
surrounded by blank lines.
Code it up and try it.
The contents of "output_ﬁle" may surprise you.
Seriously, go do it.
Get surprised, then come back.
It’s worth it.
The thing to remember is that the basic_[io]stream classes handle formatting, nothing else.
In particular, they break up
on whitespace.
The actual reading, writing, and storing of data is handled by the basic_streambuf family.
Fortunately, the
operator<< is overloaded to take an ostream and a pointer-to-streambuf, in order to help with just this kind of "dump the data
verbatim" situation.
Why a pointer to streambuf and not just a streambuf?
Well, the [io]streams hold pointers (or references, depending on the
implementation) to their buffers, not the actual buffers.
This allows polymorphic behavior on the chapter of the buffers as well
as the streams themselves.
The pointer is easily retrieved using the rdbuf() member function.
So what was happening with OUT<<IN?
Undeﬁned behavior, since that particular << isn’t deﬁned by the Standard.
I have
seen instances where it is implemented, but the character extraction process removes all the whitespace, leaving you with no
blank lines and only "Thequickbrownfox...".
With libraries that do not deﬁne that operator, IN (or one of IN’s member pointers)
sometimes gets converted to a void*, and the output ﬁle then contains a perfect text representation of a hexadecimal address
(quite a big surprise).
Others don’t compile at all.
Also note that none of this is speciﬁc to o*f*streams.
The operators shown above are all deﬁned in the parent basic_ostream class
and are therefore available with all possible descendants.
It is not a silver bullet, and will not allow you to use the <</>> operators of the normal fstreams
to do binary I/O.
Sorry.
Them’s the breaks.
This isn’t going to try and be a complete tutorial on reading and writing binary ﬁles (because "binary" covers a lot of ground),
but we will try and clear up a couple of misconceptions and common errors.
First, ios::binary has exactly one deﬁned effect, no more and no less.
Normal text mode has to be concerned with the
newline characters, and the runtime system will translate between (for example) ’\n’ and the appropriate end-of-line sequence
(LF on Unix, CRLF on DOS, CR on Macintosh, etc).
Binary mode is not supposed to suddenly give you a bitstream, and if it is doing so in your
program then you’ve discovered a bug in your vendor’s compiler (or some other chapter of the C++ implementation, possibly the
runtime system).
Second, using << to write and >> to read isn’t going to work with the standard ﬁle stream classes, even if you use skipws
during reading.
Why not?
Because ifstream and ofstream exist for the purpose of formatting, not reading and writing.
Their job
is to interpret the data into text characters, and that’s exactly what you don’t want to happen during binary I/O.
Third, using the get() and put()/write() member functions still aren’t guaranteed to help you.
These are "unformatted"
I/O functions, but still character-based.
This is a Bad Thing, because while the compiler would probably be just ﬁne with it, other humans are going to be confused.
The overloaded bitshift operators have a well-deﬁned meaning (formatting), and this breaks it.
While not trivial for the beginner, this is the best of all solutions.
The streambuf/ﬁlebuf layer is the layer that is responsible for
actual I/O.
If you want to use the C++ library for binary I/O, this is where you start.
How to go about using streambufs is a bit beyond the scope of this document (at least for now), but while streambufs go a long
way, they still leave a couple of things up to you, the programmer.
As an example, byte ordering is completely between you and
the operating system, and you have to handle it yourself.
Deriving a streambuf or ﬁlebuf class from the standard ones, one that is speciﬁc to your data types (or an abstraction thereof)
is probably a good idea, and lots of examples exist in journals and on Usenet.
Using the standard ﬁlebufs directly (either by
declaring your own or by using the pointer returned from an fstream’s rdbuf()) is certainly feasible as well.
One area that causes problems is trying to do bit-by-bit operations with ﬁlebufs.
C++ is no different from C in this respect: I/O
must be done at the byte level.
If you’re trying to read or write a few bits at a time, you’re going about it the wrong way.
You
must read/write an integral number of bytes and then process the bytes.
Another area of problems is opening text ﬁles in binary mode.
Generally, binary mode is intended for binary ﬁles, and opening
text ﬁles in binary mode means that you now have to deal with all of those end-of-line and end-of-ﬁle problems that we mentioned
before.
An instructive thread from comp.lang.c++.moderated delved off into this topic starting more or less at this post and continuing
to the end of the thread.
Take
special note of the replies by James Kanze and Dietmar Kühl.
Brieﬂy, the problems of byte ordering and type sizes mean that the unformatted functions like ostream::put() and istream::get
cannot safely be used to communicate between arbitrary programs, or across a network, or from one invocation of a program to
another invocation of the same program on a different platform, etc.


See the extensions for using FILE and ﬁle descriptors with ofstream and ifstream.
Ditch C.
It sounds like a ﬂame on C, but it isn’t.
Really.
Calm down.
I’m just saying it to get your attention.
Because the C++ library includes the C library, both C-style and C++-style I/O have to work at the same time.
For example:
#include <iostream>
#include <cstdio>
std::cout << "Hel";
std::printf ("lo, worl");
std::cout << "d!\n";
This must do what you think it does.
Alert members of the audience will immediately notice that buffering is going to make a hash of the output unless special steps
are taken.
The special steps taken by libstdc++, at least for version 3.0, involve doing very little buffering for the standard streams, leaving
most of the buffering to the underlying C library.
The upside is that correctness is
ensured.
I/O library (as it is for 3.0 by default).
Some patches have been applied which improve the situation for
3.1.
However, the C and C++ standard streams only need to be kept in sync when both libraries’ facilities are in use.
If your program
only uses C++ I/O, then there’s no need to sync with the C streams.
The right thing to do in this case is to call
#include any of the I/O headers such as ios, iostream, etc
std::ios::sync_with_stdio(false);
You must do this before performing any I/O via the C++ stream objects.
Once you call this, the C++ streams will operate
independently of the (unused) C streams.
For GCC 3.x, this means that cout and company will become fully buffered on their
own.
Note, by the way, that the synchronization requirement only applies to the standard streams (cin, cout, cerr, clog, and their
wide-character counterparts).
File stream objects that you declare yourself have no such requirement and are fully buffered.
Set of typedefs that map int to atomic_int, and so on for all builtin integral types.
Global enumeration memory_order to
control memory ordering.
Also includes atomic, a class template with member functions such as load and store that is
instantiable such that atomic_int is the base class of atomic<int>.
Full API details.
In header mutex, class template mutex and variants, class once_flag, and class template unique_lock.
In header condition_variable, classes condition_variable and condition_variable_any.
In header thread, class thread and namespace this_thread.
In header future, class template future and class template shared_future, class template promise, and packaged_task.
Full API details.
Some of these are from older versions of
standard library components, namely SGI’s STL, and some of these are GNU’s.
Before you leap in and use any of these extensions, be aware of two things:
1.
Non-Standard means exactly that.
The behavior, and the very existence, of these extensions may change with little or no warning.
Also, other platforms, other compilers, other versions of g++ or libstdc++
may not recognize these names, or treat them differently, or...
You should know how to access these headers properly.
In 1999, SGI added concept checkers to their implementation of the STL: code which checked the template parameters of
instantiated pieces of the STL, in order to insure that the parameters being used met the requirements of the standard.
For
example, the Standard requires that types passed as template parameters to vector be “Assignable” (which means what you
think it means).
The checking was done during compilation, and none of the code was executed at runtime.
Unfortunately, the size of the compiler ﬁles grew signiﬁcantly as a result.
The checking code itself was cumbersome.
And bugs
were found in it on more than one occasion.
The primary author of the checking code, Jeremy Siek, had already started work on a replacement implementation.
The new
code has been formally reviewed and accepted into the Boost libraries, and we are pleased to incorporate it into the GNU C++
library.
The new version imposes a much smaller space overhead on the generated object ﬁle.
The checks are also cleaner and easier to
read and understand.
They are off by default for all versions of GCC from 3.0 to 3.4 (the latest release at the time of writing).
They can be
enabled at conﬁgure time with --enable-concept-checks.
Please note that the concept checks only validate the requirements of the old C++03 standard.
C++11 was expected to have
ﬁrst-class support for template parameter constraints based on concepts in the core language.
This would have obviated the need
for the library-simulated concept checking described above, but was not part of C++11.
This means that programs that incorrectly use the C++ standard library will exhibit behavior that is not portable
and may not even be predictable, because they tread into implementation-speciﬁc or undeﬁned behavior.
To detect some of these
errors before they can become problematic, libstdc++ offers a debug mode that provides additional checking of library facilities,
and will report errors in the use of libstdc++ as soon as they can be detected by emitting a description of the problem to standard
error and aborting the program.
This debug mode is available with GCC and later versions.
Safe iterators: Iterators keep track of the container whose elements they reference, so errors such as incrementing a past-the-end
iterator or dereferencing an iterator that points to a container that has been destructed are diagnosed immediately.
Algorithm preconditions: Algorithms attempt to validate their input parameters to detect errors as early as possible.
For in-
stance, the set_intersection algorithm requires that its iterator parameters first1 and last1 form a valid iterator
range, and that the sequence [first1, last1) is sorted according to the same predicate that was passed to set_intersection;
the libstdc++ debug mode will detect an error if the sequence is not sorted or was sorted by a different predicate.

A program that uses the C++ standard library correctly will maintain the same semantics under debug mode as it had with the
normal (release) library.
All functional and exception-handling guarantees made by the normal library also hold for the debug
mode library, with one exception: performance guarantees made by the normal library may not hold in the debug mode library.
For instance, erasing an element in a std::list is a constant-time operation in normal library, but in debug mode it is linear
in the number of iterators that reference that particular list.
So while your (correct) program won’t change its results, it is likely
to execute more slowly.
libstdc++ includes many extensions to the C++ standard library.
In some cases the extensions are obvious, such as the hashed
associative containers, whereas other extensions give predictable results to behavior that would otherwise be undeﬁned, such
as throwing an exception when a std::basic_string is constructed from a NULL character pointer.
This latter category
also includes implementation-deﬁned and unspeciﬁed semantics, such as the growth rate of a vector.
Use of these extensions
is not considered incorrect, so code that relies on them will not be rejected by debug mode.
However, use of these extensions
may affect the portability of code to other implementations of the C++ standard library, and is therefore somewhat hazardous.
For this reason, the libstdc++ debug mode offers a "pedantic" mode (similar to GCC’s -pedantic compiler ﬂag) that attempts
to emulate the semantics guaranteed by the C++ standard.
For instance, constructing a std::basic_string with a NULL
character pointer would result in an exception under normal mode or non-pedantic debug mode (this is a libstdc++ extension),

whereas under pedantic debug mode libstdc++ would signal an error.
The following library components provide extra debugging capabilities in debug mode:
• std::array (no safe iterators)
• std::basic_string (no safe iterators and see note below)
• std::bitset
• std::deque
• std::list
• std::map
• std::multimap
• std::multiset
• std::set
• std::vector
• std::unordered_map
• std::unordered_multimap
• std::unordered_set
• std::unordered_multiset
N.B.
This is because libstdc++ uses GCC’s
extern template extension to provide explicit instantiations of std::string and std::wstring, and those explicit
instantiations don’t include the debug-mode checks.
If the containing functions are inlined then the checks will run, so compiling
with -O1 might be enough to enable them.
Alternatively -D_GLIBCXX_EXTERN_TEMPLATE=0 will suppress the declara-
tions of the explicit instantiations and cause the functions to be instantiated with the debug-mode checks included, but this is
unsupported and not guaranteed to work.
For full debug-mode support you can use the __gnu_debug::basic_string
debugging container directly, which always works correctly.
Note that this ﬂag
changes the sizes and behavior of standard class templates such as std::vector, and therefore you can only link code
compiled with debug mode and code compiled without debug mode if no instantiation of a container is passed between the two
translation units.
By default, error messages are formatted to ﬁt on lines of about 78 characters.
The environment variable GLIBCXX_DEBUG_MESSAGE_
can be used to request a different length.
Note that libstdc++ is able to produce backtraces on error.
It requires that you conﬁgure libstdc++ build with --enable-libstdcxx-
Use -D_GLIBCXX_DEBUG_BACKTRACE to activate it.
You’ll then have to link with libstdc++_libbacktrace static library
(-lstdc++_libbacktrace) to build your application.
These debugging containers are functionally equivalent to the standard drop-in containers used in
debug mode, but they are available in a separate namespace as GNU extensions and may be used in programs compiled with
either release mode or with debug mode.
Debugging Containers
When compiling in C++11 mode (or newer), these containers have additional debug capability.
Because array::iterator is just a pointer, the debug array can’t check iterator operations, it can only check direct
accesses to the container.
That alias is deprecated and may be removed in
a future release.
The following goals directed the design of the libstdc++
debug mode:
• Correctness: the libstdc++ debug mode must not change the semantics of the standard library for all cases speciﬁed in the
ANSI/ISO C++ standard.
The essence of this constraint is that any valid C++ program should behave in the same manner

regardless of whether it is compiled with debug mode or release mode.
In particular, entities that are deﬁned in namespace std
in release mode should remain deﬁned in namespace std in debug mode, so that legal specializations of namespace std entities
will remain valid.
A program that is not valid C++ (e.g., invokes undeﬁned behavior) is not required to behave similarly,
although the debug mode will abort with a diagnostic when it detects undeﬁned behavior.
Performance of the libstdc++ debug mode is secondary (and, in fact, will be worse than the release mode).
It should be easily incorporated into the user’s development
environment (e.g., by requiring only a single new compiler switch) and should produce reasonable diagnostics when it detects
a problem with the user program.
Usability also involves detection of errors when using the debug mode incorrectly, e.g., by
linking a release-compiled object against a debug-compiled object if in fact the resulting program will not run correctly.
This indirectly affects the usefulness of the debug mode,
because debugging some applications may require rebuilding a large amount of code, which may not be feasible when the
suspect code may be very localized.
There are several levels of conformance to this requirement, each with its own usability
and implementation characteristics.
In general, the higher-numbered conformance levels are more usable (i.e., require less
recompilation) but are more complicated to implement than the lower-numbered conformance levels.
Full recompilation: The user must recompile their entire application and all C++ libraries it depends on, including the
C++ standard library that ships with the compiler.
This must be done even if only a small part of the program can use
debugging features.
Full user recompilation: The user must recompile their entire application and all C++ libraries it depends on, but not the
C++ standard library itself.
This must be done even if only a small part of the program can use debugging features.
This
can be achieved given a full recompilation system by compiling two versions of the standard library when the compiler
is installed and linking against the appropriate one, e.g., a multilibs approach.
Partial recompilation: The user must recompile the parts of their application and the C++ libraries it depends on that will
use the debugging facilities directly.
This means that any code that uses the debuggable standard containers would need to
be recompiled, but code that does not use them (but may, for instance, use IOStreams) would not have to be recompiled.
This means that a set of translation
units that accesses a particular standard container instance may either be compiled in release mode (no checking) or
debug mode (full checking), but must all be compiled in the same way; a translation unit that does not see that standard
container instance need not be recompiled.
This also means that a translation unit A that contains a particular instantiation
(say, std::vector<int>) compiled in release mode can be linked against a translation unit B that contains the same
instantiation compiled in debug mode (a feature not present with partial recompilation).
While this behavior is technically
a violation of the One Deﬁnition Rule, this ability tends to be very important in practice.
The libstdc++ debug mode
supports this level of recompilation.
This has also been dubbed "-g mode", because the -g compiler switch
works in this way, emitting debugging information at a per--translation-unit granularity.
We believe that this level of
recompilation is in fact not possible if we intend to supply safe iterators, leave the program semantics unchanged, and
not regress in performance under release mode because we cannot associate extra information with an iterator (to form
a safe iterator) without either reserving that space in release mode (performance regression) or allocating extra memory
associated with each iterator with new (changes the program semantics).
The debugging components ﬁrst verify that the

operation is correct (aborting with a diagnostic if an error is found) and will then forward to the underlying release-mode con-
tainer that will perform the actual work.
This design decision ensures that we cannot regress release-mode performance (because
the release-mode containers are left untouched) and partially enables mixing debug and release code at link time, although that
will not be discussed at this time.
Two types of wrappers are used in the implementation of the debug mode: container wrappers and iterator wrappers.
The two
types of wrappers interact to maintain relationships between iterators and their associated containers, which are necessary to
detect certain types of standard library usage errors such as dereferencing past-the-end iterators or inserting into a container
using an iterator from a different container.
Because iterators have a well-deﬁned, common interface the iterator wrapper is implemented with the iterator adaptor
class template __gnu_debug::_Safe_iterator, which takes two template parameters:
• Iterator: The underlying iterator type, which must be either the iterator or const_iterator typedef from the
sequence type this iterator can reference.
This sequence must be a safe sequence (discussed below)
whose iterator or const_iterator typedef is the type of the safe iterator.
Container wrappers provide a debugging layer over a particular container type.
Because containers vary greatly in the mem-
ber functions they support and the semantics of those member functions (especially in the area of iterator invalidation), con-
tainer wrappers are tailored to the container they reference, e.g., the debugging version of std::list duplicates the en-
tire interface of std::list, adding additional semantic checks and then forwarding operations to the real std::list
(a public base class of the debugging version) as appropriate.
However, all safe containers inherit from the class template
__gnu_debug::_Safe_sequence, instantiated with the type of the safe container itself (an instance of the curiously re-
curring template pattern).
The iterators of a container wrapper will be safe iterators that reference sequences of this type and wrap the iterators provided by
the release-mode base class.
The debugging container will use only the safe iterators within its own interface (therefore requiring
the user to use safe iterators, although this does not change correct user code) and will communicate with the release-mode base
class with only the underlying, unsafe, release-mode iterators that the base class exports.
Base::const_iterator, _Self>
←�
const_iterator;
// duplicate std::list interface with debugging semantics
};

17.Precondition Checking
The debug mode operates primarily by checking the preconditions of all standard library operations that it supports.
Preconditions are validated using any additional information available at run-time, e.g., the containers that
are associated with a particular iterator, the position of the iterator within those containers, the distance between two iterators
that may form a valid range, etc.
In the absence of suitable information, e.g., an input iterator that is not a safe iterator, these
precondition checks will silently succeed.
The majority of precondition checks use the aforementioned macros, which have the secondary beneﬁt of having prewritten
debug messages that use information about the current status of the objects involved (e.g., whether an iterator is singular or
what sequence it is attached to) along with some static information (e.g., the names of the function parameters correspond-
ing to the objects involved).
When not using these macros, the debug mode uses either the debug-mode assertion macro
_GLIBCXX_DEBUG_ASSERT , its pedantic cousin _GLIBCXX_DEBUG_PEDASSERT, or the assertion check macro that sup-
ports more advance formulation of error messages, _GLIBCXX_DEBUG_VERIFY.
These macros are documented more thor-
oughly in the debug mode source code.
This guarantee minimizes the recompilation that users are required to perform, shortening the detect-compile-debug bug
hunting cycle and making the debug mode easier to incorporate into development environments by minimizing dependencies.
To achieve this goal we use inline namespaces and
a complex organization of debug- and release-modes.
The end result is that we have achieved per-use recompilation but have had
to give up some checking of the std::basic_string class template (namely, safe iterators).
However, only one of these components should be user-visible at any particular
time with the standard name, e.g., std::list.
In release mode, we deﬁne only the release-mode version of the component with its standard name and do not include the
debugging component at all.
The release mode version is deﬁned within the namespace std.
Minus the namespace associations,
this method leaves the behavior of release mode completely unchanged from its behavior prior to the introduction of the libstdc++
debug mode.
Tp, typename _Alloc = allocator<_Tp> >
class ;
} // namespace std
In debug mode we include the release-mode container (which is now deﬁned in the namespace __cxx1998) and also the debug-
mode container.
This method allows the debug and release versions of the same
component to coexist at compile-time and link-time without causing an unreasonable maintenance burden, while minimizing
confusion.
However, components that are deﬁned and used within the C++ standard library itself face additional constraints.
For instance,
some of the member functions of
std::moneypunct return std::basic_string.
Normally, this is not a problem, but
with a mixed mode standard library that could be using either debug-mode or release-mode
basic_string objects, things
get more complicated.
As the return value of a function is not encoded into the mangled name, there is no way to specify a
release-mode or a debug-mode string.
In practice, this results in runtime errors.
A simpliﬁed example of this problem is as
follows.
Take this translation unit, compiled in debug-mode:
// -D_GLIBCXX_DEBUG
#include <string>
std::string test02();
std::string test01()
{
return test02();
}
int main()
{
test01();
return 0;
}
... and linked to this translation unit, compiled in release mode:
#include <string>
std::string
test02()
{
return std::string("toast");
}

For this reason we cannot easily provide safe iterators for the std::basic_string class template, as it is present throughout
the C++ standard library.
For instance, locale facets deﬁne typedefs that include basic_string: in a mixed debug/release
program, should that typedef be based on the debug-mode basic_string or the release-mode basic_string?
While the
answer could be "both", and the difference hidden via renaming a la the debug/release containers, we must note two things about
locale facets:
1.
They exist as shared state: one can create a facet in one translation unit and access the facet via the same type name in a
different translation unit.
This means that we cannot have two different versions of locale facets, because the types would
not be the same across debug/release-mode translation unit barriers.
They have virtual functions returning strings: these functions mangle in the same way regardless of the mangling of their
return types (see above), and their precise signatures can be relied upon by users because they may be overridden in derived
classes.
With the design of libstdc++ debug mode, we cannot effectively hide the differences between debug and release-mode strings
from the user.
Failure to hide the differences may result in unpredictable behavior, and for this reason we have opted to only
perform basic_string changes that do not require ABI changes.
The effect on users is expected to be minimal, as there are
simple alternatives (e.g., __gnu_debug::basic_string), and the usability beneﬁt we gain from the ability to mix debug-
and release-compiled translation units is enormous.
The following is a partial list of solutions, with justiﬁcations for our rejection of each.
This solution has an extreme negative affect on
usability, because it is quite likely that some libraries an application depends on cannot be recompiled easily.
This would not
meet our usability or minimize recompilation criteria well.
This option would break conformance with the C++ standard in both debug and release modes.
This would not meet
our correctness criteria.
However, this has two drawbacks: ﬁrst, there is a conformance issue because the default allocator would
not be the standard-speciﬁed std::allocator<T>.
Secondly (and more importantly), users that specify allocators instead
of implicitly using the default allocator would not get debugging containers.
Thus this solution fails the correctness criteria.
However, there is no true template
aliasing mechanism in C++, because both using directives and using declarations disallow specialization.
This method fails
the correctness criteria.
Use implementation-speciﬁc properties of anonymous namespaces.
See this post.
This method fails the correctness criteria.
While this will solve some renaming problems and ensure that debug- and release-compiled code cannot be mixed unsafely, it
ensures that debug- and release-compiled code cannot be mixed at all.
For instance, the program would have two std::cout
objects!
This solution would fails the minimize recompilation requirement, because we would only be able to support option
(1) or (2).
This option involves complicated re-naming between debug-mode and release-mode components at
compile time, and then a g++ extension called link name to recover the original names at link time.
There are two drawbacks to
this approach.
One, it’s very verbose, relying on macro renaming at compile time and several levels of include ordering.
Two,
ODR issues remained with container member functions taking no arguments in mixed-mode settings resulting in equivalent
link names,
vector::push_back()
being one example.
See proof-of-concept using link name.
This list may be expanded over time to include other options that we could have implemented, but in all cases the
full ramiﬁcations of the approach (as measured against the design goals for a libstdc++ debug mode) should be considered ﬁrst.
The DejaGNU testsuite includes some testcases that check for known problems with some solutions (e.g., the using declaration
solution that breaks user specialization), and additional testcases will be added as we are able to identify other typical problem
cases.
These test cases will serve as a benchmark by which we can compare debug mode implementations.
The existing implementations include:
• SafeSTL: SafeSTL was the original debugging version of the Standard Template Library (STL), implemented by Cay S.
Horstmann on top of the Hewlett-Packard STL.
Though it inspired much work in this area, it has not been kept up-to-date for
use with modern compilers or C++ standard library implementations.
It includes a debug mode that uses a wrapper model (that in some ways inspired the libstdc++ debug
mode design), although at the time of this writing the debug mode is somewhat incomplete and meets only the "Full user
recompilation" (2) recompilation guarantee by requiring the user to link against a different library in debug mode vs. release
mode.
It is a
full debug-mode implementation (including debugging for CodeWarrior extensions) and is easy to use, although it meets only
the "Full recompilation" (1) recompilation guarantee.
Several of the standard algorithms, for instance std::sort, are made parallel using OpenMP annotations.
These parallel mode
constructs can be invoked by explicit source declaration or by compiling existing sources with a speciﬁc compiler ﬂag.
Note
The parallel mode has not been kept up to date with recent C++ standards and so it only conforms to the C++03 requirements.
That means that move-only predicates may not work with parallel mode algorithms, and for C++20 most of the algorithms
cannot be used in constexpr functions.
For C++17 and above there are new overloads of the standard algorithms which take an execution policy argument.
You should
consider using those instead of the non-standard parallel mode extensions.
The parallel mode STL algorithms are currently not exception-safe, i.e. user-deﬁned functors must not throw exceptions.
Also,
the order of execution is not guaranteed for some functions, of course.
Therefore, user-deﬁned functors should not have any
concurrent side effects.
Since the current GCC OpenMP implementation does not support OpenMP parallel regions in concurrent threads, it is not
possible to call parallel STL algorithm in concurrent threads, either.
It might work with other compilers, though.
Adding
this support is not difﬁcult: just compile your application with the compiler ﬂag -fopenmp.
This will link in libgomp, the
GNU Ofﬂoading and Multi Processing Runtime Library, whose presence is mandatory.
In addition, hardware that supports atomic operations and a compiler capable of producing atomic operations is mandatory: GCC
defaults to no support for atomic operations on some common hardware architectures.
Activating atomic operations may require
explicit compiler ﬂags on some targets (like sparc and x86), such as -march=i686, -march=native or -mcpu=v9.
See
the GCC manual for more information.
This will convert all use of the standard (sequential) algorithms to the appropriate parallel
equivalents.
Please note that this doesn’t necessarily mean that everything will end up being executed in a parallel manner, but
rather that the heuristics and settings coded into the parallel versions will be used to determine if all, some, or no algorithms will
be executed using parallel variants.
Note that the _GLIBCXX_PARALLEL deﬁne may change the sizes and behavior of standard class templates such as std::search,
and therefore one can only link code compiled with parallel mode and code compiled without parallel mode if no instantiation of
a container is passed between the two translation units.
Parallel mode functionality has distinct linkage, and cannot be confused
with normal mode symbols.
These parallel algorithms are functionally equivalent to the standard drop-in
algorithms used in parallel mode, but they are available in a separate namespace as GNU extensions and may be used in programs
compiled with either release mode or with parallel mode.
FIter>
_FIter
adjacent_find(_FIter, _FIter);
}
Which means that there should be something equivalent for the parallel version.
But.... why the ellipses?
The ellipses in the example above represent additional overloads required for the parallel version of the function.
These additional
overloads are used to dispatch calls from the ISO C++ function signature to the appropriate parallel function (or sequential
function, if no parallel functions are deemed worthy), based on either compile-time or run-time conditions.
The available signature options are speciﬁc for the different algorithms/algorithm classes.
The general view of overloads for the parallel algorithms look like this:
• ISO C++ signature
• ISO C++ signature + sequential_tag argument
• ISO C++ signature + algorithm-speciﬁc tag type (several signatures)
Please note that the implementation may use additional functions (designated with the _switch sufﬁx) to dispatch from the
ISO C++ signature to the correct parallel version.
Also, some of the algorithms do not have support for run-time conditions, so
the last overload is therefore missing.

18.Setting up the OpenMP Environment
Several aspects of the overall runtime environment can be manipulated by standard OpenMP function calls.
To specify the number of threads to be used for the algorithms globally, use the function omp_set_num_threads.
An
example:
#include <stdlib.h>
#include <omp.h>
int main()
{
// Explicitly set number of threads.
Call parallel mode algorithms.
See the next
section for further information.
Other parts of the runtime environment able to be manipulated include nested parallelism (omp_set_nested), schedule kind
(omp_set_schedule), and others.
See the OpenMP documentation for more information.
Like so:
std::sort(v.begin(), v.end(), __gnu_parallel::sequential_tag());
Some parallel algorithm variants can be excluded from compilation by preprocessor deﬁnes.
See the doxygen documentation on
compiletime_settings.h and features.h for details.
For some algorithms, the desired variant can be chosen at compile-time by appending a tag object.
The available options are
speciﬁc to the particular algorithm (class).
For the "embarrassingly parallel" algorithms, there is only one "tag object type", the enum _Parallelism.
This means that the actual par-
allelization strategy is chosen at run-time.
For all tags, the number of threads desired for this call can optionally be passed to the respective tag’s
constructor.
Exact and sampling are the two available splitting strategies.
Multiway mergesort
comes with the two splitting strategies for multi-way merging.
The quicksort options cannot be used for stable_sort.
18.Run Time Settings and Defaults
The default parallelization strategy, the choice of speciﬁc algorithm strategy, the minimum threshold limits for individual parallel
algorithms, and aspects of the underlying hardware can be speciﬁed as desired via manipulation of __gnu_parallel::_Settings
member data.
First off, the choice of parallelization strategy: serial, parallel, or heuristically deduced.
This corresponds to __gnu_parallel::_Set
and is a value of enum __gnu_parallel::_AlgorithmStrategy type.
Choices include: heuristic, force_sequential, and force_parallel.
The default is heuristic.
Next, the sub-choices for algorithm variant, if not ﬁxed at compile-time.
Likewise for setting the minimal threshold for algorithm parallelization.
Parallelism always incurs some overhead.
Thus, it
is not helpful to parallelize operations on very small sets of data.
Because of this, measures are taken to avoid parallelizing
below a certain, pre-determined threshold.
For each algorithm, a minimum problem size is encoded as a variable in the active
__gnu_parallel::_Settings object.
All these conﬁguration variables can be changed by the user, if desired.
There exists one global instance of the class _Settings,
i. e.
It can be read and written by calling __gnu_parallel::_Settings::get and __gnu_parallel::_Set
respectively.
Please note that the ﬁrst call return a const object, so direct manipulation is forbidden.
See <parallel/
settings.h> for complete details.
Do work... all algorithms will be parallelized, always.
Two namespaces contain the parallel mode: std::__parallel and __gnu_parallel.
Parallel implementations of standard components, including template helpers to select parallelism, are deﬁned in namespace
std::__parallel.
For instance, std::transform from algorithm has a parallel counterpart in std::__parallel::tra
from parallel/algorithm.
In addition, these parallel implementations are injected into namespace __gnu_parallel
with using declarations.
Support and general infrastructure is in namespace __gnu_parallel.
More information, and an organized index of types and functions related to the parallel mode on a per-namespace basis, can be
found in the generated source documentation.
To run the conformance and regression tests with the parallel mode active,
make check-parallel
The log and summary ﬁles for conformance testing are in the testsuite/parallel directory.
To run the performance tests with the parallel mode active,

make check-performance-parallel
The result ﬁle for performance testing are in the testsuite directory, in the ﬁle libstdc++_performance.sum.
In
addition, the policy-based containers have their own visualizations, which have additional software dependencies than the usual
bare-boned text ﬁle, and can be generated by using the make doc-performance rule in the testsuite’s Makeﬁle.

[53] Johannes SinglerLeonor Frias, Copyright © 2007 , Workshop on Highly Parallel Processing on a Chip (HPPC)
2007.
Over
time the allocator has evolved and been improved in many ways, in particular it now also does a good job in single-threaded
applications [hereinafter referred to as an ST application].
This is accomplished using ifdef’s on
__GTHREADS).
This allocator is tunable, very ﬂexible, and capable of high-performance.
The aim of this document is to describe - from an application point of view - the "inner workings" of the allocator.
It is possible to use a custom pool datum instead of the default class that is provided.
There are two distinct policy classes, each of which can be used with either type of underlying pool datum.
This means that allocators that are instantiated with
different types, say char and long will both use the same pool.
This is the default policy.
The second policy, __per_type_pool_policy, implements a separate pool for each instantiating type.
Thus, char and
long will use separate pools.
This allows per-type tuning, for instance.
Poolp
This class has the interface required for standard library allocator classes, namely member functions allocate and deallocate,
plus others.


Certain allocation parameters can be modiﬁed, or tuned.
There exists a nested struct __pool_base::_Tune that contains
all these parameters, which include settings for
• Alignment
• Maximum bytes before calling ::operator new directly
• Minimum bytes
• Size of underlying global allocations
• Maximum number of supported threads
• Migration of deallocations to the global free list
• Shunt for global new and delete
Adjusting parameters for a given instance of an allocator can only happen before any allocations take place, when the allocator
itself is initialized.
The very ﬁrst allocate() call will always call the _S_initialize_once() function.
In order to make sure that this function is called
exactly once we make use of a __gthread_once call in MT applications and check a static bool (_S_init) in ST applications.
S_force_new to
true and then returns.
If the GLIBCXX_FORCE_NEW environment variable is not set, both ST and MT applications will: - Calculate the number of
bins needed.
A bin is a speciﬁc power of two size of bytes.
I.e., by default the allocator will deal with requests of up to 128 bytes
(or whatever the value of _S_max_bytes is when _S_init() is called).
This means that there will be bins of the following sizes (in
bytes): 1, 2, 4, 8, 16, 32, 64, 128. - Create the _S_binmap array.
All requests are rounded up to the next "large enough" bin. I.e.,
a request for 29 bytes will cause a block from the "32 byte bin" to be returned to the application.
The purpose of _S_binmap is
to speed up the process of ﬁnding out which bin to use.
I.e., the value of _S_binmap[ 29 ] is initialized to 5 (bin 5 = 32 bytes).
This array consists of bin_records.
There will be as many bin_records in this array as the number
of bins that we calculated earlier.
I.e., if _S_max_bytes = 128 there will be 8 entries.
Each bin_record is then initialized: -
bin_record->ﬁrst = An array of pointers to block_records.
There will be as many block_records pointers as there are maximum
number of threads (in a ST application there is only 1 thread, in a MT application there are _S_max_threads).
This holds the
pointer to the ﬁrst free block for each thread in this bin.
I.e. _S_bin[ n ].ﬁrst[ n ] = NULL;
- Additionally a MT application will: - Create a list of free thread id’s.
The pointer to the ﬁrst entry is stored in _S_thread_freelist_ﬁrst.
The reason for this approach is that the __gthread_self() call will not return a value that corresponds to the maximum number
of threads allowed but rather a process id number or something else.
So what we do is that we create a list of thread_records.
This list is _S_max_threads long and each entry holds a size_t thread_id which is initialized to 1, 2, 3, 4, 5 and so on up to
_S_max_threads.
Each time a thread calls allocate() or deallocate() we call _S_get_thread_id() which looks at the value of
_S_thread_key which is a thread local storage pointer.
S_thread_key variable.
I.e., the ﬁrst thread that calls
allocate will get the ﬁrst record in this list and thus be thread number 1 and will then ﬁnd the pointer to its ﬁrst free 32 byte block
in _S_bin[ 5 ].ﬁrst[ 1 ] When we create the _S_thread_key we also deﬁne a destructor (_S_thread_key_destr) which means that
when the thread dies, this thread_record is returned to the front of this list and the thread id can then be reused if a new thread is
created.
This keeps track of the number
of blocks on a speciﬁc thread’s freelist in each bin.
I.e., if a thread has 12 32-byte blocks on it’s freelists and allocates one of
these, this counter would be decreased to 11.
This keeps track of the number of blocks
currently in use of this size by this thread.
I.e., if a thread has made 678 requests (and no deallocations...) of 32-byte blocks this
counter will read 678.
The above created arrays are now initialized with their initial values.
I.e. _S_bin[ n ].free[ n ] = 0;
- Initialize the mutex of each bin_record: The bin_record->mutex is used to protect the global freelist.
This concept of a global
freelist is explained in more detail in the section "A multi threaded example", but basically this mutex is locked whenever a block
of memory is retrieved or returned to the global freelist for this speciﬁc bin.
This only occurs when a number of blocks are
grabbed from the global list to a thread speciﬁc list or when a thread decides to return some blocks to the global freelist.
This allocator does not explicitly release memory back to the OS, but keeps its own freelists instead.
Because of this, memory debugging programs like valgrind or purify may notice leaks: sorry about this inconvenience.
Operating

systems will reclaim allocated memory at program termination anyway.
If sidestepping this kind of noise is desired, there are
three options: use an allocator, like new_allocator that releases memory while debugging, use GLIBCXX_FORCE_NEW
to bypass the allocator’s internal pools, or use a custom pool datum that releases resources on destruction.
On systems with the function __cxa_atexit, the allocator can be forced to free all memory allocated before program ter-
mination with the member function __pool_type::_M_destroy.
However, because this member function relies on the
precise and exactly-conforming ordering of static destructors, including those of a static local __pool object, it should not be
used, ever, on systems that don’t have the necessary underlying support.
In addition, in practice, forcing deallocation can be
tricky, as it requires the __pool object to be fully-constructed before the object that uses it is fully constructed.
For most (but
not all) STL containers, this works, as an instance of the allocator is constructed as part of a container’s constructor.
However,
this assumption is implementation-speciﬁc, and subject to change.
For an example of a pool that frees memory, see the following
example.

Let’s start by describing how the data on a freelist is laid out in memory.
If the requested size is within limits we start by ﬁnding out from which bin we should serve this request by looking in _S_binmap.
A quick look at _S_bin[ bin ].ﬁrst[ 0 ] tells us if there are any blocks of this size on the freelist (0).
If the freelist is empty (the pointer is NULL) we must get memory from the system and build us a freelist within this memory.
All requests for new memory is made in chunks of _S_chunk_size.
Knowing the size of a block_record and the bytes that this
bin stores we then calculate how many blocks we can create within this chunk, build the list, remove the ﬁrst block, update the
pointer (_S_bin[ bin ].ﬁrst[ 0 ]) and return a pointer to that blocks data.
Deallocation is equally simple; the pointer is casted back to a block_record pointer, lookup which bin to use based on the size,
add the block to the front of the global freelist and update the pointer as needed (_S_bin[ bin ].ﬁrst[ 0 ]).
The decision to add deallocated blocks to the front of the freelist was made after a set of performance measurements that showed
that this is roughly 10% faster than maintaining a set of "last pointers" as well.

In the ST example we never used the thread_id variable present in each block.
Let’s start by explaining the purpose of this in a
MT application.
The concept of "ownership" was introduced since many MT applications allocate and deallocate memory to shared containers
from different threads (such as a cache shared amongst all threads).
This introduces a problem if the allocator only returns
memory to the current threads freelist (I.e., there might be one thread doing all the allocation and thus obtaining ever more
memory from the system and another thread that is getting a longer and longer freelist - this will in the end consume all available
memory).
Each time a block is moved from the global list (where ownership is irrelevant), to a threads freelist (or when a new freelist is
built from a chunk directly onto a threads freelist or when a deallocation occurs on a block which was not allocated by the same
thread id as the one doing the deallocation) the thread id is set to the current one.
What’s the use?
Well, when a deallocation occurs we can now look at the thread id and ﬁnd out if it was allocated by another
thread id and decrease the used counter of that thread instead, thus keeping the free and used counters correct.
And keeping the
free and used counters corrects is very important since the relationship between these two variables decides if memory should be
returned to the global pool or not when a deallocation occurs.
S_max_bytes we
call new() directly and return.
If the requested size is within limits we start by ﬁnding out from which bin we should serve this request by looking in _S_binmap.
A call to _S_get_thread_id() returns the thread id for the calling thread (and if no value has been set in _S_thread_key, a new id
is assigned and returned).
A quick look at _S_bin[ bin ].ﬁrst[ thread_id ] tells us if there are any blocks of this size on the current threads freelist.
If the freelist is empty (the pointer is NULL) we start by looking at the global freelist (0).
If there are blocks available on the
global freelist we lock this bins mutex and move up to block_count (the number of blocks of this bins size that will ﬁt into a
_S_chunk_size) or until end of list - whatever comes ﬁrst - to the current threads freelist and at the same time change the thread_id
ownership and update the counters and pointers.
The reason that the number of blocks moved to the current threads freelist is limited to block_count is to minimize the chance that
a subsequent deallocate() call will return the excess blocks to the global freelist (based on the _S_freelist_headroom calculation,
see below).
However if there isn’t any memory on the global pool we need to get memory from the system - this is done in exactly the same
way as in a single threaded application with one major difference; the list built in the newly allocated memory (of _S_chunk_size
size) is added to the current threads freelist instead of to the global.
The basic process of a deallocation call is simple: always add the block to the front of the current threads freelist and update the
counters and pointers (as described earlier with the speciﬁc check of ownership that causes the used counter of the thread that
originally allocated the block to be decreased instead of the current threads counter).
And here comes the free and used counters to service.
Each time a deallocation() call is made, the length of the current threads
freelist is compared to the amount memory in use by this thread.
Let’s go back to the example of an application that has one thread that does all the allocations and one that deallocates.
Both
these threads use say 516 32-byte blocks that was allocated during thread creation for example.
Their used counters will both say
516 at this point.
The allocation thread now grabs 1000 32-byte blocks and puts them in a shared container.
The used counter for
this thread is now 1516.
The deallocation thread now deallocates 500 of these blocks.
For each deallocation made the used counter of the allocating thread
is decreased and the freelist of the deallocation thread gets longer and longer.
In this case, when the freelist
(given that the _S_freelist_headroom is at it’s default value of 10%) exceeds 52 (516/10) blocks will be returned to the global
pool where the allocating thread may pick them up and reuse them.
In order to reduce lock contention (since this requires this bins mutex to be locked) this operation is also made in chunks of
blocks (just like when chunks of blocks are moved from the global freelist to a threads freelist mentioned above).
The "formula"
used can probably be improved to further reduce the risk of blocks being "bounced back and forth" between freelists.
The bitmap_allocator

As this name suggests, this allocator uses a bit-map to keep track of the used and unused memory locations for its book-keeping
purposes.
This allocator will make use of 1 single bit to keep track of whether it has been allocated or not.
A bit 1 indicates free, while 0
indicates allocated.
This has been done so that you can easily check a collection of bits for a free block.
This kind of Bitmapped
strategy works best for single object allocations, and with the STL type parameterized allocators, we do not need to choose any
size for the block which will be represented by a single bit.
This will be the size of the parameter around which the allocator has
been parameterized.
Thus, close to optimal performance will result.
Hence, this should be used for node based containers which
call the allocate function with an argument of 1.
The bitmapped allocator’s internal pool is exponentially growing.
Meaning that internally, the blocks acquired from the Free List
Store will double every time the bitmapped allocator runs out of memory.
GTHREADS decides whether to use Mutex Protection around every allocation/deallocation.
The state of the macro
is picked up automatically from the gthr abstraction layer.
This maintains a sorted order of all free memory blocks given back
to it by the bitmapped allocator, and is also responsible for giving memory to the bitmapped allocator when it asks for more.
Internally, there is a Free List threshold which indicates the Maximum number of free lists that the FLS can hold internally
(cache).
Currently, this value is set at 64.
So, if there are more than 64 free lists coming in, then some of them will be given back
to the OS using operator delete so that at any given time the Free List’s size does not exceed 64 entries.
This is done because a
Binary Search is used to locate an entry in a free list when a request for memory comes along.
Thus, the run-time complexity of
the search would go up given an increasing size, for 64 entries however, lg(64) == 6 comparisons are enough to locate the correct
free list if it exists.
Suppose the free list size has reached its threshold, then the largest block from among those in the list and the new block will be
selected and given back to the OS.
This is done because it reduces external fragmentation, and allows the OS to use the larger
blocks later in an orderly fashion, possibly merging them later.
Also, on some systems, large blocks are obtained via calls to
mmap, so giving them back to free system resources becomes most important.
The function _S_should_i_give decides the policy that determines whether the current block of memory should be given to the
allocator for the request that it has made.
That’s because we may not always have exact ﬁts for the memory size that the allocator
requests.
We do this mainly to prevent external fragmentation at the cost of a little internal fragmentation.
Now, the value of this

internal fragmentation has to be decided by this function.
I can see 3 possibilities right now.
Please add more as and when you
ﬁnd better strategies.
Equal size check.
Return true only when the 2 blocks are of equal size.
Return true only when the _block_size is greater than or equal to the _required_size, and if the _BS
is > _RS by a difference of less than some THRESHOLD value, then return true, else return false.
Return true only when the _block_size is greater than or equal to the _required_size, and if the _BS
is > _RS by a percentage of less than some THRESHOLD value, then return true, else return false.
Currently, (3) is being used with a value of 36% Maximum wastage per Super Block.

A super block is the block of memory acquired from the FLS from which the bitmap allocator carves out memory for sin-
gle objects and satisﬁes the user’s requests.
These super blocks come in sizes that are powers of 2 and multiples of 32
(_Bits_Per_Block).
Yes both at the same time!
That’s because the next super block acquired will be 2 times the previous
one, and also all super blocks have to be multiples of the _Bits_Per_Block value.
How does it interact with the free list store?
The super block is contained in the FLS, and the FLS is responsible for getting / returning Super Bocks to and from the OS using
operator new as deﬁned by the C++ standard.
Typically, this value is chosen as
Bits_Per_Byte x sizeof(size_t).
On an x86 system, this gives the ﬁgure 8 x 4 = 32.
Thus, each Super Block will be of size 32
x Some_Value.
This Some_Value is sizeof(value_type).
For now, let it be called ’K’.
Thus, ﬁnally, Super Block size is 32 x K
bytes.
This value of 32 has been chosen because each size_t has 32-bits and Maximum use of these can be made with such a ﬁgure.
Consider a block of size 64 ints.
In memory, it would look like this: (assume a 32-bit system where, size_t is a 32-bit entity).
Bitmap Allocator Memory Map
The ﬁrst Column(268) represents the size of the Block in bytes as seen by the Bitmap Allocator.
Internally, a global free list is
used to keep track of the free blocks used and given back by the bitmap allocator.
It is this Free List Store that is responsible for
writing and managing this information.
These ﬁrst 4
bytes about which the bitmapped allocator is not aware hold the value 268.
What do the remaining values represent?
The 2nd 4 in the expression is the sizeof(size_t) because the Bitmapped Allocator maintains a used count for each Super Block,
which is initially set to 0 (as indicated in the diagram).
This is incremented every time a block is removed from this super block
(allocated), and decremented whenever it is given back.
So, when the used count falls to 0, the whole super block will be given
back to the Free List Store.
The 3rd 4x2 is size of the bitmap itself, which is the size of 32-bits x 2, which is 8-bytes, or 2 x sizeof(size_t).
This has nothing to do with the algorithm per-se, only with some vales that must be chosen correctly to ensure that the allocator
performs well in a real word scenario, and maintains a good balance between the memory consumption and the allocation/deal-
location speed.
Thus, suppose the type1 is int and type2 is double, they are related by the relation
sizeof(double) == 2*sizeof(int).
Thus, all types must have this double size relation for this formula to work properly.
For map/multimap: k = 12, and c = 4 (int and double), we get: 37.524%
Thus, knowing these values, and based on the sizeof(value_type), we may create a function that returns the Max_Wastage_Percentage
for us to use.
Thus, ONLY if n == 1, will the bitmap_allocator’s
specialized algorithm be used.
Otherwise, the request is satisﬁed directly by calling operator new.
Suppose n == 1, then the allocator does the following:
1.
Checks to see whether a free block exists somewhere in a region of memory close to the last satisﬁed request.
If so, then
that block is marked as allocated in the bit map and given to the user.
If not, then (2) is executed.
If so, that block is
found, and the same procedure is applied as above, and returned to the user.
If not, then (3) is executed.
The individual bit-maps for each super block.
Note: Here we are never touching any of the memory that the user will be given, and we are conﬁning all memory accesses
to a small region of memory!
This helps reduce cache misses.
If this succeeds then we apply the same procedure on that
bit-map as (1), and return that block of memory to the user.
However, if this process fails, then we resort to (4).
The said effect is achieved by calling
_S_reﬁll_pool which does the following:
• Gets more memory from the Global Free List of the Required size.
If the invariant is maintained, we are sure
that all is well.
Now, the same process is applied on the newly acquired free blocks, which are dispatched accordingly.
Thus, you can clearly see that the allocate function is nothing but a combination of the next-ﬁt and ﬁrst-ﬁt algorithm optimized
ONLY for single object allocations.
For all n belonging to > 1, the operator delete is called
without further ado, and the deallocate function returns.
However for n == 1, a series of steps are performed:
1.
We ﬁrst need to locate that super-block which holds the memory location given to us by the user.
For that purpose, we
maintain a static variable _S_last_dealloc_index, which holds the index into the vector of block pairs which indicates the
index of the last super-block from which memory was freed.
We use this strategy in the hope that the user will deallocate
memory in a region close to what he/she deallocated the last time around.
If the check for belongs_to succeeds, then we
determine the bit-map for the given pointer, and locate the index into that bit-map, and mark that bit as free by setting it.
If the _S_last_dealloc_index does not point to the memory block that we’re looking for, then we do a linear search on
the block stored in the vector of Block Pairs.
This vector in code is called _S_mem_blocks.
When the corresponding
super-block is found, we apply the same procedure as we did for (1) to mark the block as free in the bit-map.
Now, whenever a block is freed, the use count of that particular super block goes down by 1.
When this use count hits 0, we
remove that super block from the list of all valid super blocks stored in the vector.
S_last_dealloc_index point to valid locations within the
vector.
The "Data Layout" section is cryptic.
I have no idea of what you are trying to say.
Layout of what?
The free-list?
Each
bitmap?
The Super Block?
The layout of a Super Block of a given size.
In the example, a super block of size 32 x 1 is taken.
And since I just mentioned the term `each bitmap’, what in the world is meant by it?
What does each bitmap manage?
How does
it relate to the super block?
Is the Super Block a bitmap as well?
Each bitmap is part of a Super Block which is made up of 3 parts as I have mentioned earlier.
Re-iterating, 1.
The use count, 2.
The bit-map for that Super Block.
The actual memory that will be eventually given to the user.
Each bitmap is a multiple of 32
in size.
Each 32 bits managing
the allocated / free status for 32 blocks.
Since each size_t contains 32-bits, one size_t can manage up to 32 blocks’ status.
Each
bit-map is made up of a number of size_t, whose exact number for a super-block of a given size I have just mentioned.
The allocate and deallocate functions manipulate the bitmaps and have nothing to do with the memory that is given to the user.
As I have earlier mentioned, a 1 in the bitmap’s bit ﬁeld indicates free, while a 0 indicates allocated.
This lets us check 32 bits
at a time to check whether there is at lease one free block in those 32 blocks by testing for equality with (0).
Now, the allocate
function will given a memory block ﬁnd the corresponding bit in the bitmap, and will reset it (i.e., make it re-set (0)).
And when
the deallocate function is called, it will again set that bit after locating it to indicate that that particular block corresponding to
this bit in the bit-map is not being used by anyone, and may be used to satisfy future requests.
And since
the bit-maps in the reverse order to that of the address order, the last bit (LSB if the bit-map is considered as a binary word of
64-bits) is re-set to 0.
The bit-map now looks like this: 1111111111111111111111111111111111111111111111111111111111111110


Another issue would be whether to keep the all bitmaps in a separate area in memory, or to keep them near the actual blocks that
will be given out or allocated for the client.
After some testing, I’ve decided to keep these bitmaps close to the actual blocks.
This will help in 2 ways.
Constant time access for the bitmap themselves, since no kind of look up will be needed to ﬁnd the correct bitmap list or
its equivalent.
And also this would preserve the cache as far as possible.
So in effect, this kind of an allocator might prove beneﬁcial from a purely cache point of view.
But this allocator has been made
to try and roll out the defects of the node_allocator, wherein the nodes get skewed about in memory, if they are not returned in
the exact reverse order or in the same order in which they were allocated.
Also, the new_allocator’s book keeping overhead is too
much for small objects and single object allocations, though it preserves the locality of blocks very well when they are returned
back to the allocator.
Also, once the address of the free list has been found, the cost for
allocation/deallocation would be negligible, and is supposed to be constant time.
For these very reasons, it is very important to
minimize the linear time costs, which include ﬁnding a free list with a free block while allocating, and ﬁnding the corresponding
free list for a block while deallocating.
Therefore, I have decided that the growth of the internal pool for this allocator will
be exponential as compared to linear for node_allocator.
There, linear time works well, because we are mainly concerned
with speed of allocation/deallocation and memory consumption, whereas here, the allocation/deallocation part does have some
linear/logarithmic complexity components in it.
Thus, to try and minimize them would be a good thing to do at the cost of a little
bit of memory.
Another thing to be noted is the pool size will double every time the internal pool gets exhausted, and all the free blocks have
been given away.
Hence, the term given is exponential growth of the internal pool.
This is a library of policy-based elementary data structures: associative containers and priority queues.
It is designed for high-
performance, ﬂexibility, semantic safety, and conformance to the corresponding containers in std and std::tr1 (except for
some points where it differs by design).
These
performance factors are translated into design policies and incorporated into container design.
There is tension between unravelling factors into a coherent set of policies.
Every attempt is made to make a minimal set of
factors.
However, in many cases multiple factors make for long template names.
Every attempt is made to alias and use typedefs
in the source ﬁles, but the generated names for external symbols can be large for binary ﬁles or debuggers.
In many cases, the longer names allow capabilities and behaviours controlled by macros to also be unamibiguously emitted as
distinct generated names.
Speciﬁc issues found while unraveling performance factors in the design of associative containers and priority queues follow.
Implicitly hard-wiring policies can hamper
their performance and limit their functionality.
An efﬁcient hash-based container, for example, requires policies for testing key
equivalence, hashing keys, translating hash values into positions within the hash table, and determining when and how to resize
the table internally.
A tree-based container can efﬁciently support order statistics, i.e. the ability to query what is the order of
each key within the sequence of keys in the container, but only if the container is supplied with a policy to internally update
meta-data.
There are many other such examples.
Ideally, all associative containers would share the same interface.
Unfortunately, underlying data structures and mapping seman-
tics differentiate between different containers.
For example, suppose one writes a generic function manipulating an associative
container.
The answer varies according to its underlying data
structure.
If the underlying data structure of Cntnr is based on a tree or trie, then the order of elements is well deﬁned;
otherwise, it is not, in general.
If the underlying data structure of Cntnr is based on a collision-chaining hash table, then
modifying r_Cntnr will not invalidate its iterators’ order; if the underlying data structure is a probing hash table, then this is
not the case.
If the underlying data structure is based on a tree or trie, then a reference to the container can efﬁciently be split;
otherwise, it cannot, in general.
If the underlying data structure is a red-black tree, then splitting a reference to the container is
exception-free; if it is an ordered-vector tree, exceptions can be thrown.
Most useful data structures for priority queues have a relatively simple structure, as they are geared toward relatively simple
requirements.
Unfortunately, these structures do not support access to an arbitrary value, which turns out to be necessary in many
algorithms.
Say, decreasing an arbitrary value in a graph algorithm.
Therefore, some extra mechanism is necessary and must
be invented for accessing arbitrary values.
There are at least two alternatives: embedding an associative container in a priority
queue, or allowing cross-referencing through iterators.
The ﬁrst solution adds signiﬁcant overhead; the second solution requires
a precise deﬁnition of iterator invalidation.
Which is the next point...
Priority queues, like hash-based containers, store values in an order that is meaningless and undeﬁned externally.
For example,
a push operation can internally reorganize the values.
Because of this characteristic, describing a priority queues’ iterator is
difﬁcult: on one hand, the values to which iterators point can remain valid, but on the other, the logical order of iterators can
change unpredictably.
Roughly speaking, any element that is both inserted to a priority queue (e.g. through push) and removed from it (e.g., through
pop), incurs a logarithmic overhead (in the amortized sense).
Different underlying data structures place the actual cost differ-
ently: some are optimized for amortized complexity, whereas others guarantee that speciﬁc operations only have a constant cost.
One underlying data structure might be chosen if modifying a value is frequent (Dijkstra’s shortest-path algorithm), whereas a
different one might be chosen otherwise.
Unfortunately, an array-based binary heap - an underlying data structure that optimizes
(in the amortized sense) push and pop operations, differs from the others in terms of its invalidation guarantees.
Other design
decisions also impact the cost and placement of the overhead, at the expense of more difference in the kinds of operations that the
underlying data structure can support.
These differences pose a challenge when creating a uniform interface for priority queues.
Why
then write another library?
This section shows some possible advantages of this library, when considering the challenges in the
introduction.
Many of these points stem from the fact that the ISO C++ process introduced associative-containers in a two-step
process (ﬁrst standardizing tree-based containers, only then adding hash-based containers, which are fundamentally different),
did not standardize priority queues as containers, and (in our opinion) overloads the iterator concept.
In some cases
this is needed for making their common operations more efﬁcient, and in other cases this allows them to support a larger set of
operations
1.
Hash-based containers, for example, support look-up and insertion methods (find and insert).
In order to locate
elements quickly, they are supplied a hash functor, which instruct how to transform a key object into some size type; a
hash functor might transform "hello" into 1123002298.
A hash table, though, requires transforming each key object
into some size-type type in some speciﬁc domain; a hash table with a 128-long table might transform "hello" into
position 63.
The policy by which the hash value is transformed into a position within the table can dramatically affect
performance.
Hash-based containers also do not resize naturally (as opposed to tree-based containers, for example).
The
appropriate resize policy is unfortunately intertwined with the policy that transforms hash value into a position within the
table.
Tree-based containers, for example, also support look-up and insertion methods, and are primarily useful when maintaining
order between elements is important.
In some cases, though, one can utilize their balancing algorithms for completely
different purposes.
Figure A shows a tree whose each node contains two entries: a ﬂoating-point key, and some size-type metadata (in bold
beneath it) that is the number of nodes in the sub-tree.
A container based on this data structure can obviously answer efﬁciently whether 0.3 is in the container object,
but it can also answer what is the order of 0.3 among all those in the container object: see [66].
As another example, Figure B shows a tree whose each node contains two entries: a half-open geometric line interval,
and a number metadata (in bold beneath it) that is the largest endpoint of all intervals in its sub-tree.
A container based on this data structure can
obviously answer efﬁciently whether [3, 41) is in the container object, but it can also answer efﬁciently whether the
container object has intervals that intersect [3, 41).
These types of queries are very useful in geometric algorithms and
lease-management algorithms.
It is important to note, however, that as the trees are modiﬁed, their internal structure changes.
To maintain these invariants,
one must supply some policy that is aware of these changes.
Without this, it would be better to use a linked list (in itself
very efﬁcient for these purposes).
The standard C++ library contains associative containers based on red-black trees and collision-chaining hash tables.
These are
very useful, but they are not ideal for all types of settings.
The ﬁgure below shows the different underlying data structures currently supported in this library.
Each of these data structures has some performance beneﬁts, in terms of speed, size or both.
For now, note that vector-based
trees and probing hash tables manipulate memory more efﬁciently than red-black trees and collision-chaining hash tables, and
that list-based associative containers are very useful for constructing "multimaps".
Now consider a function manipulating a generic associative container,

Ideally, the underlying data structure of Cntnr would not affect what can be done with r_cnt.
Unfortunately, this is not the
case.
For example, if Cntnr is std::map, then the function can use
std::for_each(r_cnt.find(foo), r_cnt.find(bar), foobar)
in order to apply foobar to all elements between foo and bar.
If Cntnr is a hash-based container, then this call’s results are
undeﬁned.
Also, if Cntnr is tree-based, the type and object of the comparison functor can be accessed.
If Cntnr is hash based, these
queries are nonsensical.
There are various other differences based on the container’s underlying data structure.
For one, they can be constructed by, and
queried for, different policies.
Furthermore:
1.
Containers based on C, D, E and F store elements in a meaningful order; the others store elements in a meaningless (and
probably time-varying) order.
By implication, only containers based on C, D, E and F can support erase operations
taking an iterator and returning an iterator to the following element without performance loss.
Containers based on C, D, E, and F can be split and joined efﬁciently, while the others cannot.
Containers based on C and
D, furthermore, can guarantee that this is exception-free; containers based on E cannot guarantee this.
Containers based on all but E can guarantee that erasing an element is exception free; containers based on E cannot
guarantee this.
Containers based on all but B and E can guarantee that modifying an object of their type does not invalidate
iterators or references to their elements, while containers based on B and E cannot.
Containers based on C, D, and E can
furthermore make a stronger guarantee, namely that modifying an object of their type does not affect the order of iterators.
A uniﬁed tag and traits system (as used for the C++ standard library iterators, for example) can ease generic manipulation of
associative containers based on different underlying data structures.
Iterators, then, are useful because they allow
going over a speciﬁc sequence.
The standard library also uses iterators for accessing a speciﬁc element: when an associative
container returns one through find.
The standard library consistently uses the same types of iterators for both purposes: going
over a range, and accessing a speciﬁc found element.
Before the introduction of hash-based containers to the standard library,
this made sense (with the exception of priority queues, which are discussed later).
Using the standard associative containers together with non-order-preserving associative containers (and also because of priority-
queues container), there is a possible need for different types of iterators for self-organizing containers: the iterator concept seems
overloaded to mean two different things (in some cases).
Then what will be the outcome of
std::for_each(c.find(1), c.find(5), foo);
If cntnr is a tree-based container object, then an in-order walk will apply foo to the relevant elements, as in the graphic below,
label A.
In our opinion, this problem is not caused just because red-black trees are order preserving while collision-chaining hash tables
are (generally) not - it is more fundamental.
Most of the standard’s containers order sequences in a well-deﬁned manner that
is determined by their interface: calling insert on a tree-based container modiﬁes its sequence in a predictable way, as does
calling push_back on a list or a vector.
Conversely, collision-chaining hash tables, probing hash tables, priority queues, and
list-based containers (which are very useful for "multimaps") are self-organizing data structures; the effect of each operation
modiﬁes their sequences in a manner that is (practically) determined by their implementation.
Consequently, applying an algorithm to a sequence obtained from most containers may or may not make sense, but applying it
to a sub-sequence of a self-organizing container does not.
Then what composes the returned iterator?
In the graphic below, label A shows the simplest (and most efﬁcient) implementation of a collision-chaining hash table.
The
little box marked point_iterator shows an object that contains a pointer to the element’s node.
Note that this "iterator" has
no way to move to the next element ( it cannot support operator++).
Conversely, the little box marked iterator stores
both a pointer to the element, as well as some other information (the bucket number of the element).
If we were to use a different container to cross-reference into this
hash-table using these iterators - it would take much more space.
As noted above, nothing much can be done by incrementing
these iterators, so why is this extra information needed?
B. Here the iterators are as light as can be, but the hash-table’s operations are more complicated.
It should be noted that containers based on collision-chaining hash-tables are not the only ones with this type of behavior; many
other self-organizing data structures display it as well.
The answer depends on the underlying data structure of the container.
The graphic below shows three cases: A1 and A2 show a
red-black tree; B1 and B2 show a probing hash-table; C1 and C2 show a collision-chaining hash table.
Erasing 5 from A1 yields A2.
Clearly, an iterator to 3 can be de-referenced and incremented.
The sequence of iterators
changed, but in a way that is well-deﬁned by the interface.
Erasing 5 from B1 yields B2.
Clearly, an iterator to 3 is not valid at all - it cannot be de-referenced or incremented; the
order of iterators changed in a way that is (practically) determined by the implementation and not by the interface.
Erasing 5 from C1 yields C2.
Here the situation is more complicated.
On the one hand, there is no problem in de-
referencing it.
On the other hand, the order of iterators changed in a way that is (practically) determined by the imple-
mentation and not by the interface.
So in the standard library containers, it is not always possible to express whether it is valid or not.
This is true also for insert.
Again, the iterator concept seems overloaded.
A strict public interface of methods that comprise only operations which depend on the class’s internal structure;
other operations are best designed as external functions.
Order-preserving standard associative containers provide the method
iterator
erase(iterator it)
which takes an iterator, erases the corresponding element, and returns an iterator to the following element.
Also standardd
hash-based associative containers provide this method.
However, in a different sense
this actually decreases genericity: an integral implication of this method is that tree-based associative containers’ memory
use is linear in the total number of elements they store, while hash-based containers’ memory use is unbounded in the
total number of elements they store.
Assume a hash-based container is allowed to decrease its size when an element
is erased.
Then the elements might be rehashed, which means that there is no "next" element - it is simply undeﬁned.
Consequently, it is possible to infer from the fact that the standard library’s hash-based containers provide this method
that they cannot downsize when elements are erased.
As a consequence, different code is needed to manipulate different
containers, assuming that memory should be conserved.
Therefor, this library’s non-order preserving associative containers
omit this method.
All associative containers include a conditional-erase method
template<
class Pred>
size_type
erase_if
(Pred pred)
which erases all elements matching a predicate.
This is probably the only way to ensure linear-time multiple-item erase
which can actually downsize a container.
For tree-based or trie-based containers, this can implemented more
efﬁciently as a (small) sequence of split and join operations.
For other, unordered, containers, this method isn’t much better
than an external loop.
Moreover, if c is a hash-based container, then
c.erase(c.find(2), c.find(5))
is almost certain to do something different than erasing all elements whose keys are between 2 and 5, and is likely to
produce other undeﬁned behavior.
Externally splitting
or joining trees is super-linear, and, furthermore, can throw exceptions.
Split and join methods, consequently, seem good choices
for tree-based container methods, especially, since as noted just before, they are efﬁcient replacements for erasing sub-sequences.
At best, this can be implemented as an external loop, or, even more
efﬁciently, as a join operation (for the case of tree-based or trie-based containers).
Moreover, these methods seem similar to
constructors taking a range given by a pair of iterators; the constructors, however, are transactional, whereas the insert methods
are not; this is possibly confusing.
In addition, some standard associa-
tive containers have global function operators, like operator== and operator<=, that allow comparing entire associative
containers.
In our opinion, these functions are better left out.
To begin with, they do not signiﬁcantly improve over an external loop.
More importantly, however, they are possibly misleading - operator==, for example, usually checks for equivalence, or
interchangeability, but the associative container cannot check for values’ equivalence, only keys’ equivalence; also, are two
containers considered equivalent if they store the same values in different order?
Their interface supports push and pop.
The standard container std::priorityqueue indeed
support these methods, but little else.
For algorithmic and software-engineering purposes, other methods are needed:
1.
Many graph algorithms (see [66]) require increasing a value in a priority queue (again, in the sense of the container’s
comparison functor), or joining two priority-queue objects.
The return type of priority_queue’s push method is a point-type iterator, which can be used for modifying or erasing
arbitrary values.
For example:
priority_queue<int> p;
priority_queue<int>::point_iterator it = p.push(3);
p.modify(it, 4);

These types of cross-referencing operations are necessary for making priority queues useful for different applications,
especially graph applications.
It is sometimes necessary to erase an arbitrary value in a priority queue.
For example, consider the select function for
monitoring ﬁle descriptors:
int
select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *errorfds,
struct timeval *timeout);
then, as the select documentation states:
“ The nfds argument speciﬁes the range of ﬁle descriptors to be tested.
The select() function tests ﬁle descriptors in the
range of 0 to nfds-1.
It stands to reason, therefore, that we might wish to maintain a minimal value for nfds, and priority queues immediately
come to mind.
Note, though, that when a socket is closed, the minimal ﬁle description might change; in the absence of an
efﬁcient means to erase an arbitrary value from a priority queue, we might as well avoid its use altogether.
The standard containers typically support iterators.
It is somewhat unusual for std::priority_queue to omit them
(See [83]).
One might ask why do priority queues need to support iterators, since they are self-organizing containers with
a different purpose than abstracting sequences.
There are several reasons:
(a) Iterators (even in self-organizing containers) are useful for many purposes: cross-referencing containers, serialization,
and debugging code that uses these containers.
It should be noted that the standard containers also use iterators
for accessing and manipulating a speciﬁc value.
In hash-based containers, one checks the existence of a key by
comparing the iterator returned by find to the iterator returned by end, and not by comparing a pointer returned by
find to NULL.
These are shown in the ﬁgure below with labels A1 and A2, B, and C.
No single implementation can completely replace any of the others.
Some have better push and pop amortized performance,
some have better bounded (worst case) response time than others, some optimize a single method at the expense of others, etc.
In general the "best" implementation is dictated by the speciﬁc problem.
As with associative containers, the more implementations co-exist, the more necessary a traits mechanism is for handling generic
containers safely and efﬁciently.
This is especially important for priority queues, since the invalidation guarantees of one of the
most useful data structures - binary heaps - is markedly different than those of most of the others.
They are very efﬁcient in terms of memory
(since they don’t require per-value structure metadata), and have the best amortized push and pop performance for primitive
types like int.
The standard library’s priority_queue implements this data structure as an adapter over a sequence, typically std::vector
or std::deque, which correspond to labels A1 and A2 respectively in the graphic above.
This is indeed an elegant example of the adapter concept and the algorithm/container/iterator decomposition.
There
are several reasons why a binary-heap priority queue may be better implemented as a container instead of a sequence adapter:
1. std::priority_queue cannot erase values from its adapted sequence (irrespective of the sequence type).
This means
that the memory use of an std::priority_queue object is always proportional to the maximal number of values it
ever contained, and not to the number of values that it currently contains.
This implementation of binary heaps acts very differently than other underlying data
structures (See also pairing heaps).
Some combinations of adapted sequences and value types are very inefﬁcient or just don’t make sense.
If one uses
std::priority_queue<std::vector<std::string> > >, for example, then not only will each operation
perform a logarithmic number of std::string assignments, but, furthermore, any operation (including pop) can render
the container useless due to exceptions.
Conversely, if one uses std::priority_queue<std::deque<int> > >,
then each operation uses incurs a logarithmic number of indirect accesses (through pointers) unnecessarily.
It might be
better to let the container make a conservative deduction whether to use the structure in the graphic above, labels A1 or
A2.
There does not seem to be a systematic way to determine what exactly can be done with the priority queue.
If a different sequence is adapted, it is even more difﬁcult to determine what can
be done.
If a different
sequence is adapted, it is even more difﬁcult to determine what can be done.
This means that if one
needs to erase a small (say logarithmic) number of values, then one might still choose this underlying data structure.
Using
std::priority_queue, however, this will generally change the order of growth of the entire sequence of operations.
The library contains only header ﬁles, and does not require any other libraries except the standard C++ library .
All classes
are deﬁned in namespace __gnu_pbds.
The library internally uses macros beginning with PB_DS, but #undefs anything it
#defines (except for header guards).
Compiling the library in an environment where macros beginning in PB_DS are deﬁned,
may yield unpredictable results in compilation, execution, or both.
Further dependencies are necessary to create the visual output for the performance tests.
The various data structures are organized as follows.
List-Based

– list_update list-based update-policy associative container
• Heap-Based
– priority_queue A priority queue.
The hierarchy is composed naturally so that commonality is captured by base classes.
Thus operator[] is deﬁned at the base
of any hierarchy, since all derived containers support it.
Conversely split is deﬁned in basic_branch, since only tree-like
containers support it.
In addition, there are the following diagnostics classes, used to report errors speciﬁc to this library’s data structures.
For example, this shows
basic operations on a collision-chaining hash-based container:
#include <ext/pb_ds/assoc_container.h>
int main()
{
__gnu_pbds::cc_hash_table<int, char> c;
c[2] = ’b’;
assert(c.find(1) == c.end());
};
The container is called __gnu_pbds::cc_hash_table instead of std::unordered_map, since “unordered map” does
not necessarily mean a hash-based map as implied by the C++ library (C++11 or TR1).
For example, list-based associative
containers, which are very useful for the construction of "multimaps," are also unordered.
This snippet shows a red-black tree based container:
#include <ext/pb_ds/assoc_container.h>
int main()
{
__gnu_pbds::tree<int, char> c;
c[2] = ’b’;
assert(c.find(2) !
The member function naming convention is to strive to be the same as the equivalent member functions in other C++ standard
library containers.
The familiar methods are unchanged: begin, end, size, empty, and clear.
This isn’t to say that things are exactly as one would expect, given the container requirments and interfaces in the C++ standard.
The names of containers’ policies and policy accessors are different then the usual.
For example, if hash_type is some type of
hash-based container, then
hash_type::hash_fn
gives the type of its hash functor, and if obj is some hash-based container object, then
obj.get_hash_fn()
will return a reference to its hash-functor object.
Similarly, if tree_type is some type of tree-based container, then
tree_type::cmp_fn
gives the type of its comparison functor, and if obj is some tree-based container object, then
obj.get_cmp_fn()
will return a reference to its comparison-functor object.
It would be nice to give names consistent with those in the existing C++ standard (inclusive of TR1).
Unfortunately, these
standard containers don’t consistently name types and methods.
For example, std::tr1::unordered_map uses hasher
for the hash functor, but std::map uses key_compare for the comparison functor.
Also, we could not ﬁnd an accessor for
std::tr1::unordered_map’s hash functor, but std::map uses compare for accessing the comparison functor.
Instead, __gnu_pbds attempts to be internally consistent, and uses standard-derived terminology if possible.
Another source of difference is in scope: __gnu_pbds contains more types of associative containers than the standard C++
library, and more opportunities to conﬁgure these new containers, since different types of associative containers are useful in
different settings.
Namespace __gnu_pbds contains different classes for hash-based containers, tree-based containers, trie-based containers, and
list-based containers.
Since associative containers share parts of their interface, they are organized as a class hierarchy.
Each type or method is deﬁned in the most-common ancestor in which it makes sense.
But not all containers contain or use hash functors.
Yet, both collision-chaining and (general) probing hash-based associative
containers have a hash functor, so basic_hash_table contains the interface:
const hash_fn&
get_hash_fn() const;
hash_fn&
get_hash_fn();
so all hash-based associative containers inherit the same hash-functor accessor methods.
For example, the
standard hash-based container is parametrized as follows:
template<typename Key, typename Mapped, typename Hash,
typename Pred, typename Allocator, bool Cache_Hashe_Code>
class unordered_map;
and so can be conﬁgured by key type, mapped type, a functor that translates keys to unsigned integral types, an equivalence
predicate, an allocator, and an indicator whether to store hash values with each entry.
Nearly all policy parameters have default values, so this need not be considered for casual use.
It is important to note, however,
that hash-based containers’ policies can dramatically alter their performance in different settings, and that tree-based containers’
policies can make them useful for other purposes than just look-up.
As opposed to associative containers, priority queues have relatively few conﬁguration options.
The priority queue is parametrized
as follows:
template<typename Value_Type, typename Cmp_Fn,typename Tag,
typename Allocator>
class priority_queue;
The Value_Type, Cmp_Fn, and Allocator parameters are the container’s value type, comparison-functor type, and alloca-
tor type, respectively; these are very similar to the standard’s priority queue.
The Tag parameter is different: there are a number
of pre-deﬁned tag types corresponding to binary heaps, binomial heaps, etc., and Tag should be instantiated by one of them.
When manip-
ulating generically associative containers, it is often useful to be able to statically determine what they can support and what the
cannot.
Happily, the standard provides a good solution to a similar problem - that of the different behavior of iterators.
If It is an iterator,
then
typename std::iterator_traits<It>::iterator_category
is one of a small number of pre-deﬁned tag classes, and
typename std::iterator_traits<It>::value_type
is the value type to which the iterator "points".
Similarly, in this library, if C is a container, then container_traits is a trait class that stores information about the kind of
container that is implemented.
In most cases, however, the exact underlying data structure is not really important, but what is important is one of its other
attributes: whether it guarantees storing elements by key order, for example.
For this one can use
typename container_traits<C>::order_preserving
Also,
typename container_traits<C>::invalidation_guarantee
is the container’s invalidation guarantee.
Invalidation guarantees are especially important regarding priority queues, since in this
library’s design, iterators are practically the only way to manipulate them.
For example, find and
insert are point-type methods, since they each deal with a speciﬁc element; their returned iterators are point-type iterators.
Most containers store elements in an order that is determined by their interface.
Correspondingly, it is ﬁne that their point-type
iterators are synonymous with their range-type iterators.
For example, in the following snippet
std::for_each(c.find(1), c.find(5), foo);
two point-type iterators (returned by find) are used for a range-type purpose - going over all elements whose key is between 1
and 5.
Conversely, the above snippet makes no sense for self-organizing containers - ones that order (and reorder) their elements by
implementation.
It would be nice to have a uniform iterator system that would allow the above snippet to compile only if it made
sense.
This could trivially be done by specializing std::for_each for the case of iterators returned by std::tr1::unordered_map,
but this would only solve the problem for one algorithm and one container.
Fundamentally, the problem is that one can loop using
a self-organizing container’s point-type iterators.
This library’s containers deﬁne two families of iterators: point_const_iterator and point_iterator are the iterator types returned by
point-type methods; const_iterator and iterator are the iterator types returned by range-type methods.
For self-organizing containers, however, (hash-based containers as a special example), the preceding snippet will not compile,
because their point-type iterators do not support operator++.
In any case, both for order-preserving and self-organizing containers, the following snippet will compile:
typename Cntnr::point_iterator it = c.find(2);
because a range-type iterator can always be converted to a point-type iterator.
Distingushing between iterator types also raises the point that a container’s iterators might have different invalidation rules
concerning their de-referencing abilities and movement abilities.
This now corresponds exactly to the question of whether point-
type and range-type iterators are valid.
As explained above, container_traits allows querying a container for its data
structure attributes.
The iterator-invalidation guarantees are certainly a property of the underlying data structure, and so
container_traits<C>::invalidation_guarantee
gives one of three pre-determined types that answer this query.
For example, a hash-based associative container is parametrized
by a hash-functor, transforming each key into an non-negative numerical type.
Each such value is then further mapped into a
position within the table.
The mapping of a key into a position within the table is therefore a two-step process.
In some cases, instantiations are redundant.
For example, when the keys are integers, it is possible to use a redundant hash policy,
which transforms each key into its value.
In some other cases, these policies are irrelevant.
For example, a hash-based associative container might transform keys into
positions within a table by a different method than the two-step method described above.
In such a case, the hash functor is
simply irrelevant.
When a policy is either redundant or irrelevant, it can be replaced by null_type.
For example, a set is an associative container with one of its template parameters (the one for the mapped type) replaced with
null_type.
Other places simpliﬁcations are made possible with this technique include node updates in tree and trie data
structures, and hash and probe functions for hash data structures.
The map datatype associates each key to some data.
Sets are associative containers that simply store keys - they do not map them to anything.
In the standard, each map class has a
corresponding set class.
E.g., std::map<int, char> maps each int to a char, but std::set<int, char> simply
stores ints.
In this library, however, there are no distinct classes for maps and sets.
Instead, an associative container’s Mapped
template parameter is a policy: if it is instantiated by null_type, then it is a "set"; otherwise, it is a "map".
Once the Mapped template parameter is instantiated by null_type, then the "set" acts very similarly to the standard’s sets -
it does not map each key to a distinct null_type object.
Also, , the container’s value_type is essentially its key_type - just as
with the standard’s sets .
The standard’s multimaps and multisets allow, respectively, non-uniquely mapping keys and non-uniquely storing keys.
As
discussed, the reasons why this might be necessary are 1) that a key might be decomposed into a primary key and a secondary
key, 2) that a key might appear more than once, or 3) any arbitrary combination of 1)s and 2)s.
Correspondingly, one should use
1) "maps" mapping primary keys to secondary keys, 2) "maps" mapping keys to size types, or 3) any arbitrary combination of
1)s and 2)s.
Thus, for example, an std::multiset<int> might be used to store multiple instances of integers, but using
this library’s containers, one might use
tree<int, size_t>
i.e., a map of ints to size_ts.
These "multimaps" and "multisets" might be confusing to anyone familiar with the standard’s std::multimap and std::multiset
because there is no clear correspondence between the two.
For example, in some cases where one uses std::multiset in the
standard, one might use in this library a "multimap" of "multisets" - i.e., a container that maps primary keys each to an associative
container that maps each secondary key to the number of times it occurs.
When one uses a "multimap," one should choose with care the type of container used for secondary keys.
Instead, these data struc-
tures can be synthesized via manipulation of the Mapped template parameter.
One maps the unique part of a key - the primary key, into an associative-container of the (originally) non-unique parts of the key -
the secondary key.
A primary associative-container is an associative container of primary keys; a secondary associative-container
is an associative container of secondary keys.
Stepping back a bit, and starting in from the beginning.
Maps (or sets) allow mapping (or storing) unique-key values.
The standard library also supplies associative containers which map
(or store) multiple values with equivalent keys: std::multimap, std::multiset, std::tr1::unordered_multimap,
and unordered_multiset.
We ﬁrst discuss how these might be used, then why we think it is best to avoid them.
Suppose one builds a simple bank-account application that records for each client (identiﬁed by an std::string) and account-
id (marked by an unsigned long) - the balance in the account (described by a ﬂoat).
Suppose further that ordering this information
is not useful, so a hash-based container is preferable to a tree based container.
Then one can use
std::tr1::unordered_map<std::pair<std::string, unsigned long>, float, ...>
which hashes every combination of client and account-id.
This might work well, except for the fact that it is now impossible to
efﬁciently list all of the accounts of a speciﬁc client (this would practically require iterating over all entries).
Instead, one can use
std::tr1::unordered_multimap<std::pair<std::string, unsigned long>, float, ...>
which hashes every client, and decides equivalence based on client only.
This will ensure that all accounts belonging to a speciﬁc
user are stored consecutively.
Also, suppose one wants an integers’ priority queue (a container that supports push, pop, and top operations, the last of which
returns the largest int) that also supports operations such as find and lower_bound.
A reasonable solution is to build an
adapter over std::set<int>.
In this adapter, push will just call the tree-based associative container’s insert method;
pop will call its end method, and use it to return the preceding element (which must be the largest).
Then this might work well,
except that the container object cannot hold multiple instances of the same integer (push(4), will be a no-op if 4 is already in
the container object).
If multiple keys are necessary, then one might build the adapter over an std::multiset<int>.
The standard library’s non-unique-mapping containers are useful when (1) a key can be decomposed in to a primary key and a
secondary key, (2) a key is needed multiple times, or (3) any combination of (1) and (2).
The graphic below shows how the standard library’s container design works internally; in this ﬁgure nodes shaded equally
represent equivalent-key values.
Equivalent keys are stored consecutively using the properties of the underlying data structure:
binary search trees (label A) store equivalent-key values consecutively (in the sense of an in-order walk) naturally; collision-
chaining hash tables (label B) store equivalent-key values in the same bucket, the bucket can be arranged so that equivalent-key
values are consecutive.
The graphic below shows again the two containers from the ﬁrst graphic above,
this time with the embedded linked lists of the grayed nodes marked explicitly.
Figure 21.9: Effect of embedded lists in std::multimap
These embedded linked lists have several disadvantages.
The underlying data structure embeds the linked lists according to its own consideration, which means that the search path
for a value might include several different equivalent-key values.
For example, the search path for the the black node in
either of the ﬁrst graphic, labels A or B, includes more than a single gray node.
The links of the linked lists are the underlying data structures’ nodes, which typically are quite structured.
In the case of
tree-based containers (the grapic above, label B), each "link" is actually a node with three pointers (one to a parent and two
to children), and a relatively-complicated iteration algorithm.
The linked lists, therefore, can take up quite a lot of memory,
and iterating over all values equal to a given key (through the return value of the standard library’s equal_range) can
be expensive.
The primary key is stored multiply; this uses more memory.
Finally, the interface of this design excludes several useful underlying data structures.
Of all the unordered self-organizing
data structures, practically only collision-chaining hash tables can (efﬁciently) guarantee that equivalent-key values are
stored consecutively.
The underlying data structures order the links inside each embedded linked-lists according to their internal considerations,
which effectively means that each of the links is unordered.
Irrespective of the underlying data structure, searching for a
speciﬁc value can degrade to linear complexity.
Similarly to the above point, it is impossible to apply to the secondary keys considerations that apply to primary keys.
For
example, it is not possible to maintain secondary keys by sorted order.
While the interface "understands" that all equivalent-key values constitute a distinct list (through equal_range), the
underlying data structure typically does not.
This means that operations such as erasing from a tree-based container all
values whose keys are equivalent to a a given key can be super-linear in the size of the tree; this is also true also for several
other operations that target a speciﬁc list.
In this library, all associative containers map (or store) unique-key values.
One can (1) map primary keys to secondary associative-
containers (containers of secondary keys) or non-associative containers (2) map identical keys to a size-type representing the
number of times they occur, or (3) any combination of (1) and (2).
Instead of allowing multiple equivalent-key values, this
library supplies associative containers based on underlying data structures that are suitable as secondary associative-containers.
In the ﬁgure below, labels A and B show the equivalent underlying data structures in this library, as mapped to the ﬁrst graphic
above.
Labels A and B, respectively.
See the discussion in list-based container types for containers especially suited as secondary associative-containers.
A point-type iterator is an iterator that refers to a speciﬁc element as returned through an associative-container’s find method.
A range-type iterator is an iterator that is used to go over a sequence of elements, as returned by a container’s find method.
A point-type method is a method that returns a point-type iterator; a range-type method is a method that returns a range-type
iterator.
For most containers, these types are synonymous; for self-organizing containers, such as hash-based containers or priority queues,
these are inherently different (in any implementation, including that of C++ standard library components), but in this design, it
is made explicit.
They are distinct types.
Each associative container’s interface includes the methods:
point_const_iterator
find(const_key_reference r_key) const;
point_iterator
find(const_key_reference r_key);
std::pair<point_iterator,bool>
insert(const_reference r_val);
The relationship between these iterator types varies between container types.
The ﬁgure below shows the most general invariant
between point-type and range-type iterators: In A iterator, can always be converted to point_iterator.
In B shows
invariants for order-preserving containers: point-type iterators are synonymous with range-type iterators.
Orthogonally, Cshows
invariants for "set" containers: iterators are synonymous with const iterators.
Typically, one can determine an iterator’s movement capabilities using std::iterator_traits<It>iterator_category,
which is a struct indicating the iterator’s movement capabilities.
Unfortunately, none of the standard predeﬁned categories re-
ﬂect a pointer’s not having any movement capabilities whatsoever.
All
other standard C++ library tags, such as forward_iterator_tag retain their common use.
21.3.Invalidation Guarantees
If one manipulates a container object, then iterators previously obtained from it can be invalidated.
In some cases a previously-
obtained iterator cannot be de-referenced; in other cases, the iterator’s next or previous element might have changed unpre-
dictably.
This corresponds exactly to the question whether a point-type or range-type iterator (see previous concept) is valid or
not.
In this design, one can query a container (in compile time) about its invalidation guarantees.
Distinguishing between ﬁnd and range types allows ﬁne-grained invalidation guarantees, because these questions correspond
exactly to the question of whether point-type iterators and range-type iterators are valid.
The graphic below shows tags corre-
sponding to different types of invalidation guarantees.
__gnu_pbds::basic_invalidation_guarantee
__gnu_pbds::point_invalidation_guarantee
__gnu_pbds::range_invalidation_guarantee
Figure 21.12: Invalidation Guarantee Tags Hierarchy
• basic_invalidation_guarantee corresponds to a basic guarantee that a point-type iterator, a found pointer, or a
found reference, remains valid as long as the container object is not modiﬁed.
To ﬁnd the invalidation guarantee of a container, one can use
typename container_traits<Cntnr>::invalidation_guarantee
Note that this hierarchy corresponds to the logic it represents: if a container has range-invalidation guarantees, then it must also
have ﬁnd invalidation guarantees; correspondingly, its invalidation guarantee (in this case range_invalidation_guarantee)
can be cast to its base class (in this case point_invalidation_guarantee).
This means that this this hierarchy can be
used easily using standard metaprogramming techniques, by specializing on the type of invalidation_guarantee.
These types of problems were addressed, in a more general setting, in [81] - Item 2.
In our opinion, an invalidation-guarantee
hierarchy would solve these problems in all container types - not just associative containers.
When writing a function manipulating a
generic container object, what is the behavior of the object?
Suppose one writes

then one needs to address the following questions in the body of some_op_sequence:

• Which types and methods does Cntnr support?
Containers based on hash tables can be queries for the hash-functor type and
object; this is meaningless for tree-based containers.
Containers based on trees can be split, joined, or can erase iterators and
return the following iterator; this cannot be done by hash-based containers.
A container based on a probing hash-table invalidates all
iterators when it is modiﬁed; this is not the case for containers based on node-based trees.
Containers based on a node-based
tree can be split or joined without exceptions; this is not the case for containers based on vector-based trees.
A container based on a splay trees or lists with update policies "cache" "frequently accessed" elements;
containers based on most other underlying data structures do not.
What is the relationship between two different data
structures, if anything?
The remainder of this section explains these issues in detail.
For example, if It is an iterator class, then typename It::iterator_catego
or typename std::iterator_traits<It>::iterator_category will yield its category, and typename std::itera
will yield its value type.
This library contains a container tag hierarchy corresponding to the diagram below.
Container Tag Hierarchy
Given any container Cntnr, the tag of the underlying data structure can be found via typename Cntnr::container_category.
Given any container Cntnr, then
<Cntnr> is a traits class identifying the properties of the container.
To ﬁnd if a container can throw when a key is erased (which is true for vector-based trees, for example), one can use
container_traits<Cntnr>::erase_can_throw
Some of the deﬁnitions in container_traits are dependent on other deﬁnitions.
If container_traits<Cntnr>::order_p
is true (which is the case for containers based on trees and tries), then the container can be split or joined; in this case,
container_traits<Cntnr>::split_join_can_throw indicates whether splits or joins can throw exceptions (which
is true for vector-based trees); otherwise container_traits<Cntnr>::split_join_can_throw will yield a compi-
lation error.
The collision-chaining hash-based container has the following declaration.
Key is the key type.
Mapped is the mapped-policy.
Store_Hash indicates whether the hash value should be stored with each entry.
Allocator is an allocator type.
The probing hash-based container has the following declaration.
Some of the default template values depend on the values of other parameters, and are explained below.
The graphic below illustrates the discussion.
Hash functions, ranged-hash functions, and range-hashing functions
Let U be a domain (e.g., the integers, or the strings of 3 characters).
Ranged Hash Function
From the above, it is obvious that given g and h, f can always be composed (however the converse is not true).
The standard’s
hash-based containers allow specifying a hash function, and use a hard-wired range-hashing function; the ranged-hash function
is implicitly composed.
The above describes the case where a key is to be mapped into a single position within a hash table, e.g., in a collision-chaining
table.
In other cases, a key is to be mapped into a sequence of positions within a table, e.g., in a probing table.
Similar terms
apply in this case: the table requires a ranged probe function, mapping a key into a sequence of positions withing the table.
This is typically achieved by composing a hash function mapping the key into a non-negative integral type, a probe function
transforming the hash value into a sequence of hash values, and a range-hashing function transforming the sequence of hash
values into a sequence of positions.
The division method (see above) is a very common choice.
However, even this single method can be implemented in two very
different ways.
Division via Bit Mask
respectively.
The % (modulo) implementation has the advantage that for m a prime far from a power of 2, g(r, m) is affected by all the bits of
r (minimizing the chance of collision).
It has the disadvantage of using the costly modulo operation.
This method is hard-wired
into SGI’s implementation .
The & (bit-mask) implementation has the advantage of relying on the fast bit-wise and operation.
It has the disadvantage that for
g(r, m) is affected only by the low order bits of r. This method is hard-wired into Dinkumware’s implementation.
In cases it is beneﬁcial to allow the client to directly specify a ranged-hash hash function.
It is true, that the writer of the ranged-
hash function cannot rely on the values of m having speciﬁc numerical properties suitable for hashing (in the sense used in [77]),
since the values of m are determined by a resize policy with possibly orthogonal considerations.
There are two cases where a ranged-hash function can be superior.
The ﬁrs is when using perfect hashing: the second is when
the values of m can be used to estimate the "general" number of distinct values required.
This is described in the following.
A Standard String Hash Function
where a is some non-negative integral value.
This is the standard string-hashing function used in SGI’s implementation (with a =
5).
Its advantage is that it takes into account all of the characters of the string.
Now assume that s is the string representation of a of a long DNA sequence (and so S = {’A’, ’C’, ’G’, ’T’}).
In this case,
scanning the entire string might be prohibitively expensive.
Only k String DNA Hash
requiring scanning over only
k = log4( m )
characters.
It should be noted that the above functions cannot be decomposed as per a ranged hash composed of hash and range hashing.
It ﬁrst explains range-hashing functions in collision-
chaining tables, then ranged-hash functions in collision-chaining tables, then probing-based tables, and ﬁnally lists the relevant
classes in this library.
In general, Comb_Hash_Fn is considered a range-hashing functor.
The ﬁgure below shows an insert sequence diagram for this case.
The user inserts
an element (point A), the container transforms the key into a non-negative integral using the hash functor (points B and C), and
transforms the result into a position using the combining functor (points D and E).
Insert hash sequence diagram
If cc_hash_table’s hash-functor, Hash_Fn is instantiated by null_type , then Comb_Hash_Fn is taken to be a ranged-
hash function.
The graphic below shows an insert sequence diagram.
The user inserts an element (point A), the container
transforms the key into a position using the combining functor (points B and C).
Insert hash sequence diagram with a null policy
21.3.2.Probing tables
gp_hash_table is parametrized by Hash_Fn, Probe_Fn, and Comb_Probe_Fn.
As before, if Hash_Fn and Probe_Fn
are both null_type, then Comb_Probe_Fn is a ranged-probe functor.
Otherwise, Hash_Fn is a hash functor, Probe_Fn
is a functor for offsets from a hash value, and Comb_Probe_Fn transforms a probe sequence into a sequence of positions within
the table.
The graphic below shows the relationships.
Hash policy class diagram
21.3.2.Resize Policies

21.3.2.General
Hash-tables, as opposed to trees, do not naturally grow or shrink.
It is necessary to specify policies to determine how and when
a hash table should change its size.
Usually, resize policies can be decomposed into orthogonal policies:
1.
A size policy indicating how a hash table should grow (e.g., it should multiply by powers of 2).
A trigger policy indicating when a hash table should grow (e.g., a load factor is exceeded).
These policies are simple, and there are relatively few sensible options.
An
exponential-size policy (with the initial size and growth factors both powers of 2) works well with a mask-based range-hashing
function, and is the hard-wired policy used by Dinkumware.
A prime-list based policy works well with a modulo-prime range
hashing function and is the hard-wired policy used by SGI’s implementation.
Following is a description of two policies: load-check policies, and
collision-check policies.
Load-check policies are straightforward.
Amax
Collision-check policies work in the opposite direction of load-check policies.
They focus on keeping the number of collisions
moderate and hoping that the size of the table will not grow very large, instead of keeping a moderate load-factor and hoping
that the number of collisions will be small.
A maximal collision-check policy resizes when the longest probe-sequence grows
too large.
Consider the graphic below.
Let the size of the hash table be denoted by m, the length of a probe sequence be denoted by k, and
some load factor be denoted by A.
Balls and bins
Denote the probability that a probe sequence of length k appears in bin i by pi, the length of the probe sequence of bin i by li, and
assume uniform distribution.
To calculate the probability that some bin contains a probe sequence greater
than k, we note that the li are negatively-dependent ([67]) .
Let I(.) denote the indicator function.
Inserting the
ﬁrst probability equation into the second one, and equating with 1/m, we obtain
k ~ √ ( 2 α ln 2 m ln(m) ) ) .
It ﬁrst describes resize policies and their decom-
position into trigger and size policies, then describes pre-deﬁned classes, and ﬁnally discusses controlled access the policies’
internals.
As a container object is modiﬁed, it continuously notiﬁes its Resize_Policy base of internal changes (e.g., collisions en-
countered and elements being inserted).
It queries its Resize_Policy base whether it needs to be resized, and if so, to what
size.
The graphic below shows a (possible) sequence diagram of an insert operation.
The user inserts an element; the hash table notiﬁes
its resize policy that a search has started (point A); in this case, a single collision is encountered - the table notiﬁes its resize
policy of this (point B); the container ﬁnally notiﬁes its resize policy that the search has ended (point C); it then queries its resize
policy whether a resize is needed, and if so, what is the new size (points D to G); following the resize, it notiﬁes the policy that a
resize has completed (point H); ﬁnally, the element is inserted, and the policy notiﬁed (point I).
Consequently, the
library contains a single class for instantiating a resize policy: hash_standard_resize_policy is parametrized by
Size_Policy and Trigger_Policy, derives publicly from both, and acts as a standard delegate ([71]) to these poli-
cies.
The two graphics immediately below show sequence diagrams illustrating the interaction between the standard resize policy and
its trigger and size policies, respectively.
This class is currently instantiated only by hash_standard_resize_policy.
Currently, Trigger_Policy is instantiated by hash_load_che
or cc_hash_max_collision_check_resize_trigger; Size_Policy is instantiated by hash_exponential_size_p
or hash_prime_size_policy.
E.g., it is sometimes useful to query a hash-
table for the table’s actual size (as opposed to its size() - the number of values it currently holds); it is sometimes useful to set
a table’s initial size, externally resize it, or change load factors.
Clearly, supporting such methods both decreases the encapsulation of hash-based containers, and increases the diversity between
different associative-containers’ interfaces.
Conversely, omitting such methods can decrease containers’ ﬂexibility.
In order to avoid, to the extent possible, the above conﬂict, the hash-based containers themselves do not address any of these ques-
tions; this is deferred to the resize policies, which are easier to change or replace.
Thus, for example, neither cc_hash_table
nor gp_hash_table contain methods for querying the actual size of the table; this is deferred to hash_standard_resize_polic
Furthermore, the policies themselves are parametrized by template arguments that determine the methods they support ( [56]
shows techniques for doing so).
Some operations, for example, resizing a container at run time, or changing the load factors of a load-check trigger policy,
require the container itself to resize.
As mentioned above, the hash-based containers themselves do not contain these types of
methods, only their resize policies.
Consequently, there must be some mechanism for a resize policy to manipulate the hash-based
container.
As the hash-based container is a subclass of the resize policy, this is done through virtual methods.
Each hash-based
container has a private virtual method:
virtual void
do_resize
(size_type new_size);
which resizes the container.
Implementations of Resize_Policy can export public methods for resizing the container exter-
nally; these methods internally call do_resize to resize the table.
One of the more complicated aspects of this is that
poor combinations of good policies can form a poor container.
Following are some considerations.
For example, combining a quadratic probe policy with an expo-
nential size policy can yield a poor container: when an element is inserted, a trigger policy might decide that there is no need to
resize, as the table still contains unused entries; the probe sequence, however, might never reach any of the unused entries.
Unfortunately, this library cannot detect such problems at compilation (they are halting reducible).
It therefore deﬁnes an excep-
tion class insert_error to throw an exception in this case.
21.3.2.hash/trigger
Some trigger policies are especially susceptible to poor hash functions.
Suppose, as an extreme case, that the hash function
transforms each key to the same hash value.
After some inserts, a collision detecting policy will always indicate that the container
needs to grow.
The library, therefore, by design, limits each operation to one resize.
For each insert, for example, it queries only once whether
a resize is needed.
If
the latter parameter is true, then the container stores with each entry a hash value, and uses this value in case of collisions to
determine whether to apply a hash value.
This can lower the cost of collision for some types, but increase the cost of collisions
for other types.
If a ranged-hash function or ranged probe function is directly supplied, however, then it makes no sense to store the hash value
with each entry.
This library’s container will fail at compilation, by design, if this is attempted.
For example, an exponential size policy might
issue the sequence of sizes 8, 16, 32, 64, ...
This will ensure that the amortized hash cost of each modifying operation is at most approximately 3.
αmin ~ αmax is, in any case, a bad choice, and αmin > α max is horrendous.
The parameters have the following meaning:
1.
Key is the key type.
Mapped is the mapped-policy.
Tag speciﬁes which underlying data structure to use.
Allocator is an allocator type.
The Tag parameter speciﬁes which underlying data structure to use.
Instantiating it by rb_tree_tag, splay_tree_tag,
or ov_tree_tag, speciﬁes an underlying red-black tree, splay tree, or ordered-vector tree, respectively; any other tag is illegal.
Note that containers based on the former two contain more types and methods than the latter (e.g., reverse_iterator and
rbegin), and different exception and invalidation guarantees.
B.
The ﬁrst is a tree of ﬂoats; the second is a tree of pairs, each
signifying a geometric line interval.
Each element in a tree is referred to as a node of the tree.
Of course, each of these trees can
support the usual queries: the ﬁrst can easily search for 0.4; the second can easily search for std::make_pair(10, 41).
Each of these trees can efﬁciently support other queries.
The ﬁrst can efﬁciently determine that the 2rd key in the tree is 0.3;
the second can efﬁciently determine whether any of its intervals overlaps
std::make_pair(29,42)
(useful in geometric applications or distributed ﬁle systems with leases, for example).
It should be noted that an std::set can
only solve these types of problems with linear complexity.
The ﬁrst stores in
each node the size of the sub-tree rooted at the node; the second stores at each node the maximal endpoint of the intervals at the
sub-tree rooted at the node.
There must be a way to specify what a node’s metadata should be (if any).
Various operations can invalidate node invariants.
The graphic below shows how a right rotation, performed on A, results
in B, with nodes x and y having corrupted invariants (the grayed nodes in C).
The graphic shows how an insert, performed
on D, results in E, with nodes x and y having corrupted invariants (the grayed nodes in F).
It is not feasible to know outside
the tree the effect of an operation on the nodes of the tree.
The search paths of standard associative containers are deﬁned by comparisons between keys, and not through metadata.
It is not feasible to know in advance which methods trees can support.
Besides the usual find method, the ﬁrst tree can
support a find_by_order method, while the second can support an overlaps method.
Tree node invalidation
These problems are solved by a combination of two means: node iterators, and template-template node updater parameters.
These
iterators allow descending from a node to one of its children.
Node iterator allow search paths different than those determined
by the comparison functor.
The ﬁrst pairs return node iterators corresponding to the root node of the tree; the latter pair returns node iterators corresponding
to a just-after-leaf node.
A tree-based container instan-
tiates Node_Update to some node_update class, and publicly subclasses node_update.
The graphic below shows this
scheme, as well as some predeﬁned policies (which are explained below).
A tree and its update policy
node_update (an instantiation of Node_Update) must deﬁne metadata_type as the type of metadata it requires.
For
order statistics, e.g., metadata_type might be size_t.
The tree deﬁnes within each node a metadata_type object.
In this method, nd_it is a node_iterator corresponding to a node whose A) all descendants have valid invariants, and B)
its own invariants might be violated; end_nd_it is a const_node_iterator corresponding to a just-after-leaf node.
This
method should correct the node invariants of the node pointed to by nd_it.
For example, say node x in the graphic below label
A has an invalid invariant, but its’ children, y and z have valid invariants.
After the invocation, all three nodes should have valid
invariants, as in label B.
Figure 21.25: Restoring node invariants
When a tree operation might invalidate some node invariant, it invokes this method in its node_update base to restore the
invariant.
For example, the graphic below shows an insert operation (point A); the tree performs some operations, and calls
the update functor three times (points B, C, and D).
How can a tree which supports order statistics deﬁne a method such as find_by_order?
2.
How can the node updater base access methods of the tree?
3.
How can the following cyclic dependency be resolved?
The ﬁrst two questions are answered by the fact that node_update (an instantiation of Node_Update) is a public base class
of the tree.
Any public methods of node_update are automatically methods of the tree ([56]).
Thus an order-statistics node up-
dater, tree_order_statistics_node_update deﬁnes the find_by_order method; any tree instantiated by
this policy consequently supports this method as well.
In C++, if a base class declares a method as virtual, it is virtual in its subclasses.
If node_update needs to access
one of the tree’s methods, say the member function end, it simply declares that method as virtual abstract.
The cyclic dependency is solved through template-template parameters.
Node_Update is parametrized by the tree’s node
iterators, its comparison functor, and its allocator type.
Thus, instantiations of Node_Update have all information required.
This library assumes that constructing a metadata object and modifying it are exception free.
Suppose that during some method,
say insert, a metadata-related operation (e.g., changing the value of a metadata) throws an exception.
Ack!
Rolling back the
method is unusually complex.
Node invariants show a case where null policies
are required.
Assume a regular tree is required, one which need not support order statistics or interval overlap queries.
Seemingly, in this case
a redundant policy - a policy which doesn’t affect nodes’ contents would sufﬁce.
This, would lead to the following drawbacks:
1.
Each node would carry a useless metadata object, wasting space.
The tree cannot know if its Node_Update policy actually modiﬁes a node’s metadata (this is halting reducible).
In the
graphic below, assume the shaded node is inserted.
The tree would have to traverse the useless path shown to the root,
applying redundant updates all the way.
Useless update path
A null policy class, null_node_update solves both these problems.
The tree detects that node invariants are irrelevant, and
deﬁnes all accordingly.
21.3.2.Split and Join

Tree-based containers support split and join methods.
It is possible to split a tree so that it passes all nodes with keys larger than
a given key to a different tree.
These methods have the following advantages over the alternative of externally inserting to the
destination tree and erasing from the source tree:
1.
These methods are efﬁcient - red-black trees are split and joined in poly-logarithmic complexity; ordered-vector trees are
split and joined at linear complexity.
The alternatives have super-linear complexity.
Aside from orders of growth, these operations perform few allocations and de-allocations.
For red-black trees, allocations
are not performed, and the methods are exception-free.
Key is the key type.
Mapped is the mapped-policy.
E_Access_Traits is described in below.
This is described below.
Allocator is an allocator type.
The Tag parameter speciﬁes which underlying data structure to use.
Instantiating it by pat_trie_tag, speciﬁes an underlying
PATRICIA trie (explained shortly); any other tag is currently illegal.
Following is a description of a (PATRICIA) trie (this implementation follows [90] and [69]).
A (PATRICIA) trie is similar to a tree, but with the following differences:
1.
It explicitly views keys as a sequence of elements.
E.g., a trie can view a string as a sequence of characters; a trie can view
a number as a sequence of bits.
It is not (necessarily) binary.
Each node has fan-out n + 1, where n is the number of distinct elements.
It stores values only at leaf nodes.
Internal nodes have the properties that A) each has at least two children, and B) each shares the same preﬁx with any of its
descendant.
A (PATRICIA) trie has some useful properties:

1.
It can be conﬁgured to use large node fan-out, giving it very efﬁcient ﬁnd performance (albeit at insertion complexity and
size).
It works well for common-preﬁx keys.
It can support efﬁciently queries such as which keys match a certain preﬁx.
This is sometimes useful in ﬁle systems and
routers, and for "type-ahead" aka predictive text matching on mobile devices.
For example, a trie can view a string as a sequence of characters.
A
trie needs to map each of n elements to a number .
For example, a trie can map a character c to
static_cast<size_t>(c)
.
Seemingly, then, a trie can assume that its keys support (const) iterators, and that the value_type of this iterator can be cast
to a size_t.
There are several reasons, though, to decouple the mechanism by which the trie accesses its keys’ elements from
the trie:
1.
In some cases, the numerical value of an element is inappropriate.
Consider a trie storing DNA strings.
It is logical to use
a trie with a fan-out of 5 = 1 + |{’A’, ’C’, ’G’, ’T’}|.
This requires mapping ’T’ to 3, though.
In some cases the keys’ iterators are different than what is needed.
For example, a trie can be used to search for common
sufﬁxes, by using strings’ reverse_iterator.
As another example, a trie mapping UNICODE strings would have a
huge fan-out if each node would branch on a UNICODE character; instead, one can deﬁne an iterator iterating over 8-bit
(or less) groups.
Each such traits deﬁne some types, like:
typename E_Access_Traits::const_iterator
is a const iterator iterating over a key’s elements.
The traits class must also deﬁne methods for obtaining an iterator to the ﬁrst
and last element of a key.
The graphic below shows a (PATRICIA) trie resulting from inserting the words: "I wish that I could ever see a poem lovely as a
trie" (which, unfortunately, does not rhyme).
The leaf nodes contain values; each internal node contains two typename E_Access_Traits::const_iterator ob-
jects, indicating the maximal common preﬁx of all keys in the sub-tree.
For example, the shaded internal node roots a sub-tree
with leafs "a" and "as".
The maximal common preﬁx is "a".
The internal node contains, consequently, to const iterators, one
pointing to ’a’, and the other to ’s’.
A PATRICIA trie
21.3.2.Node Invariants
Trie-based containers support node invariants, as do tree-based containers.
There are two minor differences, though, which,
unfortunately, thwart sharing them sharing the same node-updating policies:
1.
A trie’s Node_Update template-template parameter is parametrized by E_Access_Traits, while a tree’s Node_Update
template-template parameter is parametrized by Cmp_Fn.
The graphic below shows the scheme, as well as some predeﬁned policies (which are explained below).
This library offers the following pre-deﬁned trie node updating policies:
1. trie_order_statistics_node_update supports order statistics.
Key is the key type.
Mapped is the mapped-policy.
Update_Policy is a policy updating positions in the list based on access patterns.
It is described in the following
subsection.
Allocator is an allocator type.
A list-based associative container is a container that stores elements in a linked-list.
It does not order the elements by any
particular order related to the keys.
List-based containers are primarily useful for creating "multimaps".
In fact, list-based
containers are designed in this library expressly for this purpose.
List-based containers might also be useful for some rare cases, where a key is encapsulated to the extent that only key-equivalence
can be tested.
Hash-based containers need to know how to transform a key into a size type, and tree-based containers need to know
if some key is larger than another.
List-based associative containers, conversely, only need to know if two keys are equivalent.
Since a list-based associative container does not order elements by keys, is it possible to order the list in some useful manner?
Remarkably, many on-line competitive algorithms exist for reordering lists to reﬂect access prediction.
The graphic below shows a simple list of integer keys.
If we search for the integer 6, we are paying an overhead: the link with
key 6 is only the ﬁfth link; if it were the ﬁrst link, it could be accessed faster.
A simple list
List-update algorithms reorder lists as elements are accessed.
They try to determine, by the access history, which keys to move
to the front of the list.
Some of these algorithms require adding some metadata alongside each entry.
For example, in the graphic below label A shows the counter algorithm.
Each node contains both a key and a count metadata
(shown in bold).
When an element is accessed (e.g. 6) its count is incremented, as shown in label B.
If the count reaches some
predetermined value, say 10, as shown in label C, the count is set to 0 and the node is moved to the front of the list, as in label D.

Figure 21.31: The counter algorithm
21.3.2.Policies
this library allows instantiating lists with policies implementing any algorithm moving nodes to the front of the list (policies
implementing algorithms interchanging nodes are unsupported).
Associative containers based on lists are parametrized by a Update_Policy parameter.
This parameter deﬁnes the type of
metadata each node contains, how to create the metadata, and how to decide, using this metadata, whether to move a node to the
front of the list.
A list-based associative container object derives (publicly) from its update policy.
An instantiation of Update_Policy must deﬁne internally update_metadata as the metadata it requires.
Internally, each
node of the list contains, besides the usual key and data, an instance of typename Update_Policy::update_metadata.
The ﬁrst is called by the container object, when creating a new node, to create the node’s metadata.
The second is called by
the container object, when a node is accessed ( when a ﬁnd operation’s key is equivalent to the key of the node), to determine
whether to move the node to the front of the list.
The library contains two predeﬁned implementations of list-update policies.
The ﬁrst is lu_counter_policy, which imple-
ments the counter algorithm described above.
The second is lu_move_to_front_policy, which unconditionally move an
accessed element to the front of the list.
The latter type is very useful in this library, since there is no need to associate metadata
with each element.
List-based containers are especially useful as associative containers for secondary keys.
In fact, they are implemented here
expressly for this purpose.
To begin with, these containers use very little per-entry structure memory overhead, since they can be implemented as singly-
linked lists.
More importantly, though, list-based containers use very little per-container memory overhead.
The memory overhead of an
empty list-based container is practically that of a pointer.
This is important for when they are used as secondary associative-
containers in situations where the average ratio of secondary keys to primary keys is low (or even 1).
In order to reduce the per-container memory overhead as much as possible, they are implemented as closely as possible to
singly-linked lists.
This means that their size method has
linear complexity (just like std::list).
Note that ﬁnding the number of equivalent-key values in a standard multimap
also has linear complexity (because it must be done, via std::distance of the multimap’s equal_range method),
but usually with higher constants.
Most associative-container objects each hold a policy object (a hash-based container object holds a hash functor).
List-
based containers, conversely, only have class-wide policy objects.
Tag speciﬁes which underlying data structure to use.
The Tag parameter speciﬁes which underlying data structure to use.
Instantiating it bypairing_heap_tag,binary_heap_tag,
binomial_heap_tag, rc_binomial_heap_tag, or thin_heap_tag, speciﬁes, respectively, an underlying pairing
heap ([70]), binary heap ([66]), binomial heap ([66]), a binomial heap with a redundant binary counter ([80]), or a thin heap
([75]).
As mentioned in the tutorial, __gnu_pbds::priority_queue shares most of the same interface with std::priority_queue.
E.g. if q is a priority queue of type Q, then q.top() will return the "largest" value in the container (according to typename

Q::cmp_fn).
Different settings require different priority-queue implementations which are described in later; see traits discusses ways to
differentiate between the different traits of different implementations.
Unfortunately, most such structures are
oriented towards making push and top efﬁcient, and consequently don’t allow efﬁcient access of other elements: for instance,
they cannot support an efﬁcient find method.
In the use case where it is important to both access and "do something with" an
arbitrary value, one would be out of luck.
For example, many graph algorithms require modifying a value (typically increasing it
in the sense of the priority queue’s comparison functor).
In order to access and manipulate an arbitrary value in a priority queue, one needs to reference the internals of the priority queue
from some form of an associative container - this is unavoidable.
Of course, in order to maintain the encapsulation of the priority
queue, this needs to be done in a way that minimizes exposure to implementation internals.
In this library the priority queue’s insert method returns an iterator, which if valid can be used for subsequent modify
and erase operations.
This both preserves the priority queue’s encapsulation, and allows accessing arbitrary values (since the
returned iterators from the push operation can be stored in some form of associative container).
Priority queues’ iterators present a problem regarding their invalidation guarantees.
One assumes that calling operator++ on
an iterator will associate it with the "next" value.
Priority-queues are self-organizing: each operation changes what the "next"
value means.
Consequently, it does not make sense that push will return an iterator that can be incremented - this can have no
possible use.
Also, as in the case of hash-based containers, it is awkward to deﬁne if a subsequent push operation invalidates
a prior returned iterator: it invalidates it in the sense that its "next" value is not related to what it previously considered to be
its "next" value.
However, it might not invalidate it, in the sense that it can be de-referenced and used for modify and erase
operations.
Similarly to the case of the other unordered associative containers, this library uses a distinction between point-type and range
type iterators.
A priority queue’s iterator can always be converted to a point_iterator, and a const_iterator can
always be converted to a point_const_iterator.
A priority queue of integers.
Now modify a value.
p.modify(it, 3);
assert(p.top() == 3);
It should be noted that an alternative design could embed an associative container in a priority queue.
Could, but most probably
should not.
To begin with, it should be noted that one could always encapsulate a priority queue and an associative container
mapping values to priority queue iterators with no performance loss.
One cannot, however, "un-encapsulate" a priority queue
embedding an associative container, which might lead to performance loss.
Assume, that one needs to associate each value
with some data unrelated to priority queues.
Then using this library’s design, one could use an associative container mapping
each value to a pair consisting of this data and a priority queue’s iterator.
Using the embedded method would need to use two
associative containers.
Similar problems might arise in cases where a value can reside simultaneously in many priority queues.
Underlying Priority-Queue Data-Structures.
Roughly speaking, any value that is both pushed and popped from a priority queue must incur a logarithmic expense (in the
amortized sense).
Any priority queue implementation that would avoid this, would violate known bounds on comparison-based
sorting (see [66] and [64]).
Most implementations do not differ in the asymptotic amortized complexity of push and pop operations, but they differ in the
constants involved, in the complexity of other operations (e.g., modify), and in the worst-case complexity of single operations.
In general, the more "structured" an implementation (i.e., the more internal invariants it possesses) - the higher its amortized
complexity of push and pop operations.
This library implements different algorithms using a single class: priority_queue.
Instantiating the Tag template parameter,
"selects" the implementation:
1.
The former is internally selected by priority_queue if Value_Type is instantiated by a primitive type (e.g., an int);
the latter is internally selected for all other types (e.g., std::string).
This implementations is relatively unstructured,
and so has good push and pop performance; it is the "best-in-kind" for primitive types, e.g., ints.
Conversely, it has high
worst-case performance, and can support only linear-time modify and erase operations.
Instantiating Tag = pairing_heap_tag creates a pairing heap of the form in represented by label B in the graphic
above.
This implementations too is relatively unstructured, and so has good push and pop performance; it is the "best-
in-kind" for non-primitive types, e.g., std:strings.
It also has very good worst-case push and join performance
(O(1)), but has high worst-case pop complexity.
This implementations is more structured than a pairing heap, and so has worse push and pop performance.
Conversely, it has sub-linear worst-case bounds for pop, e.g., and so it might be preferred in cases where responsiveness
is important.
Instantiating Tag = rc_binomial_heap_tag creates a binomial heap of the form represented in label B above,
accompanied by a redundant counter which governs the trees.
This implementations is therefore more structured than a
binomial heap, and so has worse push and pop performance.
Conversely, it guarantees O(1) push complexity, and so it
might be preferred in cases where the responsiveness of a binomial heap is insufﬁcient.
Instantiating Tag = thin_heap_tag creates a thin heap of the form represented by the label B in the graphic above.
This implementations too is more structured than a pairing heap, and so has worse push and pop performance.
Con-
versely, it has better worst-case and identical amortized complexities than a Fibonacci heap, and so might be more appro-
priate for some graph algorithms.
Of course, one can use any order-preserving associative container as a priority queue, as in the graphic above label C, possibly
by creating an adapter class over the associative container (much as std::priority_queue can adapt std::vector).
This has the advantage that no cross-referencing is necessary at all; the priority queue itself is an associative container.
Most
associative containers are too structured to compete with priority queues in terms of push and pop performance.
Sadly, this is not
possible.
Just one for instance is in join operations: joining two binary heaps might throw an exception (not corrupt any of the
heaps on which it operates), but joining two pairing heaps is exception free.
Tags and traits are very useful for manipulating generic types.
Given any container Cntnr, the tag of the underlying data structure can be found via typename Cntnr::contain
this is one of the possible tags shown in the graphic below.
Figure 21.33: Priority-Queue Data-Structure Tags.
Additionally, a traits mechanism can be used to query a container type for its attributes.
Given any container Cntnr, then
__gnu_pbds::container_traits<Cntnr>
is a traits class identifying the properties of the container.
To ﬁnd if a container might throw if two of its objects are joined, one can use
container_traits<Cntnr>::split_join_can_throw

Different priority-queue implementations have different invalidation guarantees.
This is especially important, since there is no
way to access an arbitrary value of priority queues except for iterators.
Similarly to associative containers, one can use
container_traits<Cntnr>::invalidation_guarantee
to get the invalidation guarantee type of a priority queue.
It is easy to understand from the graphic above, what container_traits<Cntnr>::invalidation_guarantee will
be for different implementations.
All implementations of type represented by label B have point_invalidation_guarantee:
the container can freely internally reorganize the nodes - range-type iterators are invalidated, but point-type iterators are always
valid.
Implementations of type represented by labels A1 and A2 have basic_invalidation_guarantee: the container
can freely internally reallocate the array - both point-type and range-type iterators might be invalidated.
This has major implications, and constitutes a good reason to avoid using binary heaps.
A binary heap can perform modify or
erase efﬁciently given a valid point-type iterator.
However, in order to supply it with a valid point-type iterator, one needs to
iterate (linearly) over all values, then supply the relevant iterator (recall that a range-type iterator can always be converted to a
point-type iterator).
This means that if the number of modify or erase operations is non-negligible (say super-logarithmic in
the total sequence of operations) - binary heaps will perform badly.


The library contains a single comprehensive regression test.
For a given container type in this library, the test creates an object of
the container type and an object of the corresponding standard type (e.g., std::set).
It then performs a random sequence of
methods with random arguments (e.g., inserts, erases, and so forth) on both objects.
At each operation, the test checks the return
value of the method, and optionally both compares this library’s object with the standard’s object as well as performing other
consistency checks on this library’s object (e.g., order preservation, when applicable, or node invariants, when applicable).
Additionally, the test integrally checks exception safety and resource leaks.
This is done as follows.
A special allocator type,
written for the purpose of the test, both randomly throws an exceptions when allocations are performed, and tracks allocations
and de-allocations.
The exceptions thrown at allocations simulate memory-allocation failures; the tracking mechanism checks
for memory-related bugs (e.g., resource leaks and multiple de-allocations).
Both this library’s containers and the containers’
value-types are conﬁgured to use this allocator.
For granularity, the test is split into the several sources, each checking only some containers.
For more details, consult the ﬁles in testsuite/ext/pb_ds/regression.
It measures the average time for find as a function of the number of values inserted.
It uses the test ﬁle: performance/ext/pb_ds/text_find_timing_test.cc
And uses the data ﬁle: filethirty_years_among_the_dead_preproc.txt
The test checks the effect of different range-hashing functions, trigger policies, and cache-hashing policies.
As the results show, containers using
mod-based range-hashing (including the native hash-based container, which is currently hard-wired to this scheme) have lower
performance than those using mask-based range-hashing.
A modulo-based range-hashing scheme’s main beneﬁt is that it takes
into account all hash-value bits.
Standard string hash-functions are designed to create hash values that are nearly-uniform as is
([77]).
Trigger policies, i.e. the load-checks constants, affect performance to a lesser extent.
Perhaps surprisingly, storing the hash value alongside each entry affects performance only marginally, at least in this library’s im-
plementation.
It
measures the average time for find as a function of the number of values inserted.
It uses the test ﬁle: performance/ext/pb_ds/random_int_find_timing.cc
The test checks the effect of different underlying hash-tables, range-hashing functions, and trigger policies.
The ﬁrst graphic below shows the results for the native and collision-chaining hash types.
The function applied being a random
integer timing test using find.
The function applied being a random
integer timing test using find.
When comparing probing and chaining containers, it is apparent that the probing containers are less efﬁcient than the collision-
chaining containers ( std::tr1::unordered_map uses collision-chaining) in this case.
In the above graphics should be noted that std::tr1::unordered_map are hard-wired
currently to mod-based schemes.
It measures the average time for operator[] as a function of the number of values inserted.
It uses the test ﬁle: performance/ext/pb_ds/random_int_subscript_find_timing.cc
The test checks the effect of different underlying hash-tables, range-hashing functions, and trigger policies.
The ﬁrst graphic below shows the results for the native and collision-chaining hash types, using as the function applied an integer
subscript timing test with find.
The function applied being a random
integer timing test using find.
This test inserts a number of values with uniform i.i.d.
It measures the
average time for operator[] as a function of the number of values inserted.
It uses the test ﬁle: performance/ext/pb_ds/random_int_subscript_insert_timing.cc
The test checks the effect of different underlying hash-tables.
The ﬁrst graphic below shows the results for the native and collision-chaining hash types, using as the function applied an integer
subscript timing test with insert.
The function applied being a random
integer timing test using find.
There are some differences, however:

1.
In this setting, probing tables function sometimes more efﬁciently than collision-chaining tables.
This is explained shortly.
The performance graphs have a "saw-tooth" shape.
The average insert time rises and falls.
As values are inserted into
the container, the load factor grows larger.
Eventually, a resize occurs.
The reallocations and rehashing are relatively
expensive.
After this, the load factor is smaller than before.
Collision-chaining containers use indirection for greater ﬂexibility; probing containers store values contiguously, in an array (see
Figure Motivation::Different underlying data structures A and B, respectively).
It follows that for simple data types, probing
containers access their allocator less frequently than collision-chaining containers, (although they still have less efﬁcient probing
sequences).
This explains why some probing containers fare better than collision-chaining containers in this case.
Within each type of hash-table, the range-hashing scheme affects performance more than other policies.
This is similar to the
situation in Hash-Based Text find Find Timing Test and Hash-Based Integer find Find Timing Test.
Unsurprisingly, however,
containers with lower αmax perform worse in this case, since more re-hashes are performed.
It measures the average time for find as a function of the number of values in the containers.
The keys are
generated as follows.
First, a uniform integer is created.
Then it is then shifted left 8 bits.
The test checks the effect of different range-hashing functions and trigger policies.
The range-hashing scheme affects performance dramatically.
A mask-based range-hashing scheme effectively maps all values
into the same bucket.
Access degenerates into a search within an unordered linked-list.
In the graphic above, it should be noted
that std::tr1::unordered_map is hard-wired currently to mod-based and mask-based schemes, respectively.
When observing the settings of this test, it is apparent that the keys’ distribution is far from natural.
One might ask if the test
is not contrived to show that, in some cases, mod-based range hashing does better than mask-based range hashing.
This is, in
fact just the case.
A more natural case in which mod-based range hashing is better was not encountered.
Thus the inescapable
conclusion: real-life key distributions are handled better with an appropriate hash function and a mask-based range-hashing
function.
If hash performance is bad, a χ2 test can be used to check how to transform it into a
more uniform distribution.
For this reason, this library’s default range-hashing function is mask-based.
It measures the ﬁnal size of
the container.
It uses the test ﬁle: performance/ext/pb_ds/hash_random_int_erase_mem_usage.cc
The test checks how containers adjust internally as their logical size decreases.
When erasing numerous keys from an
standard associative-container, the resulting memory user varies greatly depending on whether the container is tree-based or
hash-based.
This is a fundamental consequence of the standard’s interface for associative containers, and it is not due to a

speciﬁc implementation.
It
measures the average time for insert as a function of the number of values inserted.
The test checks the effect of different underlying data structures.
It uses the test ﬁle: performance/ext/pb_ds/tree_text_insert_timing.cc
21.4.2.Results
The three graphics below show the results for the native tree and this library’s node-based trees, the native tree and this library’s
vector-based trees, and the native tree and this library’s PATRICIA-trie, respectively.
The graphic immediately below shows the results for the native tree type and several node-based tree types.
Name/Instantiating Type
Parameter
Details
n_map
std::map
splay_tree_map
tree
Tag
splay_tree_tag
Node_update
null_node_update
rb_tree_map
tree
Tag
rb_tree_tag
Node_update
null_node_update

The graphic below shows the results for the native tree type and a vector-based tree type.
The abbreviated names in the legend of the graphic above are instantiated with the types in the following table.
Name/Instantiating Type
Parameter
Details
n_map
std::map
ov_tree_map
tree
Tag
ov_tree_tag
Node_update
null_node_update
The graphic below shows the results for the native tree type and a PATRICIA trie type.
Name/Instantiating Type
Parameter
Details
n_map
std::map
pat_trie_map
tree
Tag
pat_trie_tag
Node_update
null_node_update
21.4.2.Observations
Observing the ﬁrst graphic implies that for this setting, a splay tree (tree with Tag
= splay_tree_tag) does not do well.
See also the Branch-Based Text find Find Timing Test.
The two red-black trees perform better.
Observing the second graphic, an ordered-vector tree (tree with Tag
= ov_tree_tag) performs abysmally.
Inserting into
this type of tree has linear complexity [ austern00noset].
Observing the third and last graphic, A PATRICIA trie (trie with Tag
= pat_trie_tag) has abysmal performance, as
well.
This is not that surprising, since a large-fan-out PATRICIA trie works like a hash table with collisions resolved by a sub-
trie.
Each time a collision is encountered, a new "hash-table" is built A large fan-out PATRICIA trie, however, doe does well in
look-ups (see Branch-Based Text find Find Timing Test).
It may be beneﬁcial in semi-static settings.
Text find
21.4.2.Description
This test inserts a number of values with keys from an arbitrary text ([wickland96thirty]) into a container, then performs a series
of ﬁnds using find.
It measures the average time for find as a function of the number of values inserted.
It uses the test ﬁle: performance/ext/pb_ds/text_find_timing.cc
The test checks the effect of different underlying data structures.
Name/Instantiating Type
Parameter
Details
n_map
std::map
splay_tree_map
tree
Tag
splay_tree_tag
Node_Update
null_node_update
rb_tree_map
tree
Tag
rb_tree_tag
Node_Update
null_node_update
ov_tree_map
tree
Tag
ov_tree_tag
Node_Update
null_node_update
pat_trie_map
tree
Tag
pat_trie_tag
Node_Update
null_node_update
21.4.2.Observations
For this setting, a splay tree (tree with Tag
= splay_tree_tag) does not do well.
This is possibly due to two reasons:
1.
A splay tree is not guaranteed to be balanced [motwani95random].
If a splay tree contains n nodes, its average root-leaf
path can be m >> log(n).
Assume a speciﬁc root-leaf search path has length m, and the search-target node has distance m’ from the root.
A splay tree,
consequently, can perform many more comparisons than a red-black tree.
An ordered-vector tree (tree with Tag = ov_tree_tag), a red-black tree (tree with Tag = rb_tree_tag), and the
native red-black tree all share approximately the same performance.
An ordered-vector tree is slightly slower than red-black trees, since it requires, in order to ﬁnd a key, more math operations than
they do.
Conversely, an ordered-vector tree requires far lower space than the others.
A PATRICIA trie (trie with Tag = pat_trie_tag) has good look-up performance, due to its large fan-out in this case.
In
this setting, a PATRICIA trie has look-up performance comparable to a hash table (see Hash-Based Text find Timing Test),
but it is order preserving.
This is not that surprising, since a large-fan-out PATRICIA trie works like a hash table with collisions
resolved by a sub-trie.
A large-fan-out PATRICIA trie does not do well on modiﬁcations (see Tree-Based and Trie-Based Text
Insert Timing Test).
Therefore, it is possibly beneﬁcial in semi-static settings.
It is different than Tree-Based and Trie-Based Text find Find Timing Test in the sequence of ﬁnds it
performs: this test performs multiple finds on the same key before moving on to the next key.
It measures the average time for
find as a function of the number of values inserted.
It uses the test ﬁle: performance/ext/pb_ds/tree_text_lor_find_timing.cc
The test checks the effect of different underlying data structures in a locality-of-reference setting.
21.4.2.Results
The graphic immediately below shows the results for the native tree type and several other tree types.
For this setting, an ordered-vector tree (tree with Tag = ov_tree_tag), a red-black tree (tree with Tag = rb_tree_tag),
and the native red-black tree all share approximately the same performance.
A splay tree (tree with Tag = splay_tree_tag) does much better, since each (successful) ﬁnd "bubbles" the corresponding
node to the root of the tree.
It measures the time for splitting and joining the containers as a function of the number of values inserted.
It uses the test ﬁle: performance/ext/pb_ds/tree_split_join_timing.cc
The test checks the performance difference of join as opposed to a sequence of insert operations; by implication, this test
checks the most efﬁcient way to erase a sub-sequence from a tree-like-based container, since this can always be performed by a
small sequence of splits and joins.
Name/Instantiating Type
Parameter
Details
n_set
std::set
splay_tree_set
tree
Tag
splay_tree_tag
Node_Update
null_node_update
rb_tree_set
tree
Tag
rb_tree_tag
Node_Update
null_node_update
ov_tree_set
tree
Tag
ov_tree_tag
Node_Update
null_node_update
pat_trie_map
tree
Tag
pat_trie_tag
Node_Update
null_node_update
21.4.2.Observations
In this test, the native red-black trees must be split and joined externally, through a sequence of erase and insert operations.
This is clearly super-linear, and it is not that surprising that the cost is high.
This library’s tree-based containers use in this test the split and join methods, which have lower complexity: the join
method of a splay tree (tree with Tag
= splay_tree_tag) is quadratic in the length of the longest root-leaf path, and
linear in the total number of elements; the join method of a red-black tree (tree with Tag
= rb_tree_tag) or an ordered-
vector tree (tree with Tag
= ov_tree_tag) is linear in the number of elements.
Asides from orders of growth, this library’s trees access their allocator very little in these operations, and some of them do not
access it at all.
This leads to lower constants in their complexity, and, for some containers, to exception-free splits and joins
(which can be determined via container_traits).
It measures the average time for such queries as a function of the
number of values inserted.
It uses the test ﬁle: performance/ext/pb_ds/tree_order_statistics_timing.cc
The test checks the performance difference of policies based on node-invariant as opposed to a external functions.
In this test, the native red-black tree can support order-statistics queries only externally, by performing a find (alternatively,
lower_bound or upper_bound ) and then using std::distance .
This is clearly linear, and it is not that surprising that
the cost is high.
This library’s tree-based containers use in this test the order_of_key method of tree_order_statistics_node_update.
This method has only linear complexity in the length of the root-node path.
Unfortunately, the average path of a splay tree (tree
with Tag = splay_tree_tag ) can be higher than logarithmic; the longest path of a red-black tree (tree with Tag =
rb_tree_tag ) is logarithmic in the number of elements.
Consequently, the splay tree has worse performance than the red-
black tree.
The ﬁrst item of each pair is a string from an arbitrary text ([wickland96thirty]),
and the second is a uniform i.i.d.integer.
The container is a "multimap" - it considers the ﬁrst member of each pair as a primary
key, and the second member of each pair as a secondary key (see Motivation::Associative Containers::Alternative to Multiple
Equivalent Keys).
There are 400 distinct primary keys, and the ratio of secondary keys to primary keys ranges from 1 to 5.
The test measures the average ﬁnd-time as a function of the number of values inserted.
For this library’s containers, it ﬁnds the
secondary key from a container obtained from ﬁnding a primary key.
For the native multimaps, it searches a range obtained using
std::equal_range on a primary key.
It uses the test ﬁle: performance/ext/pb_ds/multimap_text_find_timing_small.cc
The test checks the ﬁnd-time scalability of different "multimap" designs.
Trigger_Policy
hash_load_check_r
with αmin =
1/8 and αmax
= 1/2
The graphic below show the results for "multimaps" which use a hash-based container for primary keys.
The ﬁrst item of each pair is a string from an arbitrary text ([wickland96thirty]),
and the second is a uniform integer.
The container is a "multimap" - it considers the ﬁrst member of each pair as a primary key,
and the second member of each pair as a secondary key.
There are 400 distinct primary keys, and the ratio of secondary keys to
primary keys ranges from 1 to 5.
The test measures the average ﬁnd-time as a function of the number of values inserted.
For this library’s containers, it ﬁnds the
secondary key from a container obtained from ﬁnding a primary key.
For the native multimaps, it searches a range obtained using
std::equal_range on a primary key.
It uses the test ﬁle: performance/ext/pb_ds/multimap_text_find_timing_large.cc
The test checks the ﬁnd-time scalability of different "multimap" designs.
Trigger_Policy
hash_load_check_r
with αmin =
1/8 and αmax
= 1/2
The graphic below show the results for "multimaps" which use a hash-based container for primary keys.
The ﬁrst item of each pair is a string from an arbitrary text ([wickland96thirty]),
and the second is a uniform integer.
The container is a "multimap" - it considers the ﬁrst member of each pair as a primary key,
and the second member of each pair as a secondary key.
There are 400 distinct primary keys, and the ratio of secondary keys to
primary keys ranges from 1 to 5.
The test measures the average insert-time as a function of the number of values inserted.
For this library’s containers, it inserts a
primary key into the primary associative container, then a secondary key into the secondary associative container.
For the native
multimaps, it obtains a range using std::equal_range, and inserts a value only if it was not contained already.
It uses the test ﬁle: performance/ext/pb_ds/multimap_text_insert_timing_small.cc
The test checks the insert-time scalability of different "multimap" designs.
Trigger_Policy
hash_load_check_r
with αmin =
1/8 and αmax
= 1/2
The graphic below show the results for "multimaps" which use a hash-based container for primary keys.
The ﬁrst item of each pair is a string from an arbitrary text ([wickland96thirty]),
and the second is a uniform integer.
The container is a "multimap" - it considers the ﬁrst member of each pair as a primary key,
and the second member of each pair as a secondary key.
There are 400 distinct primary keys, and the ratio of secondary keys to
primary keys ranges from 1 to 5.
The test measures the average insert-time as a function of the number of values inserted.
For this library’s containers, it inserts a
primary key into the primary associative container, then a secondary key into the secondary associative container.
For the native
multimaps, it obtains a range using std::equal_range, and inserts a value only if it was not contained already.
It uses the test ﬁle: performance/ext/pb_ds/multimap_text_insert_timing_large.cc
The test checks the insert-time scalability of different "multimap" designs.
Trigger_Policy
hash_load_check_r
with αmin =
1/8 and αmax
= 1/2
The graphic below show the results for "multimaps" which use a hash-based container for primary keys.
The ﬁrst item of each pair is a string from an arbitrary text ([wickland96thirty]),
and the second is a uniform integer.
The container is a "multimap" - it considers the ﬁrst member of each pair as a primary key,
and the second member of each pair as a secondary key.
There are 100 distinct primary keys, and the ratio of secondary keys to
primary keys ranges to about 20.
The test measures the memory use as a function of the number of values inserted.
It uses the test ﬁle: performance/ext/pb_ds/multimap_text_insert_mem_usage_small.cc
The test checks the memory scalability of different "multimap" designs.
Trigger_Policy
hash_load_check_r
with αmin =
1/8 and αmax
= 1/2
The graphic below show the results for "multimaps" which use a hash-based container for primary keys.
The ﬁrst item of each pair is a string from an arbitrary text ([wickland96thirty]),
and the second is a uniform integer.
The container is a "multimap" - it considers the ﬁrst member of each pair as a primary key,
and the second member of each pair as a secondary key.
There are 100 distinct primary keys, and the ratio of secondary keys to
primary keys ranges to about 20.
The test measures the memory use as a function of the number of values inserted.
It uses the test ﬁle: performance/ext/pb_ds/multimap_text_insert_mem_usage_large.cc
The test checks the memory scalability of different "multimap" designs.
Trigger_Policy
hash_load_check_r
with αmin =
1/8 and αmax
= 1/2
The graphic below show the results for "multimaps" which use a hash-based container for primary keys.
It
measures the average time for push as a function of the number of values pushed.
It uses the test ﬁle: performance/ext/pb_ds/priority_queue_text_push_timing.cc
The test checks the effect of different underlying data structures.
The graphic immediately below shows the results for the native priority_queue type instantiated with different underlying con-
tainer types versus several different versions of library’s priority_queues.
0
200
400
600
800
1000
1200
1400
1600
1800
2000
2200
Size
0.00e+00
1.16e-05
2.32e-05
3.48e-05
4.64e-05
5.80e-05
Average time (sec.)
binary_heap
rc_binomial_heap
n_pq_deque
binomial_heap
n_pq_vector
thin_heap
pairing_heap

The abbreviated names in the legend of the graphic above are instantiated with the types in the following table.
Name/Instantiating Type
Parameter
Details
n_pq_vector
std::priority_queue
Sequence
std::vector
n_pq_deque
std::priority_queue
Sequence
std::deque
thin_heap
priority_queue
Tag
thin_heap_tag
pairing_heap
priority_queue
Tag
pairing_heap_tag

21.4.2.Observations
Pairing heaps (priority_queue with Tag = pairing_heap_tag) are the most suited for sequences of push and pop
operations of non-primitive types (e.g. std::strings).
They are less
constrained than binomial heaps, e.g., and since they are node-based, they outperform binary heaps.
It measures the average time for push as a function of the number of values.
It uses the test ﬁle: performance/ext/pb_ds/priority_queue_text_push_pop_timing.cc
The test checks the effect of different underlying data structures.
The graphic immediately below shows the results for the native priority_queue type instantiated with different underlying con-
tainer types versus several different versions of library’s priority_queues.
0
200
400
600
800
1000
1200
1400
1600
1800
2000
2200
Size
0.00e+00
1.18e-05
2.35e-05
3.53e-05
4.71e-05
5.88e-05
Average time (sec.)
binary_heap
rc_binomial_heap
thin_heap
binomial_heap
n_pq_deque
pairing_heap
n_pq_vector

The abbreviated names in the legend of the graphic above are instantiated with the types in the following table.
These results are very similar to Priority Queue Text push Timing Test.
As stated there, pairing heaps (priority_queue with
Tag = pairing_heap_tag) are most suited for push and pop sequences of non-primitive types such as strings.
Observing
these two tests, one can note that a pairing heap outperforms the others in terms of push operations, but equals binary heaps
(priority_queue with Tag = binary_heap_tag) if the number of push and pop operations is equal.
As the number
of pop operations is at most equal to the number of push operations, pairing heaps are better in this case.
See Priority Queue
Random Integer push and pop Timing Test for a case which is different.
It measures the average time for push as a
function of the number of values.
It uses the test ﬁle: performance/ext/pb_ds/priority_queue_random_int_push_timing.cc
The test checks the effect of different underlying data structures.
The graphic immediately below shows the results for the native priority_queue type instantiated with different underlying con-
tainer types versus several different versions of library’s priority_queues.
0
200
400
600
800
1000
1200
1400
1600
1800
2000
2200
Size
0.00e+00
1.38e-06
2.76e-06
4.14e-06
5.52e-06
6.90e-06
Average time (sec.)
binary_heap
rc_binomial_heap
binomial_heap
thin_heap
pairing_heap
n_pq_deque
n_pq_vector
The abbreviated names in the legend of the graphic above are instantiated with the types in the following table.
Name/Instantiating Type
Parameter
Details
n_pq_vector
std::priority_queue adapting
std::vector
Sequence
std::vector
n_pq_deque
std::priority_queue
Sequence
std::deque
binary_heap
priority_queue
Tag
binary_heap_tag

21.4.2.Observations
Binary heaps are the most suited for sequences of push and pop operations of primitive types (e.g. ints).
They are less
constrained than any other type, and since it is very efﬁcient to store such types in arrays, they outperform even pairing heaps.
This test inserts a number of values with integer keys into a container using push , then removes them using pop .
It measures
the average time for push and pop as a function of the number of values.
It uses the test ﬁle: performance/ext/pb_ds/priority_queue_random_int_push_pop_timing.cc
The test checks the effect of different underlying data structures.
Name/Instantiating Type
Parameter
Details
n_pq_vector
std::priority_queue
Sequence
std::vector
n_pq_deque

Name/Instantiating Type
Parameter
Details
std::priority_queue
Sequence
std::deque
binary_heap
priority_queue
Tag
binary_heap_tag
binomial_heap
priority_queue
Tag
binomial_heap_tag
rc_binomial_heap
priority_queue
Tag
rc_binomial_heap_tag
thin_heap
priority_queue
Tag
thin_heap_tag
pairing_heap
priority_queue
Tag
pairing_heap_tag
21.4.2.Observations
Binary heaps are the most suited for sequences of push and pop operations of primitive types (e.g. ints).
This is explained in
Priority Queue Random Int push Timing Test.
At ﬁrst glance it seems that the standard’s vector-based priority queue is approximately on par with this library’s corresponding
priority queue.
There are two differences however:
1.
The standard’s priority queue does not downsize the underlying vector (or deque) as the priority queue becomes smaller
(see Priority Queue Text pop Memory Use Test).
It is therefore gaining some speed at the expense of space.
From Priority Queue Random Integer push and pop Timing Test, it seems that the standard’s priority queue is slower in
terms of push operations.
Since the number of pop operations is at most that of push operations, the test here is the
"best" for the standard’s priority queue.
This test inserts a number of values with keys from an arbitrary text ([ wickland96thirty ]) into a container, then pops them until
only one is left in the container.
It measures the memory use as a function of the number of values pushed to the container.
It uses the test ﬁle: performance/ext/pb_ds/priority_queue_text_pop_mem_usage.cc
The test checks the effect of different underlying data structures.
Name/Instantiating Type
Parameter
Details
n_pq_vector
std::priority_queue
Sequence
std::vector
n_pq_deque
std::priority_queue
Sequence
std::deque
binary_heap
priority_queue
Tag
binary_heap_tag
binomial_heap
priority_queue
Tag
binomial_heap_tag
rc_binomial_heap
priority_queue
Tag
rc_binomial_heap_tag
thin_heap
priority_queue
Tag
thin_heap_tag
pairing_heap
priority_queue
Tag
pairing_heap_tag
21.4.2.Observations
The priority queue implementations (excluding the standard’s) use memory proportionally to the number of values they hold:
node-based implementations (e.g., a pairing heap) do so naturally; this library’s binary heap de-allocates memory when a certain
lower threshold is exceeded.
Note from Priority Queue Text push and pop Timing Test and Priority Queue Random Integer push and pop Timing Test that
this does not impede performance compared to the standard’s priority queues.
See Hash-Based Erase Memory Use Test for a similar phenomenon regarding priority queues.
This test inserts a number of values with keys from an arbitrary text ([ wickland96thirty ]) into two containers, then merges the
containers.
It uses join for this library’s priority queues; for the standard’s priority queues, it successively pops values from
one container and pushes them into the other.
The test measures the average time as a function of the number of values.
It uses the test ﬁle: performance/ext/pb_ds/priority_queue_text_join_timing.cc
The test checks the effect of different underlying data structures.
In this test the node-based heaps perform join in either logarithmic or constant time.
It would be possible to apply the heapify algorithm to the standard containers, if they would support iteration (which they don’t).
Barring iterators, it is still somehow possible to perform linear-time merge on a std::vector-based standard priority queue,
using top() and size() (since they are enough to expose the underlying array), but this is impossible for a std::deque-
based standard priority queue.
Without heapify, the cost is super-linear.
It uses modify for this library’s priority queues; for the standard’s priority queues, it pops
values from a container until it reaches the value that should be modiﬁed, then pushes values back in.
It measures the average
time for modify as a function of the number of values.
It uses the test ﬁle: performance/ext/pb_ds/priority_queue_text_modify_up_timing.cc
The test checks the effect of different underlying data structures for graph algorithms settings.
Note that making an arbitrary
value larger (in the sense of the priority queue’s comparison functor) corresponds to decrease-key in standard graph algorithms
[clrs2001].
21.4.2.Results
The two graphics below show the results for the native priority_queues and this library’s priority_queues.
The graphic immediately below shows the results for the native priority_queue type instantiated with different underlying con-
tainer types versus several different versions of library’s priority_queues.
Name/Instantiating Type
Parameter
Details
n_pq_vector
std::priority_queue
Sequence
std::vector
n_pq_deque
std::priority_queue
Sequence
std::deque
binary_heap
priority_queue
Tag
binary_heap_tag
binomial_heap
priority_queue
Tag
binomial_heap_tag
rc_binomial_heap
priority_queue
Tag
rc_binomial_heap_tag
thin_heap
priority_queue
Tag
thin_heap_tag
pairing_heap
priority_queue
Tag
pairing_heap_tag
The graphic below shows the results for the native priority queues and this library’s pairing and thin heap priority_queue data
structures.
Name/Instantiating Type
Parameter
Details
thin_heap
priority_queue
Tag
thin_heap_tag
pairing_heap
priority_queue
Tag
pairing_heap_tag
21.4.2.Observations
As noted above, increasing an arbitrary value (in the sense of the priority queue’s comparison functor) is very common in graph-
related algorithms.
In this case, a thin heap (priority_queue with Tag = thin_heap_tag) outperforms a pairing heap
(priority_queue with Tag = pairing_heap_tag).
Conversely, Priority Queue Text push Timing Test, Priority Queue
Text push and pop Timing Test, Priority Queue Random Integer push Timing Test, and Priority Queue Random Integer push
and pop Timing Test show that the situation is reversed for other operations.
It is not clear when to prefer one of these two
different types.
In this test this library’s binary heaps effectively perform modify in linear time.
As explained in Priority Queue Design::Traits,
given a valid point-type iterator, a binary heap can perform modify logarithmically.
The problem is that binary heaps invalidate
their ﬁnd iterators with each modifying operation, and so the only way to obtain a valid point-type iterator is to iterate using a
range-type iterator until ﬁnding the appropriate value, then use the range-type iterator for the modify operation.
The explanation for the standard’s priority queues’ performance is similar to that in Priority Queue Text join Timing Test.
Text modify Down
21.4.2.Description
This test inserts a number of values with keys from an arbitrary text ([ wickland96thirty ]) into into a container then modiﬁes
each one "down" (i.e., it makes it smaller).
It uses modify for this library’s priority queues; for the standard’s priority queues,
it pops values from a container until it reaches the value that should be modiﬁed, then pushes values back in.
It measures the
average time for modify as a function of the number of values.
It uses the test ﬁle: performance/ext/pb_ds/priority_queue_text_modify_down_timing.cc

The main purpose of this test is to contrast Priority Queue Text modify Up Timing Test.
The graphic immediately below shows the results for the native priority_queue type instantiated with different underlying con-
tainer types versus several different versions of library’s priority_queues.
0
200
400
600
800
1000
1200
1400
1600
1800
2000
2200
Size
0.00e+00
8.40e-05
1.68e-04
2.52e-04
3.36e-04
4.20e-04
Average time (sec.)
n_pq_deque
n_pq_vector
binary_heap
thin_heap
rc_binomial_heap
binomial_heap
pairing_heap
The abbreviated names in the legend of the graphic above are instantiated with the types in the following table.
The graphic below shows the results for the native priority queues and this library’s pairing and thin heap priority_queue data
structures.
Name/Instantiating Type
Parameter
Details
thin_heap
priority_queue
Tag
thin_heap_tag
pairing_heap
priority_queue
Tag
pairing_heap_tag
21.4.2.Observations
Most points in these results are similar to Priority Queue Text modify Up Timing Test.
It is interesting to note, however, that as opposed to that test, a thin heap (priority_queue with Tag = thin_heap_tag) is
outperformed by a pairing heap (priority_queue with Tag = pairing_heap_tag).
In this case, both heaps essentially
perform an erase operation followed by a push operation.
As the other tests show, a pairing heap is usually far more efﬁcient
than a thin heap, so this is not surprising.
Most algorithms that involve priority queues increase values (in the sense of the priority queue’s comparison functor), and so
Priority Queue Text modify Up Timing Test - is more interesting than this test.
The main reason to choose a tree-based or trie-based container is if a byproduct of the tree-like structure is required: either order-
preservation, or the ability to utilize node invariants.
If memory-use is the major factor, an ordered-vector tree gives optimal
results (albeit with high modiﬁciation costs), and a list-based container gives reasonable results.
Collision-chaining containers are more ﬂexible in-
ternally, and so offer better timing performance.
Probing containers, if used for simple value-types, manage memory more
efﬁciently (they perform far fewer allocation-related calls).
In general, therefore, a collision-chaining table should be used.
A
probing container, conversely, might be used efﬁciently for operations such as eliminating duplicates in a sequence, or counting
the number of occurrences within a sequence.
Probing containers might be more useful also in multithreaded applications where
each thread manipulates a hash-based container: in the standard, allocators have class-wise semantics (see [meyers96more] -
Item 10); a probing container might incur less contention in this case.
In most settings,
a mask-based scheme works well (or can be made to work well).
If the key-distribution can be estimated a-priori, a simple hash
function can produce nearly uniform hash-value distribution.
In many other cases (e.g., text hashing, ﬂoating-point hashing),
the hash function is powerful enough to generate hash values with good uniformity properties [knuth98sorting]; a modulo-based
scheme, taking into account all bits of the hash value, appears to overlap the hash function in its effort.
The range-hashing scheme determines many of the other policies.
A mask-based scheme works well with an exponential-size
policy; for probing-based containers, it goes well with a linear-probe function.
An orthogonal consideration is the trigger policy.
This presents difﬁcult tradeoffs.
E.g., different load factors in a load-check
trigger policy yield a space/amortized-cost tradeoff.
Following are some observations on their application to different settings.
Of the balanced node-based trees, this library includes a red-black tree, as does standard (in practice).
This type of tree is the
"workhorse" of tree-based containers: it offers both reasonable modiﬁcation and reasonable lookup time.
Unfortunately, this data
structure stores a huge amount of metadata.
Each node must contain, besides a value, three pointers and a boolean.
This type
might be avoided if space is at a premium [austern00noset].
High-probability balanced node-based trees suffer the drawbacks of deterministic balanced trees.
Although they are fascinating
data structures, preliminary tests with them showed their performance was worse than red-black trees.
The library does not
contain any such trees, therefore.
Competitive node-based trees have two drawbacks.
They are usually somewhat unbalanced, and they perform a large number of
comparisons.
Balanced trees perform one comparison per each node they encounter on a search path; a splay tree performs two
comparisons.
If the keys are complex objects, e.g., std::string, this can increase the running time.
Conversely, such trees
do well when there is much locality of reference.
It is difﬁcult to determine in which case to prefer such trees over balanced trees.
This library includes a splay tree.
Ordered-vector trees use very little space [austern00noset].
They do not have any other advantages (at least in this implementa-
tion).
Large-fan-out PATRICIA tries have excellent lookup performance, but they do so through maintaining, for each node, a miniature
"hash-table".
Their space efﬁciency is low, and their modiﬁcation performance is bad.
These tries might be used for semi-static
settings, where order preservation is important.
Alternatively, red-black trees cross-referenced with hash tables can be used.
Moderate-fan-out trees might be useful for sequences where
each element has a limited number of choices, e.g., DNA strings.
Here the focus will be on the case where a
keys can be composed into primary keys and secondary keys.
In this case there are (at least) ﬁve possibilities:
1.
Use an associative container that allows equivalent-key values (such as std::multimap)
2.
Use a unique-key value associative container that maps each primary key to some complex associative container of sec-
ondary keys, say a tree-based or hash-based container.
Use a unique-key value associative container that takes into account both primary and secondary keys.
Stated simply: there is a simple answer for this.
If the expected ratio of secondary keys to primary keys is small, then 3 and 4 seem reasonable.
Both types of secondary containers
are relatively lightweight (in terms of memory use and construction time), and so creating an entire container object for each
primary key is not too expensive.
Option 4 might be preferable to option 3 if changing the secondary key of some primary key
is frequent - one cannot modify an associative container’s key, and the only possibility, therefore, is erasing the secondary key
and inserting another one instead; a non-associative container, conversely, can support in-place modiﬁcation.
The actual cost
of erasing a secondary key and inserting another one depends also on the allocator used for secondary associative-containers
(The tests above used the standard allocator, but in practice one might choose to use, e.g., [boost_pool]).
Option 2 is deﬁnitely
an overkill in this case.
Option 1 loses out either immediately (when there is one secondary key per primary key) or almost
immediately after that.
Option 5 has the same drawbacks as option 2, but it has the additional drawback that ﬁnding all values
whose primary key is equivalent to some key, might be linear in the total number of values stored (for example, if using a
hash-based container).
If the expected ratio of secondary keys to primary keys is large, then the answer is more complicated.
It depends on the distribu-
tion of secondary keys to primary keys, the distribution of accesses according to primary keys, and the types of operations most
frequent.
To be more precise, assume there are m primary keys, primary key i is mapped to ni secondary keys, and each primary key is
mapped, on average, to n secondary keys (i.e., E(ni) = n).
Suppose one wants to ﬁnd a speciﬁc pair of primary and secondary keys.
Suppose one needs the values whose primary key matches some given key.
Using 5 with a hash-based container, the cost is Θ(mn).
Suppose one wants to assign to a primary key all secondary keys assigned to a different primary key.
Using 1 with a hash-based
container, the expected cost is Θ(n), but with very high constants; using 1 with a tree-based container, the cost is Θ(nlog(mn)).
Using 2, 3, and 4, the expected cost is Θ(n), but typically with far lower costs than 1. 5 is similar to 1.
21.4.Priority_Queue
21.4.2.Complexity
The following table shows the complexities of the different underlying data structures in terms of orders of growth.
It is interesting
to note that this table implies something about the constants of the operations as well (see Amortized push and pop operations).
This is not a property of the algorithm, but rather due to the fact that the standard’s priority queue implementation
does not support iterators (and consequently the ability to access a speciﬁc value inside it).
If the priority queue is adapting an
std::vector, then it is still possible to reduce this to Θ(n) by adapting over the standard’s adapter and using the fact that top
returns a reference to the ﬁrst value; if, however, it is adapting an std::deque, then this is impossible.
Again, if the
priority queue is adapting an std::vector then it is possible to reduce this to Θ(n), but with a very high constant (one must
call std::make_heap which is an expensive linear operation); if the priority queue is adapting an std::deque, then this is
impossible.
Note that for most algorithms,
I) is important and II) is not.
All of the underlying data
structures have the same amortized logarithmic complexity, but they differ in terms of constants.
The table above shows that the different data structures are "constrained" in some respects.
In general, if a data structure has lower
worst-case complexity than another, then it will perform slower in the amortized sense.
Thus, for example a redundant-counter
binomial heap (priority_queue with Tag = rc_binomial_heap_tag) has lower worst-case push performance than a
binomial heap (priority_queue with Tag = binomial_heap_tag), and so its amortized push performance is slower
in terms of constants.
As the table shows, the "least constrained" underlying data structures are binary heaps and pairing heaps.
Consequently, it is not
surprising that they perform best in terms of amortized constants.
Pairing heaps seem to perform best for non-primitive types (e.g., std::strings), as shown by Priority Queue Text
push Timing Test and Priority Queue Text push and pop Timing Test
2. binary heaps seem to perform best for primitive types (e.g., ints), as shown by Priority Queue Random Integer push
Timing Test and Priority Queue Random Integer push and pop Timing Test.
The table above and Priority Queue Text modify
Up Timing Test show that a thin heap (priority_queue with Tag = thin_heap_tag) outperforms a pairing heap
(priority_queue with Tag = Tag = pairing_heap_tag), but the rest of the tests show otherwise.
This makes it difﬁcult to decide which implementation to use in this case.
Dijkstra’s shortest-path algorithm, for example,
requires Θ(n) push and pop operations (in the number of vertices), but O(n2) modify operations, which can be in practice
Θ(n) as well.
It is difﬁcult to ﬁnd an a-priori characterization of graphs in which the actual number of modify operations will
dwarf the number of push and pop operations.

Written by Ami Tavory and Vladimir Dreizin (IBM Haifa Research Laboratories), and Benjamin Kosnik (Red Hat).
This library was partially written at IBM’s Haifa Research Labs.
It is based heavily on policy-based design and uses many useful
techniques from Modern C++ Design: Generic Programming and Design Patterns Applied by Andrei Alexandrescu.
Two ideas are borrowed from the SGI-STL implementation:
1.
The prime-based resize policies use a list of primes taken from the SGI-STL implementation.
The red-black trees contain both a root node and a header node (containing metadata), connected in a way that forward and
reverse iteration can be performed efﬁciently.
Some test utilities borrow ideas from boost::timer.
We would like to thank Scott Meyers for useful comments (without attributing to him any ﬂaws in the design or implementation
of the library).
We would like to thank Matt Austern for the suggestion to include tries.

[55] Dave Abrahams , STL Exception Handling Contract , 1997, ISO SC22/WG21 .
Database Syst. 4 .
Database Syst. 11 .
Those dealing with older SGI-style
allocators are dealt with elsewhere.
The remaining ones all deal with bits:
The old pre-standard bit_vector class is present for backwards compatibility.
It is simply a typedef for the vector<bool>
specialization.
The bitset class has a number of extensions, described in the rest of this item.
First, we’ll mention that this implementation of
bitset<N> is specialized for cases where N number of bits will ﬁt into a single word of storage.
If your choice of N is within
that range (<=32 on i686-pc-linux-gnu, for example), then all of the operations will be faster.
There are versions of single-bit test, set, reset, and ﬂip member functions which do no range-checking.
Note that these may in fact be removed in the future, although we have no present plans to do so (and there doesn’t seem to be
any immediate reason to).
The member function operator[] on a const bitset returns a bool, and for a non-const bitset returns a reference (a nested
type).
No range-checking is done on the index argument, in keeping with other containers’ operator[] requirements.
Finally, two additional searching functions have been added.
They return the index of the ﬁrst "on" bit, and the index of the ﬁrst
"on" bit that is after prev, respectively:
size_t _Find_first() const;
size_t _Find_next (size_t prev) const;
The same caveat given for the _Unchecked_* functions applies here also.

The SGI hashing classes hash_set and hash_set have been deprecated by the unordered_set, unordered_multiset, un-
ordered_map, unordered_multimap containers in TR1 and C++11, and may be removed in future releases.
The SGI headers

<hash_map>
<hash_set>
<rope>
<slist>
<rb_tree>
are all here; <backwards/hash_map> and <backwards/hash_set> are deprecated but available as backwards-compatible
extensions, as discussed further below.
Each of the associative containers map, multimap, set, and multiset have a counterpart which uses a hashing function to do the
arranging, instead of a strict weak ordering function.
The classes take as one of their template parameters a function object that
will return the hash value; by default, an instantiation of hash.
You should specialize this functor for your class, or deﬁne your
own, before trying to use one of the hashing classes.
The hashing classes support all the usual associative container functions, as well as some extra constructors specifying the number
of buckets, etc.
Why would you want to use a hashing class instead of the “normal”implementations?
So if your implementation has hash_map, if you don’t mind
using nonstandard components, and if you aren’t scared about the possibility of pathological cases, you’ll probably
get better performance from hash_map.
The deprecated hash tables are superseded by the standard unordered associative containers deﬁned in the ISO C++ 2011 standard
in the headers <unordered_map> and <unordered_set>.
They are imple-
mented in the ﬁle stl_function.h:
• identity_element for addition and multiplication.
The functor identity, whose operator() returns the argument unchanged.
• Composition functors unary_function and binary_function, and their helpers compose1 and compose2.
A set of functors/functions which always return the same result.
They are constant_void_fun, constant_binary_fun,
constant_unary_fun, constant0, constant1, and constant2.
The class subtractive_rng.
The argument is a pointer,
which is ignored, but can be used to specify the template type (instead of using explicit function template arguments like the
standard version does).
That is, in addition to
get_temporary_buffer<int>(5);
you can also use
get_temporary_buffer(5, (int*)0);
A class temporary_buffer is given in stl_tempbuf.h.
The specialized algorithms of section are extended with uninitialized_copy_n.
The standard versions return their results.
Look in the doxygen-generated pages for notes on
these.
In the case of n == 0, returns the identity element for the monoid
operation.
The two-argument signature uses multiplication (for a true "power" implementation), but addition is supported as
well.
The operation functor must be associative.
As described in the SGI documentation, it "assigns sequentially increasing values to a range.
That is, it assigns value to
*first, value + 1 to *(first + 1) and so on.
It is extended by another signature
which takes two iterators and a reference to a result.
The result is modiﬁed, and the function returns nothing.
Today the recommended way to use stdio types with libstdc++ IOStreams is via the stdio_filebuf class
(see below), but earlier releases provided slightly different mechanisms.
The three arguments are as follows:
– __c_file_type* F
// the __c_ﬁle_type typedef usually boils down to stdio’s FILE
– ios_base::openmode M
// same as all the other uses of openmode
– int_type B
// buffer size, defaults to BUFSIZ if not speciﬁed
For those wanting to use ﬁle descriptors instead of FILE*’s, I invite you to contemplate the mysteries of C’s fdopen().
In library snapshot and later, filebufs bring back an old extension: the fd() member function.
The integer returned
from this function can be used for whatever ﬁle descriptors can be used for on your platform.
Naturally, the library cannot
track what you do on your own with a ﬁle descriptor, so if you perform any I/O directly, don’t expect the library to be aware of
it.
Instead, <ext/stdio_filebuf.h> contains a derived class template called __gnu_cxx::stdio_filebuf.
This
class can be constructed from a C FILE* or a ﬁle descriptor, and provides the fd() function.
If you have read the source documentation for namespace abi then you are aware of the cross-vendor C++ ABI in use by
GCC.
One of the exposed functions is used for demangling, abi::__cxa_demangle.
In programs like c++ﬁlt, the linker, and other tools have the ability to decode C++ ABI names, and now so can you.
Probably the only times you’ll be interested in demangling at runtime are when you’re seeing typeid strings in RTTI, or when
you’re handling the runtime-support exception classes.
The demangler interface is described in the source documentation linked to above.
It is actually written in C, so you don’t need
to be writing C++ in order to demangle C++.
In contrast to the atomics
layer, the concurrence layer consists largely of types.
All types are deﬁned within namespace __gnu_cxx.
These types can be used in a portable manner, regardless of the speciﬁc environment.
The enumerated type _Lock_policy details the set of available locking policies: _S_single, _S_mutex, and _S_atomic.
S_atomic
Indicates multi-threaded code using atomic operations.
The compile-time constant __default_lock_policy is set to one of the three values above, depending on characteristics
of the host environment and the current compilation ﬂags.
Two more datatypes make up the rest of the interface: __mutex, and __scoped_lock.
The scoped lock idiom is well-discussed within the C++ community.
This version takes a __mutex reference, and locks it
during construction of __scoped_lock and unlocks it during destruction.
This is an efﬁcient way of locking critical sections,
while retaining exception-safety.
These types have been superseded in the ISO C++ 2011 standard by the mutex and lock types
deﬁned in the header <mutex>.
The type _Atomic_word is a signed integral type supporting atomic operations.
The two functions functions are:

_Atomic_word
__exchange_and_add_dispatch(volatile _Atomic_word*, int);
void
__atomic_add_dispatch(volatile _Atomic_word*, int);
Both of these functions are declared in the header ﬁle <ext/atomicity.h>, and are in namespace __gnu_cxx.
Returns the old value.
Has no return value.
These functions forward to one of several specialized helper functions, depending on the circumstances.
For instance,
__exchange_and_add_dispatch
Calls through to either of:
• __exchange_and_add
Multi-thread version.
Inlined if compiler-generated builtin atomics can be used, otherwise resolved at link time to a non-builtin
code sequence.
Inlined.
However, only __exchange_and_add_dispatch and __atomic_add_dispatch should be used.
These functions can
be used in a portable manner, regardless of the speciﬁc environment.
In addition, there are two macros
_GLIBCXX_READ_MEM_BARRIER
_GLIBCXX_WRITE_MEM_BARRIER
Which expand to the appropriate write and read barrier required by the host hardware and operating system.
Compiler intrinsics (builtins) are always preferred.
However, as the compiler builtins for atomics are not universally implemented,
using them directly is problematic, and can result in undeﬁned function calls.
Prior to GCC 4.7 the older __sync intrinsics were used.
An example of an undeﬁned symbol from the use of __sync_fetch_and_ad
on an unsupported host is a missing reference to __sync_fetch_and_add_4.
Current releases use the newer __atomic intrinsics, which are implemented by library calls if the hardware doesn’t support
them.
Undeﬁned references to functions like __atomic_is_lock_free should be resolved by linking to libatomic,
which is usually installed alongside libstdc++.
In addition, on some hosts the compiler intrinsics are enabled conditionally, via the -march command line ﬂag.
This makes
usage vary depending on the target hardware and the ﬂags used during compile.
If builtins are possible for bool-sized integral types, ATOMIC_BOOL_LOCK_FREE will be deﬁned.
If builtins are possible for
int-sized integral types, ATOMIC_INT_LOCK_FREE will be deﬁned.
For the following hosts, intrinsics are enabled by default.
On non-ancient x86 hardware, -march=native usually does the trick.
For hosts without compiler intrinsics, but with capable hardware, hand-crafted assembly is selected.
This is the case for the
following hosts:
• cris
• hppa
• i386
• i486
• m48k
• mips
• sparc
And for the rest, a simulated atomic lock via pthreads.
Detailed information about compiler intrinsics for atomic operations can be found in the GCC documentation.
More details on the library fallbacks from the porting section.
This layer is called "gthread,"
and is comprised of one header ﬁle that wraps the host’s default thread layer with a POSIX-like interface.
The ﬁle <gthr-default.h> points to the deduced wrapper for the current host.
In libstdc++ implementation ﬁles, <bits/gthr.h> is
used to select the proper gthreads ﬁle.
Within libstdc++ sources, all calls to underlying thread functionality use this layer.
More detail as to the speciﬁc interface can be
found in the source documentation.
By design, the gthread layer is interoperable with the types, functions, and usage found in the usual <pthread.h> ﬁle, including
pthread_t, pthread_once_t, pthread_create, etc.
In this sample code, an anonymous namespace is used to keep the __mutex private to the compilation unit, and __scoped_lock
is used to guard access to the critical section within the for loop, locking the mutex on creation and freeing the mutex as control
moves out of this block.
Several exception classes are used to keep track of concurrence-related errors.
